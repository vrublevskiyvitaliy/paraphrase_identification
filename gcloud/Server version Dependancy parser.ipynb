{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# All installs here\n",
    "\n",
    "# Download medium model\n",
    "\n",
    "# Uncomment to install first time\n",
    "#! pip install spacy\n",
    "#! python -m spacy download en_core_web_lg\n",
    "# !pip install --upgrade pip\n",
    "# !pip install numpy==1.18\n",
    "# !pip install scipy==1.1.0\n",
    "# !pip install scikit-learn==0.21.3\n",
    "# !pip install networkx==2.4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# All imports and installs should be here\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk import wordpunct_tokenize\n",
    "import operator\n",
    "import re, string\n",
    "import math\n",
    "import spacy\n",
    "import copy\n",
    "\n",
    "from nltk import Tree\n",
    "# Space module import\n",
    "import en_core_web_md\n",
    "import en_core_web_lg\n",
    "# NetworkX is a Python package for the creation, manipulation, and study of the structure, dynamics, and functions of complex networks.\n",
    "import networkx as nx\n",
    "from networkx import __version__ as nxv\n",
    "import networkx.algorithms as networkx_algorithms\n",
    "\n",
    "# linear_sum_assignment Hungarian algorithm\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import NuSVC\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegressionCV, PassiveAggressiveClassifier, RidgeClassifierCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "\n",
    "# Nice progress bars\n",
    "from tqdm.notebook import tqdm\n",
    "# Used in plotting graphs \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from fractions import Fraction\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# All constants\n",
    "\n",
    "COLAB_ENV = \"colab\"\n",
    "LOCAL_ENV = \"local\"\n",
    "\n",
    "SENTENCE_START_TOKEN = \"sentence_start\"\n",
    "SENTENCE_END_TOKEN = \"sentence_end\"\n",
    "UNKNOWN_TOKEN = \"unknown_token\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_spacy_module():\n",
    "  return en_core_web_lg.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To be able run this notebook from Google Colab and localy\n",
    "\n",
    "def get_running_env():\n",
    "  current_path = os.getcwd()\n",
    "  if current_path == \"/content\":\n",
    "    return COLAB_ENV\n",
    "  return LOCAL_ENV\n",
    "\n",
    "RUNNING_ENV = get_running_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# Supress output of the cell\n",
    "\n",
    "def download_corpus():\n",
    "    \"\"\"\n",
    "      Downloading corpus files for colab research.\n",
    "    \"\"\" \n",
    "    if RUNNING_ENV == LOCAL_ENV:\n",
    "      return\n",
    "    files = [\n",
    "      'vrublevskiyvitaliy/paraphrase_identification/contents/dataset/msr-paraphrase-corpus/msr_paraphrase_train.txt',\n",
    "      'vrublevskiyvitaliy/paraphrase_identification/contents/dataset/msr-paraphrase-corpus/msr_paraphrase_test.txt',\n",
    "    ]\n",
    "    for f in files:\n",
    "       !curl --remote-name \\\n",
    "          -H 'Accept: application/vnd.github.v3.raw' \\\n",
    "          --location https://api.github.com/repos/{f}\n",
    "\n",
    "# download_corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data_location():\n",
    "  return \"\" if RUNNING_ENV == COLAB_ENV else \"./../dataset/msr-paraphrase-corpus/\"\n",
    "\n",
    "def add_start_end_sentence_tokens(s):\n",
    "  return \"%s %s %s\" % (SENTENCE_START_TOKEN, s, SENTENCE_END_TOKEN)\n",
    "\n",
    "def load_data(_preprocess_sentence=None, _train=False, _test=False):\n",
    "    \"Load the MSRP dataset.\"\n",
    "    loc = get_data_location()\n",
    "    trainloc = loc + 'msr_paraphrase_train.txt'\n",
    "    testloc = loc + 'msr_paraphrase_test.txt'\n",
    "\n",
    "    if _preprocess_sentence is None:\n",
    "      _preprocess_sentence = lambda x: x\n",
    "\n",
    "    sent1_train, sent2_train, sent1_test, sent2_test = [], [], [], []\n",
    "    label_train, label_dev, label_test = [], [], []\n",
    "\n",
    "    if _train:\n",
    "        with open(trainloc, 'r', encoding='utf8') as f:\n",
    "            f.readline()  # skipping the header of the file\n",
    "            for line in f:\n",
    "                text = line.strip().split('\\t')\n",
    "                sent1_train.append(_preprocess_sentence(text[3]))\n",
    "                sent2_train.append(_preprocess_sentence(text[4]))\n",
    "                label_train.append(int(text[0]))\n",
    "\n",
    "    if _test:\n",
    "        with open(testloc, 'r', encoding='utf8') as f:\n",
    "            f.readline()  # skipping the header of the file\n",
    "            for line in f:\n",
    "                text = line.strip().split('\\t')\n",
    "                sent1_test.append(_preprocess_sentence(text[3]))\n",
    "                sent2_test.append(_preprocess_sentence(text[4]))\n",
    "                label_test.append(int(text[0]))\n",
    "\n",
    "    if _train and _test:\n",
    "        return [sent1_train, sent2_train], [sent1_test, sent2_test], [label_train, label_test]\n",
    "    elif _train:\n",
    "        return [sent1_train, sent2_train], label_train\n",
    "    elif _test:\n",
    "        return [sent1_test, sent2_test], label_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = load_data(_preprocess_sentence=None, _train=True, _test=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sample_data(index=0):\n",
    "  all_data = load_data(_preprocess_sentence=None, _train=True, _test=False)\n",
    "  return all_data[0][0][index], all_data[0][1][index], all_data[1][index]\n",
    "\n",
    "def get_sample(index=0):\n",
    "  all_data = load_data(_preprocess_sentence=None, _train=True, _test=False)\n",
    "  return {'s1': all_data[0][0][index], 's2': all_data[0][1][index], 'label': all_data[1][index]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Amrozi accused his brother, whom he called \"the witness\", of deliberately distorting his evidence.',\n",
       " 'Referring to him as only \"the witness\", Amrozi accused his brother of deliberately distorting his evidence.',\n",
       " 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = get_sample_data()\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp = get_spacy_module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nodes': [{'node': 'ROOT', 'token': None, 'is_fake': True}, {'node': 'Amrozi', 'token': Amrozi, 'is_fake': False}, {'node': 'accused', 'token': accused, 'is_fake': False}, {'node': 'his', 'token': his, 'is_fake': False}, {'node': 'brother', 'token': brother, 'is_fake': False}, {'node': ',', 'token': ,, 'is_fake': False}, {'node': 'whom', 'token': whom, 'is_fake': False}, {'node': 'he', 'token': he, 'is_fake': False}, {'node': 'called', 'token': called, 'is_fake': False}, {'node': '\"', 'token': \", 'is_fake': False}, {'node': 'the', 'token': the, 'is_fake': False}, {'node': 'witness', 'token': witness, 'is_fake': False}, {'node': '\"', 'token': \", 'is_fake': False}, {'node': ',', 'token': ,, 'is_fake': False}, {'node': 'of', 'token': of, 'is_fake': False}, {'node': 'deliberately', 'token': deliberately, 'is_fake': False}, {'node': 'distorting', 'token': distorting, 'is_fake': False}, {'node': 'his', 'token': his, 'is_fake': False}, {'node': 'evidence', 'token': evidence, 'is_fake': False}, {'node': '.', 'token': ., 'is_fake': False}], 'edges': [{'start': 'accused', 'end': 'Amrozi', 'start_node_id': 2, 'end_node_id': 1, 'type': 'nsubj'}, {'start': 'ROOT', 'end': 'accused', 'start_node_id': 0, 'end_node_id': 2, 'type': 'ROOT'}, {'start': 'brother', 'end': 'his', 'start_node_id': 4, 'end_node_id': 3, 'type': 'poss'}, {'start': 'accused', 'end': 'brother', 'start_node_id': 2, 'end_node_id': 4, 'type': 'dobj'}, {'start': 'brother', 'end': ',', 'start_node_id': 4, 'end_node_id': 5, 'type': 'punct'}, {'start': 'called', 'end': 'whom', 'start_node_id': 8, 'end_node_id': 6, 'type': 'dobj'}, {'start': 'called', 'end': 'he', 'start_node_id': 8, 'end_node_id': 7, 'type': 'nsubj'}, {'start': 'brother', 'end': 'called', 'start_node_id': 4, 'end_node_id': 8, 'type': 'relcl'}, {'start': 'witness', 'end': '\"', 'start_node_id': 11, 'end_node_id': 9, 'type': 'punct'}, {'start': 'witness', 'end': 'the', 'start_node_id': 11, 'end_node_id': 10, 'type': 'det'}, {'start': 'called', 'end': 'witness', 'start_node_id': 8, 'end_node_id': 11, 'type': 'oprd'}, {'start': 'witness', 'end': '\"', 'start_node_id': 11, 'end_node_id': 12, 'type': 'punct'}, {'start': 'accused', 'end': ',', 'start_node_id': 2, 'end_node_id': 13, 'type': 'punct'}, {'start': 'accused', 'end': 'of', 'start_node_id': 2, 'end_node_id': 14, 'type': 'prep'}, {'start': 'distorting', 'end': 'deliberately', 'start_node_id': 16, 'end_node_id': 15, 'type': 'advmod'}, {'start': 'of', 'end': 'distorting', 'start_node_id': 14, 'end_node_id': 16, 'type': 'pcomp'}, {'start': 'evidence', 'end': 'his', 'start_node_id': 18, 'end_node_id': 17, 'type': 'poss'}, {'start': 'distorting', 'end': 'evidence', 'start_node_id': 16, 'end_node_id': 18, 'type': 'dobj'}, {'start': 'accused', 'end': '.', 'start_node_id': 2, 'end_node_id': 19, 'type': 'punct'}]}\n",
      "{'nodes': [{'node': 'ROOT', 'token': None, 'is_fake': True}, {'node': 'Referring', 'token': Referring, 'is_fake': False}, {'node': 'to', 'token': to, 'is_fake': False}, {'node': 'him', 'token': him, 'is_fake': False}, {'node': 'as', 'token': as, 'is_fake': False}, {'node': 'only', 'token': only, 'is_fake': False}, {'node': '\"', 'token': \", 'is_fake': False}, {'node': 'the', 'token': the, 'is_fake': False}, {'node': 'witness', 'token': witness, 'is_fake': False}, {'node': '\"', 'token': \", 'is_fake': False}, {'node': ',', 'token': ,, 'is_fake': False}, {'node': 'Amrozi', 'token': Amrozi, 'is_fake': False}, {'node': 'accused', 'token': accused, 'is_fake': False}, {'node': 'his', 'token': his, 'is_fake': False}, {'node': 'brother', 'token': brother, 'is_fake': False}, {'node': 'of', 'token': of, 'is_fake': False}, {'node': 'deliberately', 'token': deliberately, 'is_fake': False}, {'node': 'distorting', 'token': distorting, 'is_fake': False}, {'node': 'his', 'token': his, 'is_fake': False}, {'node': 'evidence', 'token': evidence, 'is_fake': False}, {'node': '.', 'token': ., 'is_fake': False}], 'edges': [{'start': 'accused', 'end': 'Referring', 'start_node_id': 12, 'end_node_id': 1, 'type': 'advcl'}, {'start': 'Referring', 'end': 'to', 'start_node_id': 1, 'end_node_id': 2, 'type': 'prep'}, {'start': 'to', 'end': 'him', 'start_node_id': 2, 'end_node_id': 3, 'type': 'pobj'}, {'start': 'Referring', 'end': 'as', 'start_node_id': 1, 'end_node_id': 4, 'type': 'prep'}, {'start': 'witness', 'end': 'only', 'start_node_id': 8, 'end_node_id': 5, 'type': 'advmod'}, {'start': 'witness', 'end': '\"', 'start_node_id': 8, 'end_node_id': 6, 'type': 'punct'}, {'start': 'witness', 'end': 'the', 'start_node_id': 8, 'end_node_id': 7, 'type': 'det'}, {'start': 'as', 'end': 'witness', 'start_node_id': 4, 'end_node_id': 8, 'type': 'pobj'}, {'start': 'witness', 'end': '\"', 'start_node_id': 8, 'end_node_id': 9, 'type': 'punct'}, {'start': 'accused', 'end': ',', 'start_node_id': 12, 'end_node_id': 10, 'type': 'punct'}, {'start': 'accused', 'end': 'Amrozi', 'start_node_id': 12, 'end_node_id': 11, 'type': 'nsubj'}, {'start': 'ROOT', 'end': 'accused', 'start_node_id': 0, 'end_node_id': 12, 'type': 'ROOT'}, {'start': 'brother', 'end': 'his', 'start_node_id': 14, 'end_node_id': 13, 'type': 'poss'}, {'start': 'accused', 'end': 'brother', 'start_node_id': 12, 'end_node_id': 14, 'type': 'dobj'}, {'start': 'accused', 'end': 'of', 'start_node_id': 12, 'end_node_id': 15, 'type': 'prep'}, {'start': 'distorting', 'end': 'deliberately', 'start_node_id': 17, 'end_node_id': 16, 'type': 'advmod'}, {'start': 'of', 'end': 'distorting', 'start_node_id': 15, 'end_node_id': 17, 'type': 'pcomp'}, {'start': 'evidence', 'end': 'his', 'start_node_id': 19, 'end_node_id': 18, 'type': 'poss'}, {'start': 'distorting', 'end': 'evidence', 'start_node_id': 17, 'end_node_id': 19, 'type': 'dobj'}, {'start': 'accused', 'end': '.', 'start_node_id': 12, 'end_node_id': 20, 'type': 'punct'}]}\n"
     ]
    }
   ],
   "source": [
    "def get_dependancy_graph(s, display=False):\n",
    "  doc = nlp(s)\n",
    "  if display:\n",
    "    spacy.displacy.render(doc, style=\"dep\", jupyter=True)\n",
    "  edges = []\n",
    "  nodes = [{\n",
    "      \"node\": \"ROOT\",\n",
    "      \"token\": None,\n",
    "      \"is_fake\": True, \n",
    "  }]\n",
    "  for token in doc:\n",
    "    nodes.append({\n",
    "        \"node\": token.text,\n",
    "        \"token\": token,\n",
    "        \"is_fake\": False,\n",
    "    })\n",
    "    if token.dep_ == \"ROOT\":\n",
    "      edges.append({\n",
    "        \"start\": \"ROOT\",\n",
    "        \"end\": token.text,\n",
    "        \"start_node_id\": 0,\n",
    "        \"end_node_id\": token.i + 1,\n",
    "        \"type\": token.dep_\n",
    "      })\n",
    "    else:\n",
    "      edges.append({\n",
    "        \"start\": token.head.text,\n",
    "        \"end\": token.text,\n",
    "        \"start_node_id\":  token.head.i + 1,\n",
    "        \"end_node_id\": token.i + 1,\n",
    "        \"type\": token.dep_\n",
    "      })\n",
    "  return {\"nodes\": nodes, \"edges\": edges}\n",
    "\n",
    "graph1 = get_dependancy_graph(sample[0], False)\n",
    "graph2 = get_dependancy_graph(sample[1], False)\n",
    "print(graph1)\n",
    "print(graph2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I try to explore diferent Graph similarity algorithms:\n",
    "\n",
    "First approach\n",
    "1.   Map nodes using Hungarian algorithm\n",
    "2.   Count Graph Edit Distance GED also using Hungarian algorithm\n",
    "\n",
    "Ideas to try:\n",
    "* add treshold for node matching, only if > 0.5 for example merge nodes\n",
    "\n",
    "Next ideas to try: \n",
    "* From graphs get graph based entities like path, or subgraphs.\n",
    "* Combine vectors in these entities\n",
    "* Count # of entities with some similarity threshold\n",
    "\n",
    "Look at different structural graph features. Try to look at https://networkx.github.io/documentation/latest/reference/algorithms/index.html\n",
    "\n",
    "\n",
    "One example could be Wiener index (need to think on normalization)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code is taken from https://github.com/Jacobe2169/ged4py\n",
    "\n",
    "class EdgeGraph():\n",
    "    def __init__(self, init_node, nodes):\n",
    "        self.init_node=init_node\n",
    "        self.nodes_ = nodes\n",
    "\n",
    "    def nodes(self):\n",
    "        return self.nodes_\n",
    "\n",
    "    def size(self):\n",
    "        return len(self.nodes)\n",
    "    def __len__(self):\n",
    "        return len(self.nodes_)\n",
    "\n",
    "class AbstractGraphEditDistance(object):\n",
    "    def __init__(self, g1, g2):\n",
    "        self.g1 = g1\n",
    "        self.g2 = g2\n",
    "\n",
    "    def normalized_distance(self):\n",
    "        \"\"\"\n",
    "        Returns the graph edit distance between graph g1 & g2\n",
    "        The distance is normalized on the size of the two graphs.\n",
    "        This is done to avoid favorisation towards smaller graphs\n",
    "        \"\"\"\n",
    "        avg_graphlen = len(self.g1) + len(self.g2)\n",
    "        return self.distance() / avg_graphlen\n",
    "\n",
    "    def distance(self):\n",
    "        return sum(self.edit_costs())\n",
    "\n",
    "    def edit_costs(self):\n",
    "        cost_matrix = self.create_cost_matrix()\n",
    "        row_ind,col_ind = linear_sum_assignment(cost_matrix)\n",
    "        return [cost_matrix[row_ind[i]][col_ind[i]] for i in range(len(row_ind))]\n",
    "\n",
    "    def create_cost_matrix(self):\n",
    "        \"\"\"\n",
    "        Creates a |N+M| X |N+M| cost matrix between all nodes in\n",
    "        graphs g1 and g2\n",
    "        Each cost represents the cost of substituting,\n",
    "        deleting or inserting a node\n",
    "        The cost matrix consists of four regions:\n",
    "        substitute \t| insert costs\n",
    "        -------------------------------\n",
    "        delete \t\t| delete -> delete\n",
    "        The delete -> delete region is filled with zeros\n",
    "        \"\"\"\n",
    "        n = len(self.g1)\n",
    "        m = len(self.g2)\n",
    "        cost_matrix = np.zeros((n+m,n+m))\n",
    "        #cost_matrix = [[0 for i in range(n + m)] for j in range(n + m)]\n",
    "        nodes1 = self.g1.nodes() if float(nxv) < 2 else list(self.g1.nodes())\n",
    "        nodes2 = self.g2.nodes() if float(nxv) < 2 else list(self.g2.nodes())\n",
    "\n",
    "        for i in range(n):\n",
    "            for j in range(m):\n",
    "                cost_matrix[i,j] = self.substitute_cost(nodes1[i], nodes2[j])\n",
    "\n",
    "        for i in range(m):\n",
    "            for j in range(m):\n",
    "                cost_matrix[i+n,j] = self.insert_cost(i, j, nodes2)\n",
    "\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                cost_matrix[j,i+m] = self.delete_cost(i, j, nodes1)\n",
    "\n",
    "        self.cost_matrix = cost_matrix\n",
    "        return cost_matrix\n",
    "\n",
    "    def insert_cost(self, i, j):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def delete_cost(self, i, j):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def substitute_cost(self, nodes1, nodes2):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def print_matrix(self):\n",
    "        print(\"cost matrix:\")\n",
    "        for column in self.create_cost_matrix():\n",
    "            for row in column:\n",
    "                if row == sys.maxsize:\n",
    "                    print (\"inf\\t\")\n",
    "                else:\n",
    "                    print (\"%.2f\\t\" % float(row))\n",
    "            print(\"\")\n",
    "\n",
    "class EdgeEditDistance(AbstractGraphEditDistance):\n",
    "    \"\"\"\n",
    "    Calculates the graph edit distance between two edges.\n",
    "    A node in this context is interpreted as a graph,\n",
    "    and edges are interpreted as nodes.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, g1, g2):\n",
    "        AbstractGraphEditDistance.__init__(self, g1, g2)\n",
    "\n",
    "    def insert_cost(self, i, j, nodes2):\n",
    "        if i == j:\n",
    "            return 1\n",
    "        return sys.maxsize\n",
    "\n",
    "    def delete_cost(self, i, j, nodes1):\n",
    "        if i == j:\n",
    "            return 1\n",
    "        return sys.maxsize\n",
    "\n",
    "    def substitute_cost(self, edge1, edge2):\n",
    "        if edge1 == edge2:\n",
    "            return 0.\n",
    "        return 1\n",
    "\n",
    "class GraphEditDistance(AbstractGraphEditDistance):\n",
    "    def __init__(self, g1, g2):\n",
    "        AbstractGraphEditDistance.__init__(self, g1, g2)\n",
    "\n",
    "    def substitute_cost(self, node1, node2):\n",
    "        return self.relabel_cost(node1, node2) + self.edge_diff(node1, node2)\n",
    "\n",
    "    def relabel_cost(self, node1, node2):\n",
    "        if node1 == node2:\n",
    "            return 0.\n",
    "        else:\n",
    "            return 1.\n",
    "\n",
    "    def delete_cost(self, i, j, nodes1):\n",
    "        if i == j:\n",
    "            return 1\n",
    "        return sys.maxsize\n",
    "\n",
    "    def insert_cost(self, i, j, nodes2):\n",
    "        if i == j:\n",
    "            return 1\n",
    "        else:\n",
    "            return sys.maxsize\n",
    "\n",
    "    def pos_insdel_weight(self, node):\n",
    "        return 1\n",
    "\n",
    "    def edge_diff(self, node1, node2):\n",
    "        edges1 = list(self.g1.edge[node1].keys()) if float(nxv) < 2 else list(self.g1.edges(node1))\n",
    "        edges2 = list(self.g2.edge[node2].keys()) if float(nxv) < 2 else list(self.g2.edges(node2))\n",
    "        if len(edges1) == 0 or len(edges2) == 0:\n",
    "            return max(len(edges1), len(edges2))\n",
    "\n",
    "        edit_edit_dist = EdgeEditDistance(EdgeGraph(node1,edges1), EdgeGraph(node2,edges2))\n",
    "        return edit_edit_dist.normalized_distance()\n",
    "\n",
    "def compare_graphs(g1, g2, print_details=False, use_normalized=True):\n",
    "    ged = GraphEditDistance(g1, g2)\n",
    "\n",
    "    if print_details:\n",
    "        ged.print_matrix()\n",
    "\n",
    "    return ged.normalized_distance() if use_normalized else ged.distance()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class HungarianGraphNodesMatcher:\n",
    "\n",
    "  def __init__(self, _g1, _g2, threshold=0.5):\n",
    "    self.g1 = _g1\n",
    "    self.g2 = _g2\n",
    "    self.node_threshold = threshold\n",
    "    self.create_cost_matrix()\n",
    "    self.solve_linear_sum_assignment()\n",
    "    self.match_nodes()\n",
    "\n",
    "  def set_threshold(self, threshold):\n",
    "    self.node_threshold = threshold\n",
    "    self.match_nodes()\n",
    "\n",
    "  def create_cost_matrix(self):\n",
    "    self.matrix = np.zeros((len(self.g1[\"nodes\"]), len(self.g2[\"nodes\"])))\n",
    "    for i1, n1 in enumerate(self.g1[\"nodes\"]):\n",
    "       for i2, n2 in enumerate(self.g2[\"nodes\"]):\n",
    "         if (not n1[\"is_fake\"] and not n2[\"is_fake\"] and \n",
    "            n1[\"token\"].has_vector and n2[\"token\"].has_vector):\n",
    "           self.matrix[i1][i2] = n1[\"token\"].similarity(n2[\"token\"])\n",
    "         elif n1[\"is_fake\"] == n2[\"is_fake\"]:\n",
    "           self.matrix[i1][i2] = n1[\"node\"] == n2[\"node\"]\n",
    "         else:\n",
    "           self.matrix[i1][i2] = 0\n",
    "\n",
    "    # Now we need to fleep scores, because Hungarian is trying to minimize\n",
    "    self.cost = np.subtract(np.full(self.matrix.shape, 1), self.matrix)\n",
    "\n",
    "  def get_pandas_matrix(self):\n",
    "    df = pd.DataFrame(\n",
    "        data=self.matrix,\n",
    "        index=np.array([n[\"node\"] for n in self.g1[\"nodes\"]]),\n",
    "        columns=np.array([n[\"node\"] for n in self.g2[\"nodes\"]])\n",
    "      )\n",
    "    \n",
    "    return df\n",
    "\n",
    "  def solve_linear_sum_assignment(self):\n",
    "    row_ind, col_ind = linear_sum_assignment(self.cost)\n",
    "    \n",
    "    self.row_ind = row_ind\n",
    "    self.col_ind = col_ind\n",
    "\n",
    "  def match_nodes(self):\n",
    "    self.graph1_to_graph2 = {\n",
    "        item[0]: item[1] \n",
    "        for item in zip(self.row_ind, self.col_ind)\n",
    "        if self.matrix[item[0]][item[1]] > self.node_threshold\n",
    "    }\n",
    "\n",
    "  def create_node_aliases(self):\n",
    "    for id1, n1 in enumerate(self.g1[\"nodes\"]):\n",
    "      n1[\"alias\"] = \"G1_\" + str(id1) + n1[\"node\"]\n",
    "    for id2, n2 in enumerate(self.g2[\"nodes\"]):\n",
    "      n2[\"alias\"] = \"G2_\" + str(id2) + n2[\"node\"] \n",
    "    for id1, id2 in self.graph1_to_graph2.items():\n",
    "      n1 = self.g1[\"nodes\"][id1]\n",
    "      n2 = self.g2[\"nodes\"][id2]\n",
    "      n1[\"alias\"] = \"G1_\" + str(id1) + \"_\" + n1[\"node\"] + \"_G2_\" + str(id2) + \"_\" + n2[\"node\"]\n",
    "      n2[\"alias\"] = n1[\"alias\"]\n",
    "\n",
    "  def build_graph(self, g):\n",
    "    nx_g = nx.Graph()\n",
    "    for edge in g[\"edges\"]:\n",
    "      start_node = g[\"nodes\"][edge[\"start_node_id\"]]\n",
    "      end_node = g[\"nodes\"][edge[\"end_node_id\"]]\n",
    "      nx_g.add_edge(start_node[\"alias\"], end_node[\"alias\"])\n",
    "    return nx_g\n",
    "\n",
    "  def get_converted_graphs(self):\n",
    "    self.create_node_aliases()\n",
    "    g1 = self.build_graph(self.g1)\n",
    "    g2 = self.build_graph(self.g2)\n",
    "    return g1, g2\n",
    "\n",
    "  def print_matched_nodes(self):\n",
    "    print (\"Graph 1  =>   Graph 2\")\n",
    "    for id1, id2 in self.graph1_to_graph2.items():\n",
    "      print(f\"{self.g1['nodes'][id1]['node']}    =>   {self.g2['nodes'][id2]['node']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GraphBuilder:\n",
    "\n",
    "  def __init__(self):\n",
    "    pass\n",
    "  \n",
    "  @classmethod\n",
    "  def build_nx_graph_from_dt(cls, g):\n",
    "    nx_g = nx.Graph()\n",
    "    for index, node in enumerate(g[\"nodes\"]):\n",
    "      nx_g.add_node(index, node=node['node'], token=node['token'], is_fake=node['is_fake'])\n",
    "    for edge in g[\"edges\"]:\n",
    "      nx_g.add_edge(edge[\"start_node_id\"], edge[\"end_node_id\"], dependancy_type=edge[\"type\"])\n",
    "    return nx_g\n",
    "\n",
    "\n",
    "  @classmethod\n",
    "  def build_nx_graph_from_sentance(cls, s):\n",
    "    graph = get_dependancy_graph(s, False)\n",
    "    return cls.build_nx_graph_from_dt(graph)\n",
    "\n",
    "  @classmethod\n",
    "  def get_root_node(cls, g):\n",
    "    main_root_node = [n for n, _ in g.adj[0].items()][0]\n",
    "    return g.nodes[main_root_node]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "node_matcher = HungarianGraphNodesMatcher(graph1, graph2, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph 1  =>   Graph 2\n",
      "ROOT    =>   ROOT\n",
      "Amrozi    =>   Amrozi\n",
      "accused    =>   accused\n",
      "his    =>   his\n",
      "brother    =>   brother\n",
      ",    =>   ,\n",
      "\"    =>   \"\n",
      "the    =>   the\n",
      "witness    =>   witness\n",
      "\"    =>   \"\n",
      "of    =>   of\n",
      "deliberately    =>   deliberately\n",
      "distorting    =>   distorting\n",
      "his    =>   his\n",
      "evidence    =>   evidence\n",
      ".    =>   .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_matcher.print_matched_nodes()\n",
    "len(node_matcher.graph1_to_graph2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROOT</th>\n",
       "      <th>Referring</th>\n",
       "      <th>to</th>\n",
       "      <th>him</th>\n",
       "      <th>as</th>\n",
       "      <th>only</th>\n",
       "      <th>\"</th>\n",
       "      <th>the</th>\n",
       "      <th>witness</th>\n",
       "      <th>\"</th>\n",
       "      <th>...</th>\n",
       "      <th>Amrozi</th>\n",
       "      <th>accused</th>\n",
       "      <th>his</th>\n",
       "      <th>brother</th>\n",
       "      <th>of</th>\n",
       "      <th>deliberately</th>\n",
       "      <th>distorting</th>\n",
       "      <th>his</th>\n",
       "      <th>evidence</th>\n",
       "      <th>.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ROOT</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amrozi</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accused</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.462788</td>\n",
       "      <td>0.247302</td>\n",
       "      <td>0.428843</td>\n",
       "      <td>0.329721</td>\n",
       "      <td>0.288702</td>\n",
       "      <td>0.177370</td>\n",
       "      <td>0.245612</td>\n",
       "      <td>0.495963</td>\n",
       "      <td>0.177370</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.409809</td>\n",
       "      <td>0.430317</td>\n",
       "      <td>0.245755</td>\n",
       "      <td>0.492152</td>\n",
       "      <td>0.235543</td>\n",
       "      <td>0.409809</td>\n",
       "      <td>0.455700</td>\n",
       "      <td>0.089694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>his</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.448873</td>\n",
       "      <td>0.450099</td>\n",
       "      <td>0.818316</td>\n",
       "      <td>0.534291</td>\n",
       "      <td>0.459990</td>\n",
       "      <td>0.307721</td>\n",
       "      <td>0.589037</td>\n",
       "      <td>0.460539</td>\n",
       "      <td>0.307721</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.409809</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.595102</td>\n",
       "      <td>0.470308</td>\n",
       "      <td>0.375484</td>\n",
       "      <td>0.162476</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.372411</td>\n",
       "      <td>0.293258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brother</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.326865</td>\n",
       "      <td>0.278940</td>\n",
       "      <td>0.593552</td>\n",
       "      <td>0.359954</td>\n",
       "      <td>0.315489</td>\n",
       "      <td>0.165423</td>\n",
       "      <td>0.276650</td>\n",
       "      <td>0.382124</td>\n",
       "      <td>0.165423</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.430317</td>\n",
       "      <td>0.595102</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.218296</td>\n",
       "      <td>0.202813</td>\n",
       "      <td>-0.017952</td>\n",
       "      <td>0.595102</td>\n",
       "      <td>0.181388</td>\n",
       "      <td>0.244569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.191477</td>\n",
       "      <td>0.260884</td>\n",
       "      <td>0.260457</td>\n",
       "      <td>0.453440</td>\n",
       "      <td>0.272194</td>\n",
       "      <td>0.225224</td>\n",
       "      <td>0.207785</td>\n",
       "      <td>0.204928</td>\n",
       "      <td>0.225224</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.154774</td>\n",
       "      <td>0.247196</td>\n",
       "      <td>0.260554</td>\n",
       "      <td>0.246289</td>\n",
       "      <td>0.178351</td>\n",
       "      <td>-0.007885</td>\n",
       "      <td>0.247196</td>\n",
       "      <td>0.218267</td>\n",
       "      <td>0.421524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whom</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.530618</td>\n",
       "      <td>0.404365</td>\n",
       "      <td>0.627295</td>\n",
       "      <td>0.527354</td>\n",
       "      <td>0.508026</td>\n",
       "      <td>0.194234</td>\n",
       "      <td>0.375806</td>\n",
       "      <td>0.491248</td>\n",
       "      <td>0.194234</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.503349</td>\n",
       "      <td>0.543793</td>\n",
       "      <td>0.561806</td>\n",
       "      <td>0.362452</td>\n",
       "      <td>0.402099</td>\n",
       "      <td>0.065883</td>\n",
       "      <td>0.543793</td>\n",
       "      <td>0.391814</td>\n",
       "      <td>0.222853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>he</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.501589</td>\n",
       "      <td>0.436620</td>\n",
       "      <td>0.827520</td>\n",
       "      <td>0.592211</td>\n",
       "      <td>0.577246</td>\n",
       "      <td>0.372794</td>\n",
       "      <td>0.491815</td>\n",
       "      <td>0.476299</td>\n",
       "      <td>0.372794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.454249</td>\n",
       "      <td>0.791888</td>\n",
       "      <td>0.579133</td>\n",
       "      <td>0.374885</td>\n",
       "      <td>0.455827</td>\n",
       "      <td>0.101640</td>\n",
       "      <td>0.791888</td>\n",
       "      <td>0.417391</td>\n",
       "      <td>0.419956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>called</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.503237</td>\n",
       "      <td>0.357370</td>\n",
       "      <td>0.417062</td>\n",
       "      <td>0.558222</td>\n",
       "      <td>0.401485</td>\n",
       "      <td>0.448924</td>\n",
       "      <td>0.532806</td>\n",
       "      <td>0.269240</td>\n",
       "      <td>0.448924</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.313714</td>\n",
       "      <td>0.409235</td>\n",
       "      <td>0.322105</td>\n",
       "      <td>0.401833</td>\n",
       "      <td>0.246508</td>\n",
       "      <td>-0.009064</td>\n",
       "      <td>0.409235</td>\n",
       "      <td>0.295163</td>\n",
       "      <td>0.251584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\"</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.314289</td>\n",
       "      <td>0.299291</td>\n",
       "      <td>0.304552</td>\n",
       "      <td>0.358556</td>\n",
       "      <td>0.277636</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.299336</td>\n",
       "      <td>0.192335</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.177370</td>\n",
       "      <td>0.307721</td>\n",
       "      <td>0.165423</td>\n",
       "      <td>0.237327</td>\n",
       "      <td>0.202483</td>\n",
       "      <td>0.009449</td>\n",
       "      <td>0.307721</td>\n",
       "      <td>0.209467</td>\n",
       "      <td>0.292410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.461733</td>\n",
       "      <td>0.587738</td>\n",
       "      <td>0.506893</td>\n",
       "      <td>0.604139</td>\n",
       "      <td>0.568014</td>\n",
       "      <td>0.299336</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.399221</td>\n",
       "      <td>0.299336</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.245612</td>\n",
       "      <td>0.589037</td>\n",
       "      <td>0.276650</td>\n",
       "      <td>0.713939</td>\n",
       "      <td>0.275821</td>\n",
       "      <td>0.140437</td>\n",
       "      <td>0.589037</td>\n",
       "      <td>0.409072</td>\n",
       "      <td>0.311351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>witness</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.431173</td>\n",
       "      <td>0.340437</td>\n",
       "      <td>0.493643</td>\n",
       "      <td>0.392104</td>\n",
       "      <td>0.376920</td>\n",
       "      <td>0.192335</td>\n",
       "      <td>0.399221</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.192335</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.495963</td>\n",
       "      <td>0.460539</td>\n",
       "      <td>0.382124</td>\n",
       "      <td>0.333289</td>\n",
       "      <td>0.351068</td>\n",
       "      <td>0.220822</td>\n",
       "      <td>0.460539</td>\n",
       "      <td>0.629995</td>\n",
       "      <td>0.219035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\"</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.314289</td>\n",
       "      <td>0.299291</td>\n",
       "      <td>0.304552</td>\n",
       "      <td>0.358556</td>\n",
       "      <td>0.277636</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.299336</td>\n",
       "      <td>0.192335</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.177370</td>\n",
       "      <td>0.307721</td>\n",
       "      <td>0.165423</td>\n",
       "      <td>0.237327</td>\n",
       "      <td>0.202483</td>\n",
       "      <td>0.009449</td>\n",
       "      <td>0.307721</td>\n",
       "      <td>0.209467</td>\n",
       "      <td>0.292410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.191477</td>\n",
       "      <td>0.260884</td>\n",
       "      <td>0.260457</td>\n",
       "      <td>0.453440</td>\n",
       "      <td>0.272194</td>\n",
       "      <td>0.225224</td>\n",
       "      <td>0.207785</td>\n",
       "      <td>0.204928</td>\n",
       "      <td>0.225224</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.154774</td>\n",
       "      <td>0.247196</td>\n",
       "      <td>0.260554</td>\n",
       "      <td>0.246289</td>\n",
       "      <td>0.178351</td>\n",
       "      <td>-0.007885</td>\n",
       "      <td>0.247196</td>\n",
       "      <td>0.218267</td>\n",
       "      <td>0.421524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.352237</td>\n",
       "      <td>0.473689</td>\n",
       "      <td>0.359554</td>\n",
       "      <td>0.537883</td>\n",
       "      <td>0.474578</td>\n",
       "      <td>0.237327</td>\n",
       "      <td>0.713939</td>\n",
       "      <td>0.333289</td>\n",
       "      <td>0.237327</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.245755</td>\n",
       "      <td>0.470308</td>\n",
       "      <td>0.218296</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.162817</td>\n",
       "      <td>0.109792</td>\n",
       "      <td>0.470308</td>\n",
       "      <td>0.390543</td>\n",
       "      <td>0.314684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deliberately</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.468218</td>\n",
       "      <td>0.314271</td>\n",
       "      <td>0.396287</td>\n",
       "      <td>0.345136</td>\n",
       "      <td>0.381660</td>\n",
       "      <td>0.202483</td>\n",
       "      <td>0.275821</td>\n",
       "      <td>0.351068</td>\n",
       "      <td>0.202483</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.492152</td>\n",
       "      <td>0.375484</td>\n",
       "      <td>0.202813</td>\n",
       "      <td>0.162817</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500688</td>\n",
       "      <td>0.375484</td>\n",
       "      <td>0.408713</td>\n",
       "      <td>0.132542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distorting</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.278553</td>\n",
       "      <td>0.067570</td>\n",
       "      <td>0.141566</td>\n",
       "      <td>0.114629</td>\n",
       "      <td>0.125476</td>\n",
       "      <td>0.009449</td>\n",
       "      <td>0.140437</td>\n",
       "      <td>0.220822</td>\n",
       "      <td>0.009449</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.235543</td>\n",
       "      <td>0.162476</td>\n",
       "      <td>-0.017952</td>\n",
       "      <td>0.109792</td>\n",
       "      <td>0.500688</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.162476</td>\n",
       "      <td>0.285325</td>\n",
       "      <td>-0.002664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>his</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.448873</td>\n",
       "      <td>0.450099</td>\n",
       "      <td>0.818316</td>\n",
       "      <td>0.534291</td>\n",
       "      <td>0.459990</td>\n",
       "      <td>0.307721</td>\n",
       "      <td>0.589037</td>\n",
       "      <td>0.460539</td>\n",
       "      <td>0.307721</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.409809</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.595102</td>\n",
       "      <td>0.470308</td>\n",
       "      <td>0.375484</td>\n",
       "      <td>0.162476</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.372411</td>\n",
       "      <td>0.293258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>evidence</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.479350</td>\n",
       "      <td>0.323899</td>\n",
       "      <td>0.368769</td>\n",
       "      <td>0.398676</td>\n",
       "      <td>0.445381</td>\n",
       "      <td>0.209467</td>\n",
       "      <td>0.409072</td>\n",
       "      <td>0.629995</td>\n",
       "      <td>0.209467</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.455700</td>\n",
       "      <td>0.372411</td>\n",
       "      <td>0.181388</td>\n",
       "      <td>0.390543</td>\n",
       "      <td>0.408713</td>\n",
       "      <td>0.285325</td>\n",
       "      <td>0.372411</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.225468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.254930</td>\n",
       "      <td>0.358275</td>\n",
       "      <td>0.380523</td>\n",
       "      <td>0.453307</td>\n",
       "      <td>0.366517</td>\n",
       "      <td>0.292410</td>\n",
       "      <td>0.311351</td>\n",
       "      <td>0.219035</td>\n",
       "      <td>0.292410</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.089694</td>\n",
       "      <td>0.293258</td>\n",
       "      <td>0.244569</td>\n",
       "      <td>0.314684</td>\n",
       "      <td>0.132542</td>\n",
       "      <td>-0.002664</td>\n",
       "      <td>0.293258</td>\n",
       "      <td>0.225468</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ROOT  Referring        to       him        as      only  \\\n",
       "ROOT           1.0   0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "Amrozi         0.0   0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "accused        0.0   0.462788  0.247302  0.428843  0.329721  0.288702   \n",
       "his            0.0   0.448873  0.450099  0.818316  0.534291  0.459990   \n",
       "brother        0.0   0.326865  0.278940  0.593552  0.359954  0.315489   \n",
       ",              0.0   0.191477  0.260884  0.260457  0.453440  0.272194   \n",
       "whom           0.0   0.530618  0.404365  0.627295  0.527354  0.508026   \n",
       "he             0.0   0.501589  0.436620  0.827520  0.592211  0.577246   \n",
       "called         0.0   0.503237  0.357370  0.417062  0.558222  0.401485   \n",
       "\"              0.0   0.314289  0.299291  0.304552  0.358556  0.277636   \n",
       "the            0.0   0.461733  0.587738  0.506893  0.604139  0.568014   \n",
       "witness        0.0   0.431173  0.340437  0.493643  0.392104  0.376920   \n",
       "\"              0.0   0.314289  0.299291  0.304552  0.358556  0.277636   \n",
       ",              0.0   0.191477  0.260884  0.260457  0.453440  0.272194   \n",
       "of             0.0   0.352237  0.473689  0.359554  0.537883  0.474578   \n",
       "deliberately   0.0   0.468218  0.314271  0.396287  0.345136  0.381660   \n",
       "distorting     0.0   0.278553  0.067570  0.141566  0.114629  0.125476   \n",
       "his            0.0   0.448873  0.450099  0.818316  0.534291  0.459990   \n",
       "evidence       0.0   0.479350  0.323899  0.368769  0.398676  0.445381   \n",
       ".              0.0   0.254930  0.358275  0.380523  0.453307  0.366517   \n",
       "\n",
       "                     \"       the   witness         \"    ...     Amrozi  \\\n",
       "ROOT          0.000000  0.000000  0.000000  0.000000    ...        0.0   \n",
       "Amrozi        0.000000  0.000000  0.000000  0.000000    ...        1.0   \n",
       "accused       0.177370  0.245612  0.495963  0.177370    ...        0.0   \n",
       "his           0.307721  0.589037  0.460539  0.307721    ...        0.0   \n",
       "brother       0.165423  0.276650  0.382124  0.165423    ...        0.0   \n",
       ",             0.225224  0.207785  0.204928  0.225224    ...        0.0   \n",
       "whom          0.194234  0.375806  0.491248  0.194234    ...        0.0   \n",
       "he            0.372794  0.491815  0.476299  0.372794    ...        0.0   \n",
       "called        0.448924  0.532806  0.269240  0.448924    ...        0.0   \n",
       "\"             1.000000  0.299336  0.192335  1.000000    ...        0.0   \n",
       "the           0.299336  1.000000  0.399221  0.299336    ...        0.0   \n",
       "witness       0.192335  0.399221  1.000000  0.192335    ...        0.0   \n",
       "\"             1.000000  0.299336  0.192335  1.000000    ...        0.0   \n",
       ",             0.225224  0.207785  0.204928  0.225224    ...        0.0   \n",
       "of            0.237327  0.713939  0.333289  0.237327    ...        0.0   \n",
       "deliberately  0.202483  0.275821  0.351068  0.202483    ...        0.0   \n",
       "distorting    0.009449  0.140437  0.220822  0.009449    ...        0.0   \n",
       "his           0.307721  0.589037  0.460539  0.307721    ...        0.0   \n",
       "evidence      0.209467  0.409072  0.629995  0.209467    ...        0.0   \n",
       ".             0.292410  0.311351  0.219035  0.292410    ...        0.0   \n",
       "\n",
       "               accused       his   brother        of  deliberately  \\\n",
       "ROOT          0.000000  0.000000  0.000000  0.000000      0.000000   \n",
       "Amrozi        0.000000  0.000000  0.000000  0.000000      0.000000   \n",
       "accused       1.000000  0.409809  0.430317  0.245755      0.492152   \n",
       "his           0.409809  1.000000  0.595102  0.470308      0.375484   \n",
       "brother       0.430317  0.595102  1.000000  0.218296      0.202813   \n",
       ",             0.154774  0.247196  0.260554  0.246289      0.178351   \n",
       "whom          0.503349  0.543793  0.561806  0.362452      0.402099   \n",
       "he            0.454249  0.791888  0.579133  0.374885      0.455827   \n",
       "called        0.313714  0.409235  0.322105  0.401833      0.246508   \n",
       "\"             0.177370  0.307721  0.165423  0.237327      0.202483   \n",
       "the           0.245612  0.589037  0.276650  0.713939      0.275821   \n",
       "witness       0.495963  0.460539  0.382124  0.333289      0.351068   \n",
       "\"             0.177370  0.307721  0.165423  0.237327      0.202483   \n",
       ",             0.154774  0.247196  0.260554  0.246289      0.178351   \n",
       "of            0.245755  0.470308  0.218296  1.000000      0.162817   \n",
       "deliberately  0.492152  0.375484  0.202813  0.162817      1.000000   \n",
       "distorting    0.235543  0.162476 -0.017952  0.109792      0.500688   \n",
       "his           0.409809  1.000000  0.595102  0.470308      0.375484   \n",
       "evidence      0.455700  0.372411  0.181388  0.390543      0.408713   \n",
       ".             0.089694  0.293258  0.244569  0.314684      0.132542   \n",
       "\n",
       "              distorting       his  evidence         .  \n",
       "ROOT            0.000000  0.000000  0.000000  0.000000  \n",
       "Amrozi          0.000000  0.000000  0.000000  0.000000  \n",
       "accused         0.235543  0.409809  0.455700  0.089694  \n",
       "his             0.162476  1.000000  0.372411  0.293258  \n",
       "brother        -0.017952  0.595102  0.181388  0.244569  \n",
       ",              -0.007885  0.247196  0.218267  0.421524  \n",
       "whom            0.065883  0.543793  0.391814  0.222853  \n",
       "he              0.101640  0.791888  0.417391  0.419956  \n",
       "called         -0.009064  0.409235  0.295163  0.251584  \n",
       "\"               0.009449  0.307721  0.209467  0.292410  \n",
       "the             0.140437  0.589037  0.409072  0.311351  \n",
       "witness         0.220822  0.460539  0.629995  0.219035  \n",
       "\"               0.009449  0.307721  0.209467  0.292410  \n",
       ",              -0.007885  0.247196  0.218267  0.421524  \n",
       "of              0.109792  0.470308  0.390543  0.314684  \n",
       "deliberately    0.500688  0.375484  0.408713  0.132542  \n",
       "distorting      1.000000  0.162476  0.285325 -0.002664  \n",
       "his             0.162476  1.000000  0.372411  0.293258  \n",
       "evidence        0.285325  0.372411  1.000000  0.225468  \n",
       ".              -0.002664  0.293258  0.225468  1.000000  \n",
       "\n",
       "[20 rows x 21 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = node_matcher.get_pandas_matrix()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph 1  =>   Graph 2\n",
      "ROOT    =>   ROOT\n",
      "Amrozi    =>   Amrozi\n",
      "accused    =>   accused\n",
      "his    =>   his\n",
      "brother    =>   brother\n",
      ",    =>   ,\n",
      "\"    =>   \"\n",
      "the    =>   the\n",
      "witness    =>   witness\n",
      "\"    =>   \"\n",
      "of    =>   of\n",
      "deliberately    =>   deliberately\n",
      "distorting    =>   distorting\n",
      "his    =>   his\n",
      "evidence    =>   evidence\n",
      ".    =>   .\n",
      "Similarity score 0.2060365109145597\n"
     ]
    }
   ],
   "source": [
    "node_matcher.print_matched_nodes()\n",
    "g1, g2 = node_matcher.get_converted_graphs()\n",
    "score = compare_graphs(g1, g2)\n",
    "print(f\"Similarity score {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [10, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkMAAAI1CAYAAADVQv5HAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7670845eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nx.draw_networkx(g1, with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_scores(limit=10):\n",
    "  result = []\n",
    "  for i in range(limit):\n",
    "    s1 = data[0][0][i]\n",
    "    s2 = data[0][1][i]\n",
    "    label = data[1][i]\n",
    "    graph1 = get_dependancy_graph(s1, False)\n",
    "    graph2 = get_dependancy_graph(s2, False)\n",
    "    node_matcher = HungarianGraphNodesMatcher(graph1, graph2, 0.8)  \n",
    "    g1, g2 = node_matcher.get_converted_graphs()\n",
    "    score = compare_graphs(g1, g2)\n",
    "    result.append((s1, s2, label, score))\n",
    "  return result\n",
    "\n",
    "result = calculate_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 1  |   Score 0.18164626701212067\n",
      "Label 0  |   Score 0.43574108818011253\n",
      "Label 1  |   Score 0.2671296296296296\n",
      "Label 0  |   Score 0.3958450046685341\n",
      "Label 1  |   Score 0.3988475177304965\n",
      "Label 1  |   Score 0.2107481060606061\n",
      "Label 0  |   Score 0.5372405372405372\n",
      "Label 1  |   Score 0.19363553113553114\n",
      "Label 0  |   Score 0.4445767195767195\n",
      "Label 1  |   Score 0.21071428571428572\n"
     ]
    }
   ],
   "source": [
    "for d in result:\n",
    "  print (f\"Label {d[2]}  |   Score {d[3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prepared_data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DataGenerator:\n",
    "  @classmethod\n",
    "  def get_train_data(cls):\n",
    "    [sent1_train, sent2_train], label_train = load_data(_preprocess_sentence=None, _train=True, _test=False)\n",
    "    return [\n",
    "      {\"s1\": item[0], \"s2\": item[1], \"label\": item[2]}\n",
    "      for item in zip(sent1_train, sent2_train, label_train)       \n",
    "    ]\n",
    "\n",
    "  @classmethod\n",
    "  def get_test_data(cls):\n",
    "    [sent1_test, sent2_test], label_test = load_data(_preprocess_sentence=None, _train=False, _test=True)\n",
    "    \n",
    "    return [\n",
    "      {\"s1\": item[0], \"s2\": item[1], \"label\": item[2]}\n",
    "      for item in zip(sent1_test, sent2_test, label_test)       \n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_data(feature_generator, force=False, limit=100000):\n",
    "  feature_name = feature_generator.NAME\n",
    "  global prepared_data\n",
    "  if feature_name not in prepared_data or force:\n",
    "    train_data = DataGenerator.get_train_data()\n",
    "    test_data = DataGenerator.get_test_data()\n",
    "    train_X = [\n",
    "      feature_generator.get_features(item['s1'], item['s2'])\n",
    "      for item in tqdm(train_data)\n",
    "    ]\n",
    "    train_Y = [item['label'] for item in train_data]\n",
    "\n",
    "    test_X = [\n",
    "      feature_generator.get_features(item['s1'], item['s2'])\n",
    "      for item in tqdm(test_data)\n",
    "    ]\n",
    "    test_Y = [item['label'] for item in test_data]\n",
    "    \n",
    "    features = {}\n",
    "    features['train_X'] = train_X\n",
    "    features['train_Y'] = train_Y\n",
    "    features['test_X'] = test_X\n",
    "    features['test_Y'] = test_Y\n",
    "    prepared_data[feature_name] = features\n",
    "\n",
    "def verbose_data(feature_generator, limit=10, offset=0):\n",
    "    train_data = DataGenerator.get_train_data()\n",
    "    for item in train_data[offset:limit]:\n",
    "      features = feature_generator.get_features(item['s1'], item['s2'])\n",
    "      print(item['s1'])\n",
    "      print(item['s2'])\n",
    "      print(f\"Label {item['label']}\")\n",
    "      print(features)\n",
    "      print(\"*\"* 8)\n",
    "\n",
    "def get_metrics(feature_generator, classificator, force=False, limit=None, features_bitmap=None):\n",
    "  prepare_data(feature_generator, force, limit)\n",
    "  global prepared_data\n",
    "  feature_name = feature_generator.NAME\n",
    "\n",
    "  train_X = np.array(prepared_data[feature_name]['train_X'])\n",
    "  test_X = np.array(prepared_data[feature_name]['test_X'])\n",
    "  if features_bitmap is not None:\n",
    "    train_X = train_X[:, features_bitmap]\n",
    "    test_X = test_X[:, features_bitmap]\n",
    "\n",
    "  classificator.fit(\n",
    "    train_X,\n",
    "    prepared_data[feature_name]['train_Y']\n",
    "  )\n",
    "\n",
    "  test_Y_predicted = classificator.predict(test_X)\n",
    "\n",
    "  precision = precision_score(\n",
    "    prepared_data[feature_name]['test_Y'],\n",
    "    test_Y_predicted\n",
    "  )\n",
    "  recall = recall_score(\n",
    "    prepared_data[feature_name]['test_Y'],\n",
    "    test_Y_predicted\n",
    "  )\n",
    "  f1 = f1_score(\n",
    "    prepared_data[feature_name]['test_Y'],\n",
    "    test_Y_predicted\n",
    "  )\n",
    "  accuracy = accuracy_score(\n",
    "    prepared_data[feature_name]['test_Y'],\n",
    "    test_Y_predicted\n",
    "  )\n",
    "\n",
    "  return {\n",
    "    \"precision\" : round(precision * 100, 2),\n",
    "    \"recall\" : round(recall * 100, 2),\n",
    "    \"f1\" : round(f1 * 100, 2),\n",
    "    \"accuracy\" : round(accuracy * 100, 2),\n",
    "  }\n",
    "\n",
    "class BaselineFeatureGenerator:\n",
    "  NAME = 'Baseline'\n",
    "\n",
    "  def get_features(self, s1, s2):\n",
    "    return np.array([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def base_classification_test(feature_generator, verbose=True, features_bitmap=None, force_feature_update=False):\n",
    "  if force_feature_update:\n",
    "    prepare_data(feature_generator, True, 10000)\n",
    "\n",
    "  classificators = [\n",
    "    {\n",
    "      \"name\": \"SVC\",\n",
    "      \"classificator\": SVC(),\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"SVC(kernel = 'rbf', random_state = 0)\",\n",
    "      \"classificator\": SVC(kernel = 'rbf', random_state = 0),\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"SVC(probability=True)\",\n",
    "      \"classificator\": SVC(probability=True),\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"NuSVC\",\n",
    "      \"classificator\": NuSVC(),\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"LinearSVC\",\n",
    "      \"classificator\": LinearSVC(),\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"DecisionTreeClassifier\",\n",
    "      \"classificator\": DecisionTreeClassifier(),\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"DecisionTreeClassifier(criterion='entropy',random_state=0)\",\n",
    "      \"classificator\": DecisionTreeClassifier(criterion=\"entropy\",random_state=0),\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"ExtraTreeClassifier\",\n",
    "      \"classificator\": ExtraTreeClassifier(),\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"KNeighborsClassifier\",\n",
    "      \"classificator\": KNeighborsClassifier(),\n",
    "    },\n",
    "    {\n",
    "      \"name\": \" KNeighborsClassifier(n_neighbors=5,metric='minkowski',p=2)\",\n",
    "      \"classificator\":  KNeighborsClassifier(n_neighbors=5,metric='minkowski',p=2),\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"GaussianNB\",\n",
    "      \"classificator\": GaussianNB(),\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"BernoulliNB\",\n",
    "      \"classificator\": BernoulliNB(),\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"Perceptron\",\n",
    "      \"classificator\": Perceptron(),\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"SGDClassifier\",\n",
    "      \"classificator\": SGDClassifier(),\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"RandomForestClassifier\",\n",
    "      \"classificator\": RandomForestClassifier(),\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"RandomForestClassifier(n_estimators=1000,criterion='entropy',random_state=0)\",\n",
    "      \"classificator\": RandomForestClassifier(n_estimators=1000,criterion='entropy',random_state=0),\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"LogisticRegressionCV\",\n",
    "      \"classificator\": LogisticRegressionCV(),\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"PassiveAggressiveClassifier\",\n",
    "      \"classificator\": PassiveAggressiveClassifier(),\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"RidgeClassifierCV\",\n",
    "      \"classificator\": RidgeClassifierCV(),\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"LogisticRegression(max_iter = 500000)\",\n",
    "      \"classificator\": LogisticRegression(max_iter = 500000),\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"GradientBoostingClassifier\",\n",
    "      \"classificator\": GradientBoostingClassifier(),\n",
    "    },\n",
    "  ]\n",
    "  res = []\n",
    "  for item in tqdm(classificators):\n",
    "    score = get_metrics(feature_generator, item[\"classificator\"], features_bitmap=features_bitmap)\n",
    "    res.append({\"classificator\": item[\"name\"], \"score\": score})\n",
    "\n",
    "  if verbose:\n",
    "    for r in res:\n",
    "      print(r[\"classificator\"])\n",
    "      print(r[\"score\"])\n",
    "  return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_all_bitmasks(length):\n",
    "  res = []\n",
    "  for i in range(1, 2 ** length):\n",
    "     bitmask = np.zeros(length)\n",
    "     n = int(i)\n",
    "     pos = 0\n",
    "     while n > 0:\n",
    "       bitmask[pos] = n % 2\n",
    "       pos += 1\n",
    "       n = n // 2\n",
    "     bitmask = [b == 1 for b in bitmask]\n",
    "     res.append(bitmask)\n",
    "  return res\n",
    "\n",
    "\n",
    "def feature_selection(feature_generator, top_results=5, verbose=False, bitmask_amount=None):\n",
    "  global prepared_data\n",
    "  feature_name = feature_generator.NAME\n",
    "  assert feature_name in prepared_data\n",
    "  length = len(prepared_data[feature_generator.NAME][\"test_X\"][0])\n",
    "  bitmasks = get_all_bitmasks(length)\n",
    "  results = []\n",
    "  if bitmask_amount is not None:\n",
    "    random.shuffle(bitmasks)\n",
    "    bitmasks = random.sample(bitmasks, bitmask_amount)\n",
    "  for bitmask in tqdm(bitmasks):\n",
    "    if verbose:\n",
    "      print(f\"mask {bitmask}\")\n",
    "    scores = base_classification_test(feature_generator, features_bitmap=bitmask, verbose=False)\n",
    "    for score in scores:\n",
    "      if verbose:\n",
    "        print(f\"classificator {score['classificator']}\")\n",
    "        print(f\"score {score['score']}\")\n",
    "        \n",
    "      results.append({\n",
    "        \"mask\": bitmask, \n",
    "        \"score\": score[\"score\"], \n",
    "        \"classificator\": score[\"classificator\"]\n",
    "      })\n",
    "  \n",
    "  results = sorted(results, key=lambda k: k[\"score\"][\"accuracy\"], reverse=True)\n",
    "  print(\"Top Accuracy\")\n",
    "  for r in results[:top_results]:\n",
    "    print(f\"{r['classificator']} {r['score']} {r['mask']}\")\n",
    "  \n",
    "  results = sorted(results, key=lambda k: k[\"score\"][\"f1\"], reverse=True)\n",
    "  print(\"Top F1\")\n",
    "  for r in results[:top_results]:\n",
    "    print(f\"{r['classificator']} {r['score']} {r['mask']}\")\n",
    "\n",
    "# Uncomment to run feature selection\n",
    "# feature_selection(path_feature_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class HungarianGraphFeatureGenerator:\n",
    "  NAME = 'HungarianGraph'\n",
    "\n",
    "  def get_features_for_graphs(self, node_matcher, similarity):\n",
    "    node_matcher.set_threshold(similarity)\n",
    "    g1, g2 = node_matcher.get_converted_graphs()\n",
    "    score_normalized = compare_graphs(g1, g2, False, True)\n",
    "    score_raw = compare_graphs(g1, g2, False, False)\n",
    "    return np.array([score_normalized, score_raw])\n",
    "\n",
    "  def get_features(self, s1, s2):\n",
    "    g1 = get_dependancy_graph(s1, False)\n",
    "    g2 = get_dependancy_graph(s2, False)\n",
    "    node_matcher = HungarianGraphNodesMatcher(g1, g2, 0.9)\n",
    "    \n",
    "    features = np.array([])\n",
    "    \n",
    "    for similarity in [0.8, 0.85,  0.90, 0.95]:\n",
    "      features = np.append(features, self.get_features_for_graphs(node_matcher, similarity))\n",
    "    \n",
    "    return features\n",
    "\n",
    "hungarian_feature_generator = HungarianGraphFeatureGenerator()\n",
    "\n",
    "# It gives {'precision': 73.99, 'recall': 89.54, 'f1': 81.03, 'accuracy': 72.12}\n",
    "# on LinearSVC()\n",
    "# LinearSVC {'precision': 71.27, 'recall': 95.82, 'f1': 81.74, 'accuracy': 71.54} \n",
    "# [False, False, False, False, False, True, True, True]\n",
    "# LinearSVC {'precision': 71.3, 'recall': 95.73, 'f1': 81.73, 'accuracy': 71.54} \n",
    "# [True, False, False, True, False, False, False, True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verbose_data(hungarian_feature_generator)\n",
    "# base_classification_test(hungarian_feature_generator, force_feature_update=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_selection(hungarian_feature_generator, verbose=False, bitmask_amount=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_selection(hungarian_feature_generator, verbose=False, bitmask_amount=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amrozi accused his brother, whom he called \"the witness\", of deliberately distorting his evidence.\n",
      "Referring to him as only \"the witness\", Amrozi accused his brother of deliberately distorting his evidence.\n",
      "Label 1\n",
      "[0.20603651 8.44749695 0.20603651 8.44749695 0.20603651 8.44749695\n",
      " 0.20603651 8.44749695]\n",
      "********\n",
      "Yucaipa owned Dominick's before selling the chain to Safeway in 1998 for $2.5 billion.\n",
      "Yucaipa bought Dominick's in 1995 for $693 million and sold it to Safeway for $1.8 billion in 1998.\n",
      "Label 0\n",
      "[ 0.43574109 17.86538462  0.43574109 17.86538462  0.43574109 17.86538462\n",
      "  0.43574109 17.86538462]\n",
      "********\n",
      "They had published an advertisement on the Internet on June 10, offering the cargo for sale, he added.\n",
      "On June 10, the ship's owners had published an advertisement on the Internet, offering the explosives for sale.\n",
      "Label 1\n",
      "[ 0.26712963 12.02083333  0.26712963 12.02083333  0.26712963 12.02083333\n",
      "  0.26712963 12.02083333]\n",
      "********\n",
      "Around 0335 GMT, Tab shares were up 19 cents, or 4.4%, at A$4.56, having earlier set a record high of A$4.57.\n",
      "Tab shares jumped 20 cents, or 4.6%, to set a record closing high at A$4.57.\n",
      "Label 0\n",
      "[ 0.42721755 21.78809524  0.42721755 21.78809524  0.42721755 21.78809524\n",
      "  0.42721755 21.78809524]\n",
      "********\n",
      "The stock rose $2.11, or about 11 percent, to close Friday at $21.51 on the New York Stock Exchange.\n",
      "PG&E Corp. shares jumped $1.63 or 8 percent to $21.03 on the New York Stock Exchange on Friday.\n",
      "Label 1\n",
      "[ 0.41445035 19.47916667  0.41445035 19.47916667  0.41445035 19.47916667\n",
      "  0.41445035 19.47916667]\n",
      "********\n",
      "Revenue in the first quarter of the year dropped 15 percent from the same period a year earlier.\n",
      "With the scandal hanging over Stewart's company, revenue the first quarter of the year dropped 15 percent from the same period a year earlier.\n",
      "Label 1\n",
      "[ 0.21074811 10.11590909  0.21074811 10.11590909  0.21074811 10.11590909\n",
      "  0.21074811 10.11590909]\n",
      "********\n",
      "The Nasdaq had a weekly gain of 17.27, or 1.2 percent, closing at 1,520.15 on Friday.\n",
      "The tech-laced Nasdaq Composite .IXIC rallied 30.46 points, or 2.04 percent, to 1,520.15.\n",
      "Label 0\n",
      "[ 0.53724054 20.95238095  0.53724054 20.95238095  0.53724054 20.95238095\n",
      "  0.53724054 20.95238095]\n",
      "********\n",
      "The DVD-CCA then appealed to the state Supreme Court.\n",
      "The DVD CCA appealed that decision to the U.S. Supreme Court.\n",
      "Label 1\n",
      "[0.19363553 5.03452381 0.19363553 5.03452381 0.19363553 5.03452381\n",
      " 0.19363553 5.03452381]\n",
      "********\n",
      "That compared with $35.18 million, or 24 cents per share, in the year-ago period.\n",
      "Earnings were affected by a non-recurring $8 million tax benefit in the year-ago period.\n",
      "Label 0\n",
      "[ 0.44457672 18.67222222  0.44457672 18.67222222  0.44457672 18.67222222\n",
      "  0.44457672 18.67222222]\n",
      "********\n",
      "He said the foodservice pie business doesn't fit the company's long-term growth strategy.\n",
      "\"The foodservice pie business does not fit our long-term growth strategy.\n",
      "Label 1\n",
      "[0.25595238 8.95833333 0.25595238 8.95833333 0.25595238 8.95833333\n",
      " 0.25595238 8.95833333]\n",
      "********\n"
     ]
    }
   ],
   "source": [
    "# Uncomment to test\n",
    "verbose_data(hungarian_feature_generator)\n",
    "\n",
    "# prepare_data(hungarian_feature_generator, True, 100000)\n",
    "# base_classification_test(hungarian_feature_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class HungarianNodeFeatureGenerator:\n",
    "  NAME = 'HungarianNode'\n",
    "\n",
    "  def get_features_for_graphs(self, node_matcher, similarity):\n",
    "    node_matcher.set_threshold(similarity)\n",
    "    g1, g2 = node_matcher.get_converted_graphs()\n",
    "    n1, n2 = len(g1), len(g2)\n",
    "    num_matched_nodes = len(node_matcher.graph1_to_graph2)\n",
    "    percent_matched = num_matched_nodes * 2. / (n1 + n2)\n",
    "    features = np.array([n1, n2, percent_matched])\n",
    "    return features\n",
    "\n",
    "  def get_features(self, s1, s2):\n",
    "    g1 = get_dependancy_graph(s1, False)\n",
    "    g2 = get_dependancy_graph(s2, False)\n",
    "    node_matcher = HungarianGraphNodesMatcher(g1, g2, 0.9)\n",
    "    \n",
    "    features = np.array([])\n",
    "    \n",
    "    for similarity in [0.8, 0.85,  0.90, 0.95]:\n",
    "      features = np.append(features, self.get_features_for_graphs(node_matcher, similarity))\n",
    "    \n",
    "    return features\n",
    "\n",
    "#   def get_features(self, s1, s2):\n",
    "#     graph1 = get_dependancy_graph(s1, False)\n",
    "#     graph2 = get_dependancy_graph(s2, False)\n",
    "#     node_matcher = HungarianGraphNodesMatcher(graph1, graph2, 0.9)\n",
    "    \n",
    "#     g1, g2 = node_matcher.get_converted_graphs()\n",
    "#     n1, n2 = len(g1), len(g2)\n",
    "#     num_matched_nodes = len(node_matcher.graph1_to_graph2)\n",
    "#     percent_matched = num_matched_nodes * 2. / (n1 + n2)\n",
    "#     features = np.array([n1, n2, percent_matched])\n",
    "#     return features\n",
    "\n",
    "hungarian_node_feature_generator = HungarianNodeFeatureGenerator()\n",
    "# It gives {'precision': 74.5, 'recall': 90.67, 'f1': 81.79, 'accuracy': 73.16}\n",
    "# on SGDClassifier(),\n",
    "\n",
    "\n",
    "# LinearSVC {'precision': 73.62, 'recall': 92.94, 'f1': 82.16, 'accuracy': 73.16} \n",
    "# [False, False, False, \n",
    "# True, False, True, \n",
    "# False, True, False,\n",
    "# True, False, True]\n",
    "# Perceptron {'precision': 72.96, 'recall': 94.33, 'f1': 82.28, 'accuracy': 72.99} [True, False, True, False, False, True, True, False, False, True, False, True]\n",
    "# LinearSVC {'precision': 73.52, 'recall': 93.2, 'f1': 82.2, 'accuracy': 73.16} \n",
    "# [False, True, False, \n",
    "# False, False, True, \n",
    "# False, False, False, \n",
    "# False, False, True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amrozi accused his brother, whom he called \"the witness\", of deliberately distorting his evidence.\n",
      "Referring to him as only \"the witness\", Amrozi accused his brother of deliberately distorting his evidence.\n",
      "Label 1\n",
      "[20.        21.         0.7804878]\n",
      "********\n",
      "Yucaipa owned Dominick's before selling the chain to Safeway in 1998 for $2.5 billion.\n",
      "Yucaipa bought Dominick's in 1995 for $693 million and sold it to Safeway for $1.8 billion in 1998.\n",
      "Label 0\n",
      "[18.         23.          0.58536585]\n",
      "********\n",
      "They had published an advertisement on the Internet on June 10, offering the cargo for sale, he added.\n",
      "On June 10, the ship's owners had published an advertisement on the Internet, offering the explosives for sale.\n",
      "Label 1\n",
      "[22.  23.   0.8]\n",
      "********\n",
      "Around 0335 GMT, Tab shares were up 19 cents, or 4.4%, at A$4.56, having earlier set a record high of A$4.57.\n",
      "Tab shares jumped 20 cents, or 4.6%, to set a record closing high at A$4.57.\n",
      "Label 0\n",
      "[30.         21.          0.66666667]\n",
      "********\n",
      "The stock rose $2.11, or about 11 percent, to close Friday at $21.51 on the New York Stock Exchange.\n",
      "PG&E Corp. shares jumped $1.63 or 8 percent to $21.03 on the New York Stock Exchange on Friday.\n",
      "Label 1\n",
      "[25.         22.          0.59574468]\n",
      "********\n",
      "Revenue in the first quarter of the year dropped 15 percent from the same period a year earlier.\n",
      "With the scandal hanging over Stewart's company, revenue the first quarter of the year dropped 15 percent from the same period a year earlier.\n",
      "Label 1\n",
      "[20.         28.          0.79166667]\n",
      "********\n",
      "The Nasdaq had a weekly gain of 17.27, or 1.2 percent, closing at 1,520.15 on Friday.\n",
      "The tech-laced Nasdaq Composite .IXIC rallied 30.46 points, or 2.04 percent, to 1,520.15.\n",
      "Label 0\n",
      "[20.         19.          0.46153846]\n",
      "********\n",
      "The DVD-CCA then appealed to the state Supreme Court.\n",
      "The DVD CCA appealed that decision to the U.S. Supreme Court.\n",
      "Label 1\n",
      "[13.         13.          0.76923077]\n",
      "********\n",
      "That compared with $35.18 million, or 24 cents per share, in the year-ago period.\n",
      "Earnings were affected by a non-recurring $8 million tax benefit in the year-ago period.\n",
      "Label 0\n",
      "[21.         21.          0.47619048]\n",
      "********\n",
      "He said the foodservice pie business doesn't fit the company's long-term growth strategy.\n",
      "\"The foodservice pie business does not fit our long-term growth strategy.\n",
      "Label 1\n",
      "[19.         16.          0.74285714]\n",
      "********\n"
     ]
    }
   ],
   "source": [
    "verbose_data(hungarian_node_feature_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Uncomment to test\n",
    "# prepare_data(hungarian_node_feature_generator, True, 100000)\n",
    "# base_classification_test(hungarian_node_feature_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GraphTraversal:\n",
    "  def __init__(self, graph=None, sentance=None):\n",
    "    assert graph is not None or sentance is not None\n",
    "    if graph is not None:\n",
    "      self.g = graph\n",
    "    else:\n",
    "      self.g = GraphBuilder.build_nx_graph_from_sentance(sentance)\n",
    "  \n",
    "  def get_paths_from_root_to_leafs(self, root=0):\n",
    "     #                 node. parent. path.      \n",
    "    res, stack = [], [(root, None, [])]\n",
    "    while stack:\n",
    "        node, parent, path = stack.pop()\n",
    "        path.append(node)\n",
    "        neighbours = [n for n, _ in self.g.adj[node].items()]\n",
    "        if len(neighbours) == 1 and neighbours[0] == parent:\n",
    "            res.append(path)\n",
    "        for n in neighbours:\n",
    "          if n == parent:\n",
    "            continue\n",
    "          stack.append((n, node, path[:]))\n",
    "    return res\n",
    "    \n",
    "  def get_all_paths_with_len(self, root=0, length=0):\n",
    "    \"\"\"\n",
    "    Return list of pathes with specificified len + 1.\n",
    "    The start is every node.\n",
    "    \n",
    "    For the tree:\n",
    "           1\n",
    "         2   3\n",
    "       5\n",
    "         6\n",
    "         \n",
    "    Len = 2:\n",
    "    [1, 2, 5]\n",
    "    [2, 5, 6]\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    #                  node. parent. path.                  \n",
    "    res, stack = [], [(root, None, [])]\n",
    "    started_new_path = {root}\n",
    "    while stack:\n",
    "        node, parent, path = stack.pop()\n",
    "        path.append(node)\n",
    "        neighbours = [n for n, _ in self.g.adj[node].items()]\n",
    "        if len(path) == length + 1:\n",
    "          res.append(path)\n",
    "        for n in neighbours:\n",
    "          if n == parent:\n",
    "            continue\n",
    "          if len(path) < length + 1:\n",
    "            stack.append((n, node, path[:]))\n",
    "          if n not in started_new_path:\n",
    "            stack.append((n, node, []))\n",
    "            started_new_path.add(n)\n",
    "        \n",
    "    return res\n",
    "\n",
    "  def get_all_subtrees_with_depth(self, root=0, parent=None, length=0):\n",
    "    \"\"\"\n",
    "      Return array of subtrees.\n",
    "      Each subtree is defined by indexes of their nodes.\n",
    "    \"\"\"\n",
    "    #                  node. parent. distance.  \n",
    "    res, stack = [], [(root, parent, 0)]\n",
    "    reached_depth = False\n",
    "    while stack:\n",
    "        node, _parent, distance = stack.pop()\n",
    "        res.append(node)\n",
    "        if distance >= length:\n",
    "          reached_depth = True\n",
    "          continue\n",
    "        neighbours = [n for n, _ in self.g.adj[node].items()]\n",
    "        for n in neighbours:\n",
    "          if n == _parent:\n",
    "            continue\n",
    "          stack.append((n, node, distance + 1))\n",
    "      \n",
    "    all_subtrees = []\n",
    "    if reached_depth:\n",
    "      all_subtrees.append(res)\n",
    "    for n, _ in self.g.adj[root].items():\n",
    "      if n == parent:\n",
    "        continue\n",
    "      all_subtrees += self.get_all_subtrees_with_depth(n, root, length)\n",
    "\n",
    "    return all_subtrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_graphs(graphs, word_labels=False):\n",
    "  for g in graphs:\n",
    "     fig, ax = plt.subplots(1, 1)\n",
    "     if word_labels:\n",
    "       nx.draw(g, arrowstyle=\"->\", with_labels=True, pos=nx.kamada_kawai_layout(g), ax=ax, labels={n: g.nodes[n]['node'] for n in g.nodes})\n",
    "     else:\n",
    "       nx.draw(g, with_labels=True, pos=nx.kamada_kawai_layout(g), ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GraphFeatures:\n",
    "  def __init__(self, graph=None, sentance=None):\n",
    "    assert graph is not None or sentance is not None\n",
    "    if graph is not None:\n",
    "      self.g = graph\n",
    "    else:\n",
    "      self.g = GraphBuilder.build_nx_graph_from_sentance(sentance)\n",
    "  \n",
    "  def get_path_features(self, length=0):\n",
    "    traversal = GraphTraversal(graph=self.g)\n",
    "    pathes = traversal.get_all_paths_with_len(length=length)\n",
    "    \n",
    "    pathes_with_nodes = [\n",
    "      [self.g.nodes[node] for node in path ]\n",
    "      for path in pathes \n",
    "    ]\n",
    "\n",
    "    filtered_pathes_with_nodes = [\n",
    "      path \n",
    "      for path in pathes_with_nodes \n",
    "      if all(\n",
    "          node[\"token\"] is not None and node[\"token\"].has_vector \n",
    "          for node in path\n",
    "      )\n",
    "    ]\n",
    "\n",
    "    aggregated_vectors = [\n",
    "       sum([node[\"token\"].vector for node in path])\n",
    "       for path in filtered_pathes_with_nodes\n",
    "    ]\n",
    "\n",
    "    return aggregated_vectors\n",
    "\n",
    "  def get_subtree_features(self, length=0, remove_tree_without_vector=True, remove_stop_words=False, idf_model=None):\n",
    "    \"\"\"\n",
    "    Return list of vectors, where each vector represent one subtree.\n",
    "    Subtree is created by aggregating vectors in this subtree.\n",
    "\n",
    "    Keyword arguments:\n",
    "    length -- the real part (default 0.0)\n",
    "    remove_tree_without_vector -- remove whole tree if at least one vector inside it \n",
    "      is empty (non common word)\n",
    "    remove_stop_words - remove word from tree if it is stop word\n",
    "    idf_model - If present, multiply vector by word idf\n",
    "    \"\"\"\n",
    "    traversal = GraphTraversal(graph=self.g)\n",
    "    subtrees = traversal.get_all_subtrees_with_depth(length=length)\n",
    "    \n",
    "    subtrees_with_nodes = [\n",
    "      [self.g.nodes[node] for node in subtree ]\n",
    "      for subtree in subtrees\n",
    "    ]\n",
    "\n",
    "    if remove_tree_without_vector:\n",
    "      subtrees_with_nodes = [\n",
    "        subtree \n",
    "        for subtree in subtrees_with_nodes \n",
    "        if all(\n",
    "            node[\"token\"] is not None and node[\"token\"].has_vector \n",
    "            for node in subtree\n",
    "        )\n",
    "      ]\n",
    "\n",
    "    idf = lambda word: 1\n",
    "    \n",
    "    if idf_model is not None:\n",
    "        idf = lambda word: idf_model.get_idf(word)\n",
    "    \n",
    "    aggregated_vectors = [\n",
    "       sum([\n",
    "          node[\"token\"].vector * idf(node[\"token\"])\n",
    "          for node in subtree \n",
    "          # If remove_tree_without_vector == false\n",
    "          if node[\"token\"] is not None and node[\"token\"].has_vector\n",
    "          and (not remove_stop_words or not node[\"token\"].is_stop)\n",
    "        ])\n",
    "       for subtree in subtrees_with_nodes\n",
    "    ]\n",
    "\n",
    "    # Filter empty vectors\n",
    "    aggregated_vectors = [\n",
    "      v\n",
    "      for v in aggregated_vectors\n",
    "      if not np.isscalar(v)\n",
    "    ]\n",
    "\n",
    "    return aggregated_vectors\n",
    "\n",
    "  def get_simple_edge_features(self):\n",
    "    \"\"\"\n",
    "    Return list of edges\n",
    "    \"\"\"\n",
    "    edges = []\n",
    "    for (start_idx, end_idx, dependancy_type) in self.g.edges.data('dependancy_type'):\n",
    "        item = {}\n",
    "        item['start_idx'] = start_idx\n",
    "        item['end_idx'] = end_idx\n",
    "        item['dependancy_type'] = dependancy_type\n",
    "        item['start_node'] = self.g.nodes[start_idx]\n",
    "        item['end_node'] = self.g.nodes[end_idx]\n",
    "        edges.append(item)\n",
    "        \n",
    "    return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Vector:\n",
    "  @classmethod\n",
    "  def get_norm(cls, v):\n",
    "    total = (v ** 2).sum()\n",
    "    return np.sqrt(total) if total != 0 else 0\n",
    "\n",
    "  @classmethod\n",
    "  def similarity(cls, v1, v2):\n",
    "    v1_norm = cls.get_norm(v1)\n",
    "    v2_norm = cls.get_norm(v2)\n",
    "    if v1_norm == 0 or v1_norm == 0:\n",
    "      return 0.0\n",
    "    return (np.dot(v1, v2) / (v1_norm * v2_norm))\n",
    "\n",
    "class MatchFeatureVectors:\n",
    "  @classmethod\n",
    "  def match_feature_vectors(cls, features1, features2, similarity=0.8):\n",
    "    \"\"\"\n",
    "      This function tries to do the following:\n",
    "      1) For each vector in features1 try to find whether vector with good similarity exist in features2.\n",
    "      Return ammount of matched vectors.\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "\n",
    "    features1_norm = []\n",
    "    for v1 in features1:\n",
    "      for v2 in features2:\n",
    "        score = Vector.similarity(v1, v2)\n",
    "        if score > similarity:\n",
    "          count += 1\n",
    "          break\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nxv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "sample = get_sample(0)\n",
    "g1 = GraphBuilder.build_nx_graph_from_sentance(sample['s1'])\n",
    "g2 = GraphBuilder.build_nx_graph_from_sentance(sample['s2'])\n",
    "g_f1 = GraphFeatures(g1)\n",
    "g_f2 = GraphFeatures(g2)\n",
    "f1 = g_f1.get_subtree_features(length=1)\n",
    "f2 = g_f2.get_subtree_features(length=1)\n",
    "score = MatchFeatureVectors.match_feature_vectors(f1, f2, similarity=0.8)\n",
    "print (score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "sample = get_sample(0)\n",
    "g1 = GraphBuilder.build_nx_graph_from_sentance(sample['s1'])\n",
    "g2 = GraphBuilder.build_nx_graph_from_sentance(sample['s2'])\n",
    "g_f1 = GraphFeatures(g1)\n",
    "g_f2 = GraphFeatures(g2)\n",
    "f1 = g_f1.get_path_features(length=3)\n",
    "f2 = g_f2.get_path_features(length=3)\n",
    "score = MatchFeatureVectors.match_feature_vectors(f1, f2, similarity=0.8)\n",
    "print (score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PathFeatureGenerator:\n",
    "  NAME = 'PathSimilarity'\n",
    "\n",
    "  SIMILARITY = 0.8\n",
    "\n",
    "  def get_feature_for_length(self, g_f1, g_f2, length):\n",
    "    f1 = g_f1.get_path_features(length=length)\n",
    "    f2 = g_f2.get_path_features(length=length)\n",
    "    \n",
    "    score = MatchFeatureVectors.match_feature_vectors(f1, f2, similarity=self.SIMILARITY)\n",
    "\n",
    "    norm = len(f1) + len(f2)\n",
    "    return (score * 2.) / norm if norm != 0 else 0\n",
    "\n",
    "  def get_features(self, s1, s2):\n",
    "    g1 = GraphBuilder.build_nx_graph_from_sentance(s1)\n",
    "    g2 = GraphBuilder.build_nx_graph_from_sentance(s2)\n",
    "    \n",
    "    g_f1 = GraphFeatures(g1)\n",
    "    g_f2 = GraphFeatures(g2)\n",
    "\n",
    "    features = np.array([\n",
    "      self.get_feature_for_length(g_f1, g_f2, 0),\n",
    "      self.get_feature_for_length(g_f1, g_f2, 1),\n",
    "      self.get_feature_for_length(g_f1, g_f2, 2),\n",
    "      self.get_feature_for_length(g_f1, g_f2, 3),\n",
    "      self.get_feature_for_length(g_f1, g_f2, 4),\n",
    "    ])\n",
    "\n",
    "    return features\n",
    "\n",
    "path_feature_generator = PathFeatureGenerator()\n",
    "# SGDClassifier {'precision': 74.34, 'recall': 90.41, 'f1': 81.59, 'accuracy': 72.87} [True, False, True, False, True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amrozi accused his brother, whom he called \"the witness\", of deliberately distorting his evidence.\n",
      "Referring to him as only \"the witness\", Amrozi accused his brother of deliberately distorting his evidence.\n",
      "Label 1\n",
      "[0.86486486 0.74285714 1.03703704 1.         0.88888889]\n",
      "********\n",
      "Yucaipa owned Dominick's before selling the chain to Safeway in 1998 for $2.5 billion.\n",
      "Yucaipa bought Dominick's in 1995 for $693 million and sold it to Safeway for $1.8 billion in 1998.\n",
      "Label 0\n",
      "[0.56410256 0.54054054 0.53846154 0.70588235 0.75      ]\n",
      "********\n",
      "They had published an advertisement on the Internet on June 10, offering the cargo for sale, he added.\n",
      "On June 10, the ship's owners had published an advertisement on the Internet, offering the explosives for sale.\n",
      "Label 1\n",
      "[0.79069767 0.68292683 0.62068966 0.88888889 1.        ]\n",
      "********\n",
      "Around 0335 GMT, Tab shares were up 19 cents, or 4.4%, at A$4.56, having earlier set a record high of A$4.57.\n",
      "Tab shares jumped 20 cents, or 4.6%, to set a record closing high at A$4.57.\n",
      "Label 0\n",
      "[0.84444444 0.55813953 0.90322581 0.875      0.        ]\n",
      "********\n",
      "The stock rose $2.11, or about 11 percent, to close Friday at $21.51 on the New York Stock Exchange.\n",
      "PG&E Corp. shares jumped $1.63 or 8 percent to $21.03 on the New York Stock Exchange on Friday.\n",
      "Label 1\n",
      "[0.72727273 0.33333333 0.28571429 0.13333333 0.25      ]\n",
      "********\n",
      "Revenue in the first quarter of the year dropped 15 percent from the same period a year earlier.\n",
      "With the scandal hanging over Stewart's company, revenue the first quarter of the year dropped 15 percent from the same period a year earlier.\n",
      "Label 1\n",
      "[0.7826087  0.81818182 0.8        0.88       0.875     ]\n",
      "********\n",
      "The Nasdaq had a weekly gain of 17.27, or 1.2 percent, closing at 1,520.15 on Friday.\n",
      "The tech-laced Nasdaq Composite .IXIC rallied 30.46 points, or 2.04 percent, to 1,520.15.\n",
      "Label 0\n",
      "[0.41176471 0.         0.         0.         0.        ]\n",
      "********\n",
      "The DVD-CCA then appealed to the state Supreme Court.\n",
      "The DVD CCA appealed that decision to the U.S. Supreme Court.\n",
      "Label 1\n",
      "[0.75       0.90909091 0.8        0.85714286 0.        ]\n",
      "********\n",
      "That compared with $35.18 million, or 24 cents per share, in the year-ago period.\n",
      "Earnings were affected by a non-recurring $8 million tax benefit in the year-ago period.\n",
      "Label 0\n",
      "[0.45       0.57894737 0.64516129 0.4137931  0.58823529]\n",
      "********\n",
      "He said the foodservice pie business doesn't fit the company's long-term growth strategy.\n",
      "\"The foodservice pie business does not fit our long-term growth strategy.\n",
      "Label 1\n",
      "[0.84848485 0.83870968 0.90909091 1.23076923 0.        ]\n",
      "********\n"
     ]
    }
   ],
   "source": [
    "verbose_data(path_feature_generator, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that PathFeatureGenerator with more length are giving more stable (core) feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Uncomment to test\n",
    "# prepare_data(path_feature_generator, True)\n",
    "# base_classification_test(path_feature_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.1312923\n",
      "5.1312923\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Give it back! He pleaded.\")\n",
    "token = doc[0]\n",
    "vector = token.vector\n",
    "total = (vector ** 2).sum()\n",
    "norm = np.sqrt(total) if total != 0 else 0\n",
    "print(norm)\n",
    "print(token.vector_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample = get_sample(0)\n",
    "g1 = GraphBuilder.build_nx_graph_from_sentance(sample['s1'])\n",
    "g2 = GraphBuilder.build_nx_graph_from_sentance(sample['s2'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkMAAAI1CAYAAADVQv5HAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f72300fa7b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_graphs([g1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'is_fake': True, 'node': 'ROOT', 'token': None}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g1.nodes[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SimpleGraphVector:\n",
    "  @classmethod\n",
    "  def get_graph_vector(cls, g):\n",
    "    \"\"\"\n",
    "    g: networkx graph\n",
    "    Return vector\n",
    "    \"\"\"\n",
    "    vectors = []\n",
    "    for node_index in g.nodes:\n",
    "      node = g.nodes[node_index]\n",
    "      if node['token'] is not None and node['token'].has_vector:\n",
    "        attention = g.degree[node_index]\n",
    "        vectors.append(attention * np.array(node['token'].vector))\n",
    "    return sum(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SimpleGraphVectorFeatureGenerator:\n",
    "  \"\"\"\n",
    "  Compute only one feature - one vector of the whole tree\n",
    "  \"\"\"\n",
    "  NAME = 'SimpleGraphVectorFeatureGenerator'\n",
    "\n",
    "  def get_features(self, s1, s2):\n",
    "    g1 = GraphBuilder.build_nx_graph_from_sentance(s1)\n",
    "    g2 = GraphBuilder.build_nx_graph_from_sentance(s2)\n",
    "    \n",
    "    v1 = SimpleGraphVector.get_graph_vector(g1)\n",
    "    v2 = SimpleGraphVector.get_graph_vector(g2)\n",
    "\n",
    "    features = np.array([\n",
    "      Vector.similarity(v1, v2)\n",
    "    ])\n",
    "\n",
    "    return features\n",
    "\n",
    "simple_graph_vector_feature_generator = SimpleGraphVectorFeatureGenerator()\n",
    "# GaussianNB {'precision': 71.35, 'recall': 92.5, 'f1': 80.56, 'accuracy': 70.32}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Uncomment to test\n",
    "# prepare_data(simple_graph_vector_feature_generator, True, 10000)\n",
    "# base_classification_test(simple_graph_vector_feature_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amrozi accused his brother, whom he called \"the witness\", of deliberately distorting his evidence.\n",
      "Referring to him as only \"the witness\", Amrozi accused his brother of deliberately distorting his evidence.\n",
      "Label 1\n",
      "[0.9749242]\n",
      "********\n",
      "Yucaipa owned Dominick's before selling the chain to Safeway in 1998 for $2.5 billion.\n",
      "Yucaipa bought Dominick's in 1995 for $693 million and sold it to Safeway for $1.8 billion in 1998.\n",
      "Label 0\n",
      "[0.92126673]\n",
      "********\n",
      "They had published an advertisement on the Internet on June 10, offering the cargo for sale, he added.\n",
      "On June 10, the ship's owners had published an advertisement on the Internet, offering the explosives for sale.\n",
      "Label 1\n",
      "[0.9578174]\n",
      "********\n",
      "Around 0335 GMT, Tab shares were up 19 cents, or 4.4%, at A$4.56, having earlier set a record high of A$4.57.\n",
      "Tab shares jumped 20 cents, or 4.6%, to set a record closing high at A$4.57.\n",
      "Label 0\n",
      "[0.92144954]\n",
      "********\n",
      "The stock rose $2.11, or about 11 percent, to close Friday at $21.51 on the New York Stock Exchange.\n",
      "PG&E Corp. shares jumped $1.63 or 8 percent to $21.03 on the New York Stock Exchange on Friday.\n",
      "Label 1\n",
      "[0.8688785]\n",
      "********\n",
      "Revenue in the first quarter of the year dropped 15 percent from the same period a year earlier.\n",
      "With the scandal hanging over Stewart's company, revenue the first quarter of the year dropped 15 percent from the same period a year earlier.\n",
      "Label 1\n",
      "[0.9773977]\n",
      "********\n",
      "The Nasdaq had a weekly gain of 17.27, or 1.2 percent, closing at 1,520.15 on Friday.\n",
      "The tech-laced Nasdaq Composite .IXIC rallied 30.46 points, or 2.04 percent, to 1,520.15.\n",
      "Label 0\n",
      "[0.7365288]\n",
      "********\n",
      "The DVD-CCA then appealed to the state Supreme Court.\n",
      "The DVD CCA appealed that decision to the U.S. Supreme Court.\n",
      "Label 1\n",
      "[0.9789003]\n",
      "********\n",
      "That compared with $35.18 million, or 24 cents per share, in the year-ago period.\n",
      "Earnings were affected by a non-recurring $8 million tax benefit in the year-ago period.\n",
      "Label 0\n",
      "[0.8678842]\n",
      "********\n",
      "He said the foodservice pie business doesn't fit the company's long-term growth strategy.\n",
      "\"The foodservice pie business does not fit our long-term growth strategy.\n",
      "Label 1\n",
      "[0.948756]\n",
      "********\n"
     ]
    }
   ],
   "source": [
    "verbose_data(simple_graph_vector_feature_generator, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SubtreeFeatureGenerator:\n",
    "  NAME = 'SubtreeFeature'\n",
    "\n",
    "  SIMILARITY = 0.8\n",
    "\n",
    "  def get_feature_for_length(self, g_f1, g_f2, length):\n",
    "    f1 = g_f1.get_subtree_features(length=length)\n",
    "    f2 = g_f2.get_subtree_features(length=length)\n",
    "    \n",
    "    score = MatchFeatureVectors.match_feature_vectors(f1, f2, similarity=self.SIMILARITY)\n",
    "\n",
    "    norm = len(f1) + len(f2)\n",
    "    return (score * 2.) / norm if norm != 0 else 0\n",
    "\n",
    "  def get_features(self, s1, s2):\n",
    "    g1 = GraphBuilder.build_nx_graph_from_sentance(s1)\n",
    "    g2 = GraphBuilder.build_nx_graph_from_sentance(s2)\n",
    "    \n",
    "    g_f1 = GraphFeatures(g1)\n",
    "    g_f2 = GraphFeatures(g2)\n",
    "\n",
    "    features = np.array([\n",
    "      self.get_feature_for_length(g_f1, g_f2, 0),\n",
    "      self.get_feature_for_length(g_f1, g_f2, 1),\n",
    "      self.get_feature_for_length(g_f1, g_f2, 2),\n",
    "      self.get_feature_for_length(g_f1, g_f2, 3),\n",
    "      self.get_feature_for_length(g_f1, g_f2, 4),\n",
    "    ])\n",
    "\n",
    "    return features\n",
    "\n",
    "subtree_feature_generator = SubtreeFeatureGenerator()\n",
    "# LinearSVC {'precision': 74.85, 'recall': 89.8, 'f1': 81.65, 'accuracy': 73.16}\n",
    "# SGDClassifier {'precision': 74.84, 'recall': 90.5, 'f1': 81.93, 'accuracy': 73.45}\n",
    "# LogisticRegression(max_iter = 500000) {'precision': 75.02, 'recall': 90.32, 'f1': 81.96, 'accuracy': 73.57} [True, True, True, True, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Uncomment to test\n",
    "# prepare_data(subtree_feature_generator, True, 10000)\n",
    "# scores = base_classification_test(subtree_feature_generator)\n",
    "# Uncomment to run feature selection\n",
    "# feature_selection(subtree_feature_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amrozi accused his brother, whom he called \"the witness\", of deliberately distorting his evidence.\n",
      "Referring to him as only \"the witness\", Amrozi accused his brother of deliberately distorting his evidence.\n",
      "Label 1\n",
      "[0.86486486 0.85714286 1.         1.         0.        ]\n",
      "********\n",
      "Yucaipa owned Dominick's before selling the chain to Safeway in 1998 for $2.5 billion.\n",
      "Yucaipa bought Dominick's in 1995 for $693 million and sold it to Safeway for $1.8 billion in 1998.\n",
      "Label 0\n",
      "[0.56410256 0.73684211 1.         1.2        1.33333333]\n",
      "********\n",
      "They had published an advertisement on the Internet on June 10, offering the cargo for sale, he added.\n",
      "On June 10, the ship's owners had published an advertisement on the Internet, offering the explosives for sale.\n",
      "Label 1\n",
      "[0.79069767 0.76190476 1.         1.14285714 1.33333333]\n",
      "********\n",
      "Around 0335 GMT, Tab shares were up 19 cents, or 4.4%, at A$4.56, having earlier set a record high of A$4.57.\n",
      "Tab shares jumped 20 cents, or 4.6%, to set a record closing high at A$4.57.\n",
      "Label 0\n",
      "[0.84444444 0.82352941 1.25       1.         0.        ]\n",
      "********\n",
      "The stock rose $2.11, or about 11 percent, to close Friday at $21.51 on the New York Stock Exchange.\n",
      "PG&E Corp. shares jumped $1.63 or 8 percent to $21.03 on the New York Stock Exchange on Friday.\n",
      "Label 1\n",
      "[0.72727273 0.47619048 0.5        0.66666667 0.        ]\n",
      "********\n",
      "Revenue in the first quarter of the year dropped 15 percent from the same period a year earlier.\n",
      "With the scandal hanging over Stewart's company, revenue the first quarter of the year dropped 15 percent from the same period a year earlier.\n",
      "Label 1\n",
      "[0.7826087  0.74074074 0.84210526 0.85714286 0.88888889]\n",
      "********\n",
      "The Nasdaq had a weekly gain of 17.27, or 1.2 percent, closing at 1,520.15 on Friday.\n",
      "The tech-laced Nasdaq Composite .IXIC rallied 30.46 points, or 2.04 percent, to 1,520.15.\n",
      "Label 0\n",
      "[0.41176471 0.         0.         0.         0.        ]\n",
      "********\n",
      "The DVD-CCA then appealed to the state Supreme Court.\n",
      "The DVD CCA appealed that decision to the U.S. Supreme Court.\n",
      "Label 1\n",
      "[0.75       0.88888889 0.8        0.66666667 0.        ]\n",
      "********\n",
      "That compared with $35.18 million, or 24 cents per share, in the year-ago period.\n",
      "Earnings were affected by a non-recurring $8 million tax benefit in the year-ago period.\n",
      "Label 0\n",
      "[0.45       0.47058824 0.66666667 1.         1.        ]\n",
      "********\n",
      "He said the foodservice pie business doesn't fit the company's long-term growth strategy.\n",
      "\"The foodservice pie business does not fit our long-term growth strategy.\n",
      "Label 1\n",
      "[0.84848485 0.83333333 1.14285714 1.33333333 0.        ]\n",
      "********\n"
     ]
    }
   ],
   "source": [
    "verbose_data(subtree_feature_generator, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RootNodeFeatureGenerator:\n",
    "  NAME = 'RootNodeFeature'\n",
    "\n",
    "  def get_features(self, s1, s2):\n",
    "    g1 = GraphBuilder.build_nx_graph_from_sentance(s1)\n",
    "    g2 = GraphBuilder.build_nx_graph_from_sentance(s2)\n",
    "\n",
    "    root_node1 = GraphBuilder.get_root_node(g1)\n",
    "    root_node2 = GraphBuilder.get_root_node(g2)\n",
    "\n",
    "    if root_node1['token'].has_vector and root_node2['token'].has_vector:\n",
    "      score = root_node1['token'].similarity(root_node2['token'])\n",
    "    else:\n",
    "      score = 0\n",
    "\n",
    "    features = np.array([\n",
    "      score,\n",
    "    ])\n",
    "\n",
    "    return features\n",
    "\n",
    "root_node_feature_generator = RootNodeFeatureGenerator()\n",
    "# SVC {'precision': 66.49, 'recall': 100.0, 'f1': 79.87, 'accuracy': 66.49}\n",
    "# By itself is not usefull, but maybe in combination could be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare_data(root_node_feature_generator, True, 10000)\n",
    "# scores = base_classification_test(root_node_feature_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# class GraphAlgoFeatureGenerator:\n",
    "#   NAME = 'GraphAlgoFeature'\n",
    "\n",
    "#   def get_features(self, s1, s2):\n",
    "#     g1 = GraphBuilder.build_nx_graph_from_sentance(s1)\n",
    "#     g2 = GraphBuilder.build_nx_graph_from_sentance(s2)\n",
    "\n",
    "#     s1 = networkx_algorithms.smetric.s_metric(g1, normalized=False)\n",
    "#     s2 = networkx_algorithms.smetric.s_metric(g2, normalized=False)\n",
    "    \n",
    "#     w1 = networkx_algorithms.wiener.wiener_index(g1)\n",
    "#     w2 = networkx_algorithms.wiener.wiener_index(g2)\n",
    "\n",
    "#     # r1 = networkx_algorithms.richclub.rich_club_coefficient(g1)\n",
    "#     # r2 = networkx_algorithms.richclub.rich_club_coefficient(g2)\n",
    "\n",
    "#     features = np.array([\n",
    "#       s1 / (s1 + s2),\n",
    "#       s2 / (s1 + s2),\n",
    "#       abs(s1 - s2) / (s1 + s2),\n",
    "#       w1 / (w1 + w2),\n",
    "#       w2 / (w1 + w2),\n",
    "#       abs(w1 - w2) / (w1 + w2),\n",
    "#       # abs(r1[0] - r2[0]),\n",
    "#       # abs(r1[1] - r2[1]),\n",
    "#       # abs(r1[2] - r2[2]),      \n",
    "#     ])\n",
    "\n",
    "#     return features\n",
    "\n",
    "# graph_algo_feature_generator = GraphAlgoFeatureGenerator()\n",
    "# Even after feature selection\n",
    "# PassiveAggressiveClassifier {'precision': 68.34, 'recall': 95.2, 'f1': 79.56, 'accuracy': 67.48} [False, False, False, True, True, True]\n",
    "# So it's not useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare_data(graph_algo_feature_generator, True, 10000)\n",
    "# scores = base_classification_test(graph_algo_feature_generator)\n",
    "# feature_selection(graph_algo_feature_generator, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# import json\n",
    "# from json import JSONEncoder\n",
    "\n",
    "# class NumpyArrayEncoder(JSONEncoder):\n",
    "#     def default(self, obj):\n",
    "#         if isinstance(obj, np.ndarray):\n",
    "#             return obj.tolist()\n",
    "#         return JSONEncoder.default(self, obj)\n",
    "\n",
    "# with open('/content/drive/My Drive/phd/prepared_data.json', 'w') as f:\n",
    "#   json.dump(prepared_data, f, cls=NumpyArrayEncoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to remove stop words (don't use their vectors):\n",
    " - Results:\n",
    "    SubtreeFeature - not very usefull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SubtreeFeatureGeneratorWithoutStopWords:\n",
    "  NAME = 'SubtreeFeatureWithoutStopWords'\n",
    "\n",
    "  SIMILARITY = 0.8\n",
    "\n",
    "  def get_feature_for_length(self, g_f1, g_f2, length):\n",
    "    f1 = g_f1.get_subtree_features(length=length, remove_stop_words=True)\n",
    "    f2 = g_f2.get_subtree_features(length=length, remove_stop_words=True)\n",
    "    \n",
    "    score = MatchFeatureVectors.match_feature_vectors(f1, f2, similarity=self.SIMILARITY)\n",
    "\n",
    "    norm = len(f1) + len(f2)\n",
    "    return (score * 2.) / norm if norm != 0 else 0\n",
    "\n",
    "  def get_features(self, s1, s2):\n",
    "    g1 = GraphBuilder.build_nx_graph_from_sentance(s1)\n",
    "    g2 = GraphBuilder.build_nx_graph_from_sentance(s2)\n",
    "    \n",
    "    g_f1 = GraphFeatures(g1)\n",
    "    g_f2 = GraphFeatures(g2)\n",
    "\n",
    "    features = np.array([\n",
    "      self.get_feature_for_length(g_f1, g_f2, 0),\n",
    "      self.get_feature_for_length(g_f1, g_f2, 1),\n",
    "      self.get_feature_for_length(g_f1, g_f2, 2),\n",
    "      self.get_feature_for_length(g_f1, g_f2, 3),\n",
    "      self.get_feature_for_length(g_f1, g_f2, 4),\n",
    "    ])\n",
    "\n",
    "    return features\n",
    "\n",
    "subtree_without_stop_words_feature_generator = SubtreeFeatureGeneratorWithoutStopWords()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare_data(subtree_without_stop_words_feature_generator, True, 10000)\n",
    "# scores = base_classification_test(subtree_without_stop_words_feature_generator)\n",
    "# feature_selection(subtree_without_stop_words_feature_generator, verbose=False)\n",
    "\n",
    "# Results\n",
    "# SVC {'precision': 72.9, 'recall': 91.46, 'f1': 81.13, 'accuracy': 71.71}\n",
    "# feature selection didn't improve results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AllFeatureGenerator:\n",
    "  NAME = 'AllFeatures'\n",
    "\n",
    "  def get_features(self, s1, s2):\n",
    "    generators = [\n",
    "        HungarianGraphFeatureGenerator(),\n",
    "        HungarianNodeFeatureGenerator(),\n",
    "        PathFeatureGenerator(),\n",
    "        SubtreeFeatureGenerator(),\n",
    "    ]\n",
    "    features = np.array([])\n",
    "    for generator in generators:\n",
    "      features = np.append(features, generator.get_features(s1, s2))\n",
    "    return features\n",
    "\n",
    "all_feature_generator = AllFeatureGenerator()\n",
    "# LogisticRegression(max_iter = 500000) {'precision': 76.04, 'recall': 88.84, 'f1': 81.95, 'accuracy': 73.97}\n",
    "# RandomForestClassifier(n_estimators=1000,criterion='entropy',random_state=0) {'precision': 76.32, 'recall': 88.23, 'f1': 81.84, 'accuracy': 73.97}\n",
    "\n",
    "# RidgeClassifierCV {'precision': 76.28, 'recall': 89.71, 'f1': 82.45, 'accuracy': 74.61} [True, False, True, False, False, True, False, False, True, False, True, True, False, True, False]\n",
    "# LogisticRegressionCV {'precision': 76.8, 'recall': 88.58, 'f1': 82.27, 'accuracy': 74.61} [True, False, True, True, True, False, False, True, True, True, False, False, True, True, False]\n",
    "# RidgeClassifierCV {'precision': 76.09, 'recall': 90.15, 'f1': 82.52, 'accuracy': 74.61} [True, True, False, False, False, True, True, False, False, False, True, True, False, False, True]\n",
    "# LogisticRegression(max_iter = 500000) {'precision': 76.4, 'recall': 89.45, 'f1': 82.41, 'accuracy': 74.61} [True, False, True, True, True, True, False, True, True, True, False, False, False, True, False]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare_data(all_feature_generator, True, 10000)\n",
    "# scores = base_classification_test(all_feature_generator)\n",
    "# all_feature_generator = AllFeatureGenerator()\n",
    "# feature_selection(all_feature_generator, verbose=True, bitmask_amount=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AllFeatureGeneratorV1:\n",
    "  NAME = 'AllFeatureV1'\n",
    "\n",
    "  def get_features(self, s1, s2):\n",
    "    generators = [\n",
    "        HungarianGraphFeatureGenerator(),\n",
    "        HungarianNodeFeatureGenerator(),\n",
    "        PathFeatureGenerator(),\n",
    "        SubtreeFeatureGenerator(),\n",
    "        SubtreeFeatureGeneratorWithoutStopWords(),\n",
    "    ]\n",
    "    features = np.array([])\n",
    "    for generator in generators:\n",
    "      features = np.append(features, generator.get_features(s1, s2))\n",
    "    return features\n",
    "\n",
    "all_feature_generator_v1 = AllFeatureGeneratorV1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare_data(all_feature_generator, True, 10000)\n",
    "# scores = base_classification_test(all_feature_generator)\n",
    "# all_feature_generator = AllFeatureGenerator()\n",
    "# feature_selection(all_feature_generator, verbose=False, bitmask_amount=100)\n",
    "\n",
    "# Top Accuracy\n",
    "# LinearSVC {'precision': 76.62, 'recall': 89.45, 'f1': 82.54, 'accuracy': 74.84} [True, False, False, False, False, False, False, False, True, True, True, True, True, True, False]\n",
    "# RidgeClassifierCV {'precision': 76.57, 'recall': 89.45, 'f1': 82.51, 'accuracy': 74.78} [True, False, False, False, False, False, False, False, True, True, True, True, True, True, False]\n",
    "# LogisticRegression(max_iter = 500000) {'precision': 76.79, 'recall': 88.84, 'f1': 82.38, 'accuracy': 74.72} [False, True, False, True, True, True, False, False, False, True, False, True, False, False, True]\n",
    "# LogisticRegression(max_iter = 500000) {'precision': 76.59, 'recall': 89.28, 'f1': 82.45, 'accuracy': 74.72} [False, False, True, True, True, False, False, True, False, False, True, False, True, True, False]\n",
    "# RidgeClassifierCV {'precision': 76.83, 'recall': 88.75, 'f1': 82.36, 'accuracy': 74.72} [False, False, False, False, True, True, False, True, False, False, False, True, True, True, False]\n",
    "# Top F1\n",
    "# LogisticRegression(max_iter = 500000) {'precision': 76.01, 'recall': 90.32, 'f1': 82.55, 'accuracy': 74.61} [True, False, True, False, False, True, True, True, False, True, False, False, False, True, True]\n",
    "# LinearSVC {'precision': 76.62, 'recall': 89.45, 'f1': 82.54, 'accuracy': 74.84} [True, False, False, False, False, False, False, False, True, True, True, True, True, True, False]\n",
    "# RidgeClassifierCV {'precision': 76.57, 'recall': 89.45, 'f1': 82.51, 'accuracy': 74.78} [True, False, False, False, False, False, False, False, True, True, True, True, True, True, False]\n",
    "# SGDClassifier {'precision': 75.22, 'recall': 91.28, 'f1': 82.47, 'accuracy': 74.2} [False, True, True, False, True, False, False, False, False, False, True, True, False, True, False]\n",
    "# Perceptron {'precision': 75.97, 'recall': 90.15, 'f1': 82.46, 'accuracy': 74.49} [True, False, True, False, True, False, False, False, False, False, True, True, True, False, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AnalyzePredictions:\n",
    "  CORRECT_PREDICTIONS = 'CORRECT_PREDICTIONS'\n",
    "  WRONG_PREDICTIONS = 'WRONG_PREDICTIONS'\n",
    "  \n",
    "  @classmethod\n",
    "  def get_predictions(cls, feature_generator, classificator, mode, verbose=True, limit=10):\n",
    "    feature_name = feature_generator.NAME\n",
    "    assert feature_name in prepared_data, \"No features found\"\n",
    "\n",
    "    test_data = DataGenerator.get_test_data()\n",
    "    \n",
    "    train_X = prepared_data[feature_name]['train_X']\n",
    "    test_X = prepared_data[feature_name]['test_X']\n",
    "    train_Y = prepared_data[feature_name]['train_Y']\n",
    "    test_Y = prepared_data[feature_name]['test_Y']\n",
    "\n",
    "\n",
    "    classificator.fit(train_X, train_Y)\n",
    "\n",
    "    test_Y_predicted = classificator.predict(test_X)\n",
    "\n",
    "    res = []\n",
    "    for data, features, prediction, label in zip(test_data, test_X, test_Y_predicted, test_Y):\n",
    "      if (mode == AnalyzePredictions.CORRECT_PREDICTIONS and prediction == label or \n",
    "         mode == AnalyzePredictions.WRONG_PREDICTIONS and prediction != label):\n",
    "          res.append({\n",
    "              \"raw\": data,\n",
    "              \"features\": features,\n",
    "              \"prediction\": prediction,\n",
    "              \"label\": label\n",
    "          })\n",
    "          if verbose:\n",
    "            print(data)\n",
    "            print(features)\n",
    "            print(f\"Prediction {prediction}, but label {label}\")\n",
    "          limit -= 1\n",
    "          if limit == 0:\n",
    "            break\n",
    "    return res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_sample(p):\n",
    "  print (p[\"raw\"][\"s1\"])\n",
    "  print (p[\"raw\"][\"s2\"])\n",
    "  print (f\"Label {p['raw']['label']}\")\n",
    "  print (f\"Prediction {p['prediction']}\")\n",
    "  print (p[\"features\"])\n",
    "\n",
    "# model = LinearSVC()\n",
    "# prepare_data(subtree_feature_generator, True, 10000)\n",
    "# not_predicted = AnalyzePredictions.get_predictions(subtree_feature_generator, model, AnalyzePredictions.WRONG_PREDICTIONS,  verbose=False)\n",
    "# ok_predicted = AnalyzePredictions.get_predictions(subtree_feature_generator, model, AnalyzePredictions.CORRECT_PREDICTIONS,  verbose=False, limit=10)\n",
    "# sample_wrong = not_predicted[0]\n",
    "# sample_ok = ok_predicted[0]\n",
    "\n",
    "# print_sample(sample_wrong)\n",
    "# print_sample(sample_ok)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting to work with edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SimpleEdgeMatcher:\n",
    "  NAME = 'SimpleEdgeMatcher'\n",
    "\n",
    "  SIMILARITY = 0.8\n",
    "\n",
    "  def simple_match_edges(self, g_f1, g_f2):\n",
    "    f1 = g_f1.get_simple_edge_features()\n",
    "    f2 = g_f2.get_simple_edge_features()\n",
    "    \n",
    "    score = 0\n",
    "    for edge1 in f1:\n",
    "        if (edge1['start_node']['token'] is None or \n",
    "            not edge1['start_node']['token'].has_vector\n",
    "            or edge1['end_node']['token'] is None\n",
    "            or not edge1['end_node']['token'].has_vector):\n",
    "                continue\n",
    "        for edge2 in f2:\n",
    "            if (edge2['start_node']['token'] is None \n",
    "            or not edge2['start_node']['token'].has_vector\n",
    "            or edge2['end_node']['token'] is None\n",
    "            or not edge2['end_node']['token'].has_vector):\n",
    "                continue\n",
    "            if (Vector.similarity(\n",
    "                    edge1['start_node']['token'].vector, \n",
    "                    edge2['start_node']['token'].vector\n",
    "                ) > self.SIMILARITY\n",
    "                and Vector.similarity(\n",
    "                    edge1['end_node']['token'].vector, \n",
    "                    edge2['end_node']['token'].vector\n",
    "                ) > self.SIMILARITY\n",
    "               ):\n",
    "                score += 1\n",
    "        \n",
    "    similarity_score = (1. * score) / (len(f1) * len(f2))\n",
    "    \n",
    "    return similarity_score\n",
    "\n",
    "  def get_features(self, s1, s2):\n",
    "    g1 = GraphBuilder.build_nx_graph_from_sentance(s1)\n",
    "    g2 = GraphBuilder.build_nx_graph_from_sentance(s2)\n",
    "    \n",
    "    g_f1 = GraphFeatures(g1)\n",
    "    g_f2 = GraphFeatures(g2)\n",
    "\n",
    "    features = np.array([\n",
    "      self.simple_match_edges(g_f1, g_f2)\n",
    "    ])\n",
    "    \n",
    "    return features\n",
    "\n",
    "simple_edge_matcher_feature_generator = SimpleEdgeMatcher()\n",
    "# Don't efective \n",
    "# GaussianNB {'precision': 67.78, 'recall': 97.56, 'f1': 79.99, 'accuracy': 67.54}\n",
    "# RidgeClassifierCV {'precision': 66.82, 'recall': 99.74, 'f1': 80.03, 'accuracy': 66.9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare_data(simple_edge_matcher_feature_generator, True, 10000)\n",
    "# scores = base_classification_test(simple_edge_matcher_feature_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SimpleEdgeMatcherWithDependancy:\n",
    "  NAME = 'SimpleEdgeMatcherWithDependancy'\n",
    "\n",
    "  SIMILARITY = 0.8\n",
    "\n",
    "  def simple_match_edges_with_dependancy_type(self, g_f1, g_f2):\n",
    "    f1 = g_f1.get_simple_edge_features()\n",
    "    f2 = g_f2.get_simple_edge_features()\n",
    "    \n",
    "    score = 0\n",
    "    total = 0\n",
    "    for edge1 in f1:\n",
    "        if (edge1['start_node']['token'] is None or \n",
    "            not edge1['start_node']['token'].has_vector\n",
    "            or edge1['end_node']['token'] is None\n",
    "            or not edge1['end_node']['token'].has_vector):\n",
    "                continue\n",
    "        for edge2 in f2:\n",
    "            if (edge2['start_node']['token'] is None \n",
    "            or not edge2['start_node']['token'].has_vector\n",
    "            or edge2['end_node']['token'] is None\n",
    "            or not edge2['end_node']['token'].has_vector):\n",
    "                continue\n",
    "            if (Vector.similarity(\n",
    "                    edge1['start_node']['token'].vector, \n",
    "                    edge2['start_node']['token'].vector\n",
    "                ) > self.SIMILARITY\n",
    "                and Vector.similarity(\n",
    "                    edge1['end_node']['token'].vector, \n",
    "                    edge2['end_node']['token'].vector\n",
    "                ) > self.SIMILARITY\n",
    "               ):\n",
    "                if (edge1['dependancy_type'] == edge2['dependancy_type']):\n",
    "                    score += 1\n",
    "                total += 1\n",
    "        \n",
    "    similarity_score = 0 if total == 0 else (1. * score) / total\n",
    "    \n",
    "    return similarity_score\n",
    "\n",
    "  def get_features(self, s1, s2):\n",
    "    g1 = GraphBuilder.build_nx_graph_from_sentance(s1)\n",
    "    g2 = GraphBuilder.build_nx_graph_from_sentance(s2)\n",
    "    \n",
    "    g_f1 = GraphFeatures(g1)\n",
    "    g_f2 = GraphFeatures(g2)\n",
    "\n",
    "    features = np.array([\n",
    "      self.simple_match_edges_with_dependancy_type(g_f1, g_f2)\n",
    "    ])\n",
    "    \n",
    "    simple_edge_matcher_feature_generator = SimpleEdgeMatcher()\n",
    "    features = np.append(features, simple_edge_matcher_feature_generator.get_features(s1, s2))\n",
    "\n",
    "\n",
    "    return features\n",
    "\n",
    "simple_edge_matcher_with_dependancy_feature_generator = SimpleEdgeMatcherWithDependancy()\n",
    "# GradientBoostingClassifier {'precision': 68.77, 'recall': 94.25, 'f1': 79.51, 'accuracy': 67.71}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare_data(simple_edge_matcher_with_dependancy_feature_generator, True, 10000)\n",
    "# scores = base_classification_test(simple_edge_matcher_with_dependancy_feature_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SimpleApproximateBigramKernel:\n",
    "  \"\"\"\n",
    "        From https://www.aclweb.org/anthology/L16-1452.pdf\n",
    "        Simple Approximate Bigram Kernel (SABK)\n",
    "  \"\"\"\n",
    "\n",
    "  NAME = 'SimpleApproximateBigramKernel'\n",
    "  EDGE_SIMILARITY_SCORE = 2\n",
    "\n",
    "  @classmethod  \n",
    "  def node_similarity(cls, node1, node2):\n",
    "    if (node1['token'] is None or \n",
    "        node2['token'] is None or \n",
    "        not node1['token'].has_vector or \n",
    "        not node2['token'].has_vector\n",
    "       ):\n",
    "        return 1 if node1['node'] == node2['node'] else 0\n",
    "    else:\n",
    "        return Vector.similarity(\n",
    "            node1['token'].vector, \n",
    "            node2['token'].vector\n",
    "        )\n",
    "  @classmethod  \n",
    "  def edge_similarity(cls, edge1, edge2):\n",
    "    return SimpleApproximateBigramKernel.EDGE_SIMILARITY_SCORE if edge1['dependancy_type'] == edge2['dependancy_type'] else 1\n",
    "\n",
    "  @classmethod  \n",
    "  def similarity(cls, edge1, edge2):\n",
    "    start_node_similarity = cls.node_similarity(edge1['start_node'], edge2['start_node'])\n",
    "    end_node_similarity = cls.node_similarity(edge1['end_node'], edge2['end_node'])\n",
    "    \n",
    "    edge_similarity = cls.edge_similarity(edge1, edge2)\n",
    "    \n",
    "    return (start_node_similarity + end_node_similarity) * edge_similarity\n",
    "    \n",
    "  @classmethod  \n",
    "  def compute_simple_approximate_bigram_kernel(cls, g_f1, g_f2):\n",
    "    f1 = g_f1.get_simple_edge_features()\n",
    "    f2 = g_f2.get_simple_edge_features()\n",
    "    \n",
    "    similarity_score = 0\n",
    "\n",
    "    for edge1 in f1:\n",
    "        for edge2 in f2:\n",
    "            similarity_score += cls.similarity(edge1, edge2)\n",
    "        \n",
    "    similarity_score = (similarity_score * 1.) / (len(g1.nodes) + len(g2.nodes))\n",
    "    \n",
    "    return similarity_score\n",
    "\n",
    "  def get_features(self, s1, s2):\n",
    "    g1 = GraphBuilder.build_nx_graph_from_sentance(s1)\n",
    "    g2 = GraphBuilder.build_nx_graph_from_sentance(s2)\n",
    "    \n",
    "    g_f1 = GraphFeatures(g1)\n",
    "    g_f2 = GraphFeatures(g2)\n",
    "\n",
    "    features = np.array([\n",
    "      SimpleApproximateBigramKernel.compute_simple_approximate_bigram_kernel(g_f1, g_f2)\n",
    "    ])\n",
    "\n",
    "    return features\n",
    "\n",
    "simple_approximate_bigram_kernel = SimpleApproximateBigramKernel()\n",
    "# LogisticRegression(max_iter = 500000) {'precision': 67.65, 'recall': 98.08, 'f1': 80.07, 'accuracy': 67.54}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scores = base_classification_test(simple_approximate_bigram_kernel, force_feature_update=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TfIdf:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.prepare_corpus()\n",
    "        self.fit()\n",
    "        \n",
    "    def prepare_corpus(self):\n",
    "        self.corpus = [x['s1'] for x in self.data] + [x['s2'] for x in self.data]\n",
    "        self.corpus = list(set(self.corpus))\n",
    "        self.corpus = sorted(self.corpus)\n",
    "        self.corpus_len = len(self.corpus)\n",
    "                \n",
    "        self.sent_to_index = {}\n",
    "        for index, s in enumerate(self.corpus):\n",
    "            self.sent_to_index[s] = index\n",
    "            \n",
    "    def fit(self):\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        X = vectorizer.fit_transform(self.corpus)\n",
    "        \n",
    "        self.vectorizer = vectorizer\n",
    "        \n",
    "        self.words_list = vectorizer.get_feature_names()\n",
    "        self.idf = vectorizer._tfidf.idf_\n",
    "        \n",
    "        self.word_to_index = {}\n",
    "        for index, w in enumerate(self.words_list):\n",
    "            self.word_to_index[w] = index\n",
    "    \n",
    "    def use_idf(self, t):\n",
    "        return (t.is_alpha and \n",
    "                not (t.is_space or t.is_punct or \n",
    "                     t.is_stop or t.like_num))\n",
    "    \n",
    "    def get_idf(self, token):\n",
    "        if not self.use_idf(token):\n",
    "            return 1\n",
    "        return self.get_word_idf(token.text)\n",
    "    \n",
    "    def get_word_idf(self, word):\n",
    "        if word in self.word_to_index:\n",
    "            idf = self.idf[self.word_to_index[word]]\n",
    "        else:\n",
    "            # https://github.com/scikit-learn/scikit-learn/blob/0fb307bf3/sklearn/feature_extraction/text.py#L1443\n",
    "            idf = np.log(self.corpus_len + 1 / 1) + 1\n",
    "#         print(\"Calling idf for \" + word + \" = \" + str(idf))\n",
    "        return idf\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idf_model = TfIdf(DataGenerator.get_test_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SubtreeFeatureGeneratorIdf:\n",
    "  NAME = 'SubtreeFeatureIdf'\n",
    "\n",
    "  SIMILARITY = 0.8\n",
    "\n",
    "  def get_feature_for_length(self, g_f1, g_f2, length):\n",
    "    f1 = g_f1.get_subtree_features(length=length, idf_model=idf_model)\n",
    "    f2 = g_f2.get_subtree_features(length=length, idf_model=idf_model)\n",
    "    \n",
    "    score = MatchFeatureVectors.match_feature_vectors(f1, f2, similarity=self.SIMILARITY)\n",
    "\n",
    "    norm = len(f1) + len(f2)\n",
    "    return (score * 2.) / norm if norm != 0 else 0\n",
    "\n",
    "  def get_features(self, s1, s2):\n",
    "    g1 = GraphBuilder.build_nx_graph_from_sentance(s1)\n",
    "    g2 = GraphBuilder.build_nx_graph_from_sentance(s2)\n",
    "    \n",
    "    g_f1 = GraphFeatures(g1)\n",
    "    g_f2 = GraphFeatures(g2)\n",
    "\n",
    "    features = np.array([\n",
    "      self.get_feature_for_length(g_f1, g_f2, 0),\n",
    "      self.get_feature_for_length(g_f1, g_f2, 1),\n",
    "      self.get_feature_for_length(g_f1, g_f2, 2),\n",
    "      self.get_feature_for_length(g_f1, g_f2, 3),\n",
    "      self.get_feature_for_length(g_f1, g_f2, 4),\n",
    "    ])\n",
    "\n",
    "    return features\n",
    "\n",
    "subtree_feature_generator_idf = SubtreeFeatureGeneratorIdf()\n",
    "# SGDClassifier {'precision': 71.5, 'recall': 95.38, 'f1': 81.73, 'accuracy': 71.65}\n",
    "# Not better than simple subtree_feature_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scores = base_classification_test(subtree_feature_generator_idf, force_feature_update=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GeneralFeatures:\n",
    "    \n",
    "    @classmethod\n",
    "    def get_s_len(cls, s):\n",
    "        doc = nlp(s)\n",
    "        return np.array([len(doc)])\n",
    "    \n",
    "    @classmethod\n",
    "    def get_n_grams(cls, s, n, doc=None):\n",
    "        if doc is None:\n",
    "            d = nlp(s)\n",
    "        else:\n",
    "            d = doc\n",
    "        \n",
    "        res = []\n",
    "        count=0\n",
    "        for token in d[:len(d)-n+1]:  \n",
    "           res.append(d[count:count+n])  \n",
    "           count=count+1  \n",
    "        return res\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NodeSimilarity:\n",
    "    \n",
    "    \n",
    "    @classmethod\n",
    "    def basic(cls, node1, node2):\n",
    "        if (node1['token'] is None or \n",
    "            node2['token'] is None or \n",
    "            not node1['token'].has_vector or \n",
    "            not node2['token'].has_vector\n",
    "           ):\n",
    "            return 1 if node1['node'] == node2['node'] else 0\n",
    "        else:\n",
    "            return Vector.similarity(\n",
    "                node1['token'].vector, \n",
    "                node2['token'].vector\n",
    "            )\n",
    "        \n",
    "    @classmethod\n",
    "    def token_similarity(cls, token1, token2):\n",
    "        \"\"\"\n",
    "        It's spacy tokens\n",
    "        \"\"\"\n",
    "        if token1.has_vector and token2.has_vector:\n",
    "            return Vector.similarity(\n",
    "                token1.vector, \n",
    "                token2.vector\n",
    "            )\n",
    "        else:\n",
    "            return 1 if token1.text == token2.text else 0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from spacy.tokens import Token as SpacyToken\n",
    "\n",
    "class NGramSimilarity:\n",
    "    \n",
    "    @classmethod\n",
    "    def basic_word(cls, n_gram_1, n_gram_2):\n",
    "        \"\"\"\n",
    "            n_gram_1 is Token\n",
    "            n_gram_2 is Token\n",
    "        \"\"\"\n",
    "        if isinstance(n_gram_1[0], SpacyToken):\n",
    "            comparator = NodeSimilarity.token_similarity\n",
    "            \n",
    "        for i in range(len(n_gram_1)):\n",
    "            if comparator(n_gram_1[i], n_gram_2[i]) < 0.9:\n",
    "                return False\n",
    "        return True\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BrevityPenalty:\n",
    "    \n",
    "    @classmethod\n",
    "    def compute(cls, ref_length, hyp_length):\n",
    "        \"\"\"\n",
    "            ref_lengths - int\n",
    "            hyp_lengths - int\n",
    "            Return BrevityPenalty - double\n",
    "            https://www.nltk.org/_modules/nltk/translate/bleu_score.html\n",
    "        \"\"\"\n",
    "        \n",
    "        if hyp_length > ref_length:\n",
    "            return 1\n",
    "        # If hypothesis is empty, brevity penalty = 0 should result in BLEU = 0.0\n",
    "        elif hyp_length == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return math.exp(1 - ref_length / hyp_length)\n",
    "\n",
    "\n",
    "class BLEUCalculator:\n",
    "    \n",
    "    @classmethod\n",
    "    def precision(cls, reference, hypothesis, get_n_grams_funct, is_n_gram_equal_func, n):\n",
    "        \"\"\"\n",
    "        s1 - First sentance\n",
    "        s2 - Second sentance\n",
    "        get_n_grams_funct - Function that takes:\n",
    "            s - sentance\n",
    "            n - size of n gram\n",
    "            Return list of n_grams\n",
    "        is_n_gram_equal_func - n_gram comparator\n",
    "            n_gram_1\n",
    "            n_gram_2\n",
    "            Return Bool\n",
    "        n - size of bigram\n",
    "\n",
    "        \"\"\"\n",
    "        # Extracts all ngrams in hypothesis\n",
    "        # Set an empty Counter if hypothesis is empty.\n",
    "        \n",
    "        reference_n_grams = get_n_grams_funct(reference, n)\n",
    "\n",
    "        hypothesis_n_grams = get_n_grams_funct(hypothesis, n)\n",
    "\n",
    "        total_found = 0\n",
    "\n",
    "        for n_gram_h in hypothesis_n_grams:\n",
    "            found = False\n",
    "            for n_gram_r in reference_n_grams:\n",
    "#                 print(n_gram_h)\n",
    "#                 print(n_gram_r)\n",
    "                if is_n_gram_equal_func(n_gram_h, n_gram_r):\n",
    "#                     print(n_gram_h)\n",
    "#                     print(n_gram_r)\n",
    "#                     print(\"Match\")\n",
    "#                     print(\"*\" * 20)\n",
    "                    \n",
    "                    found = True\n",
    "            if found:\n",
    "                total_found += 1\n",
    "\n",
    "        numerator = total_found\n",
    "        # Ensures that denominator is minimum 1 to avoid ZeroDivisionError.\n",
    "        denominator = max(1, len(hypothesis_n_grams))\n",
    "\n",
    "        return (numerator * 1.) / denominator\n",
    "    \n",
    "    @classmethod\n",
    "    def compute(cls, reference, hypothesis, get_n_grams_funct, is_n_gram_equal_func, max_n):\n",
    "        \"\"\"\n",
    "        s1 - First sentance\n",
    "        s2 - Second sentance\n",
    "        get_n_grams_funct - Function that takes:\n",
    "            s - sentance\n",
    "            n - size of n gram\n",
    "            Return list of n_grams\n",
    "        is_n_gram_equal_func - n_gram comparator\n",
    "            n_gram_1\n",
    "            n_gram_2\n",
    "            Return Bool\n",
    "        max_n - Max size of bigram\n",
    "        \n",
    "        Return BLEU - double\n",
    "        \n",
    "        https://www.nltk.org/_modules/nltk/translate/bleu_score.html\n",
    "        \"\"\"\n",
    "        \n",
    "        p_n = []\n",
    "        \n",
    "        weight = 1. / max_n\n",
    "            \n",
    "        weights = [weight] * max_n\n",
    "        \n",
    "        # For each order of ngram, calculate the numerator and\n",
    "        # denominator for the corpus-level modified precision.\n",
    "        for i, _ in enumerate(weights, start=1):\n",
    "            _p = cls.precision(reference, hypothesis, get_n_grams_funct, is_n_gram_equal_func, i)\n",
    "            if abs(_p) < 0.001:\n",
    "                return 0\n",
    "            p_n.append(_p)\n",
    "\n",
    "        hyp_lengths = GeneralFeatures.get_s_len(hypothesis)\n",
    "        ref_lengths = GeneralFeatures.get_s_len(reference)\n",
    "\n",
    "        # Calculate brevity penalty.\n",
    "        bp = BrevityPenalty.compute(ref_lengths, hyp_lengths)\n",
    "        \n",
    "        s = [w_i * math.log(p_i) for w_i, p_i in zip(weights, p_n)]\n",
    "        s = bp * math.exp(math.fsum(s))\n",
    "        \n",
    "        return s\n",
    "    \n",
    "    @classmethod\n",
    "    def test_precision(cls):\n",
    "        \"\"\"\n",
    "            Example from https://leimao.github.io/blog/BLEU-Score/\n",
    "        \n",
    "        \"\"\"\n",
    "        s1 = \"the cat is on the mat\"\n",
    "        s2 = \"the cat the cat on the mat\"\n",
    "        \n",
    "        p1 = cls.precision(\n",
    "            s1, \n",
    "            s2,\n",
    "            GeneralFeatures.get_n_grams,\n",
    "            NGramSimilarity.basic_word,\n",
    "            1\n",
    "        )\n",
    "        \n",
    "        assert( abs(p1 - 1.) < 0.001)\n",
    "        \n",
    "        p2 = cls.precision(\n",
    "            s1, \n",
    "            s2,\n",
    "            GeneralFeatures.get_n_grams,\n",
    "            NGramSimilarity.basic_word,\n",
    "            2\n",
    "        )\n",
    "        \n",
    "        assert( abs(p2 - 0.66666) < 0.001)\n",
    "        \n",
    "    @classmethod\n",
    "    def test_bleu(cls):\n",
    "        \"\"\"\n",
    "            Example from https://leimao.github.io/blog/BLEU-Score/\n",
    "        \n",
    "        \"\"\"\n",
    "        s1 = \"the cat is on the mat\"\n",
    "        s2 = \"the cat the cat on the mat\"\n",
    "        \n",
    "        bleu1 = cls.compute(\n",
    "            s1, \n",
    "            s2,\n",
    "            GeneralFeatures.get_n_grams,\n",
    "            NGramSimilarity.basic_word,\n",
    "            4\n",
    "        )\n",
    "        print(bleu1)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "BLEUCalculator.test_bleu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MarchFeatureGenerator:\n",
    "    NAME = 'MarchFeature'\n",
    "\n",
    "    def get_feature_1(self, s1, s2):\n",
    "        len_s1 = GeneralFeatures.get_s_len(s1)\n",
    "        len_s2 = GeneralFeatures.get_s_len(s2)\n",
    "        \n",
    "        def f(len_s1, len_s2):\n",
    "            d_1 = (len_s1 - len_s2) * 1. / len_s1\n",
    "            d_2 = 1./ 0.8 ** (len_s1 - len_s2)\n",
    "            r = np.array([d_1, d_2])\n",
    "            return r\n",
    "        \n",
    "        feature_1 = np.array([])\n",
    "        feature_1 = np.append(feature_1, f(len_s1, len_s2))\n",
    "        feature_1 = np.append(feature_1, f(len_s2, len_s1))\n",
    "        return feature_1\n",
    "    \n",
    "    def get_feature_2(self, s1, s2):\n",
    "        doc_1 = nlp(s1)\n",
    "        doc_2 = nlp(s2)\n",
    "        \n",
    "        def compare_n_grams(s1, s2, doc_1, doc_2,  n):\n",
    "            s1_list = GeneralFeatures.get_n_grams(s1, n, doc_1)\n",
    "            s2_list = GeneralFeatures.get_n_grams(s2, n, doc_2)\n",
    "            \n",
    "            def is_n_gram_equal(n_gram_1, n_gram_2):\n",
    "                for i in range(len(n_gram_1)):\n",
    "                    if n_gram_1[i].text != n_gram_2[i].text:\n",
    "                        if n_gram_1[i].similarity(n_gram_2[i]) < 0.9:\n",
    "                            return False\n",
    "                return True\n",
    "            \n",
    "            count = 0\n",
    "            for n_gram_1 in s1_list:\n",
    "                match = False\n",
    "                for n_gram_2 in s2_list:\n",
    "                    if is_n_gram_equal(n_gram_1, n_gram_2):\n",
    "                        match = True\n",
    "                if match:\n",
    "                    count += 1\n",
    "            d = count * 1. / len(s1_list)\n",
    "            return np.array([d])\n",
    "        \n",
    "        feature_2 = np.array([])\n",
    "        \n",
    "        feature_2 = np.append(feature_2, compare_n_grams(s1, s2, doc_1, doc_2, 1))\n",
    "        feature_2 = np.append(feature_2, compare_n_grams(s2, s1, doc_2, doc_1, 1))\n",
    "        feature_2 = np.append(feature_2, compare_n_grams(s1, s2, doc_1, doc_2, 2))\n",
    "        feature_2 = np.append(feature_2, compare_n_grams(s2, s1, doc_2, doc_1, 2))\n",
    "        feature_2 = np.append(feature_2, compare_n_grams(s1, s2, doc_1, doc_2, 3))\n",
    "        feature_2 = np.append(feature_2, compare_n_grams(s2, s1, doc_2, doc_1, 3))\n",
    "        \n",
    "        return feature_2\n",
    "    \n",
    "    def get_feature_4(self, s1, s2):\n",
    "        g1 = GraphBuilder.build_nx_graph_from_sentance(s1)\n",
    "        g2 = GraphBuilder.build_nx_graph_from_sentance(s2)\n",
    "    \n",
    "        g_f1 = GraphFeatures(g1)\n",
    "        g_f2 = GraphFeatures(g2)\n",
    "        \n",
    "        f1 = g_f1.get_simple_edge_features()\n",
    "        f2 = g_f2.get_simple_edge_features()\n",
    "        \n",
    "        def edge_similarity(edge1, edge2):\n",
    "            return (\n",
    "                (edge1['dependancy_type'] == edge2['dependancy_type']) \n",
    "                and NodeSimilarity.basic(edge1['start_node'], edge2['start_node']) > 0.9\n",
    "                and NodeSimilarity.basic(edge1['end_node'], edge2['end_node']) > 0.9\n",
    "            )\n",
    "        \n",
    "        def get_dependancy_similarity(f1, f2):\n",
    "            similarity_score = 0\n",
    "            \n",
    "#             def print_edge(edge):\n",
    "#                 print (edge['start_node']['node'] + \" <\" + edge['dependancy_type'] +  \"> \" + edge['end_node']['node'])\n",
    "            \n",
    "#             print(\"First tree\")\n",
    "#             for edge1 in f1:\n",
    "#                 print_edge(edge1)\n",
    "            \n",
    "#             print(\"*\" * 20)\n",
    "#             print(\"Second tree\")\n",
    "            \n",
    "#             for edge2 in f2:\n",
    "#                 print_edge(edge2)\n",
    "                        \n",
    "            for edge1 in f1:\n",
    "                match = False\n",
    "                for edge2 in f2:\n",
    "                    if edge_similarity(edge1, edge2):\n",
    "                        match = True\n",
    "                if match:\n",
    "                    similarity_score += 1\n",
    "\n",
    "            similarity_score = (similarity_score * 1.) / len(f1)\n",
    "            \n",
    "            return np.array([similarity_score])\n",
    "    \n",
    "        feature_4 = np.array([])\n",
    "        feature_4 = np.append(feature_4, get_dependancy_similarity(f1, f2))\n",
    "        feature_4 = np.append(feature_4, get_dependancy_similarity(f2, f1))\n",
    "        \n",
    "\n",
    "        return feature_4\n",
    "    \n",
    "    def get_feature_5(self, s1, s2):\n",
    "        g1 = GraphBuilder.build_nx_graph_from_sentance(s1)\n",
    "        g2 = GraphBuilder.build_nx_graph_from_sentance(s2)\n",
    "        \n",
    "        def compare_n_grams(g1, g2, length):\n",
    "            # Length in traversal starts with 0\n",
    "            length = length - 1\n",
    "            traversal_1 = GraphTraversal(graph=g1)\n",
    "            traversal_2 = GraphTraversal(graph=g2)\n",
    "            \n",
    "            s1_list = traversal_1.get_all_paths_with_len(length=length)\n",
    "            s2_list = traversal_2.get_all_paths_with_len(length=length)\n",
    "\n",
    "            def is_n_gram_equal(g1, g2, n_gram_1, n_gram_2):\n",
    "                for i in range(len(n_gram_1)):\n",
    "                    if NodeSimilarity.basic(g1.nodes[n_gram_1[i]], g2.nodes[n_gram_2[i]]) < 0.9:\n",
    "                        return False\n",
    "                return True\n",
    "            \n",
    "            count = 0\n",
    "            for n_gram_1 in s1_list:\n",
    "                match = False\n",
    "                for n_gram_2 in s2_list:\n",
    "                    if is_n_gram_equal(g1, g2, n_gram_1, n_gram_2):\n",
    "                        match = True\n",
    "                if match:\n",
    "                    count += 1\n",
    "            d = count * 1. / len(s1_list)\n",
    "            return np.array([d])\n",
    "        \n",
    "        feature_5 = np.array([])\n",
    "        \n",
    "        feature_5 = np.append(feature_5, compare_n_grams(g1, g2, 1))\n",
    "        feature_5 = np.append(feature_5, compare_n_grams(g2, g1, 1))\n",
    "        feature_5 = np.append(feature_5, compare_n_grams(g1, g2, 2))\n",
    "        feature_5 = np.append(feature_5, compare_n_grams(g2, g1, 2))\n",
    "        feature_5 = np.append(feature_5, compare_n_grams(g1, g2, 3))\n",
    "        feature_5 = np.append(feature_5, compare_n_grams(g2, g1, 3))\n",
    "        feature_5 = np.append(feature_5, compare_n_grams(g1, g2, 4))\n",
    "        feature_5 = np.append(feature_5, compare_n_grams(g2, g1, 4))\n",
    "        \n",
    "        return feature_5\n",
    "    \n",
    "    \n",
    "    def get_feature_6(self, s1, s2):\n",
    "        \n",
    "        def get_bleu(s1, s2, n_grams):\n",
    "            return np.array([BLEUCalculator.compute(\n",
    "                s1, \n",
    "                s2,\n",
    "                GeneralFeatures.get_n_grams,\n",
    "                NGramSimilarity.basic_word,\n",
    "                n_grams\n",
    "            )])\n",
    "        \n",
    "\n",
    "        feature_6 = np.array([])\n",
    "        \n",
    "        feature_6 = np.append(feature_6, get_bleu(s1, s2, 1))\n",
    "        feature_6 = np.append(feature_6, get_bleu(s2, s1, 1))\n",
    "        feature_6 = np.append(feature_6, get_bleu(s1, s2, 2))\n",
    "        feature_6 = np.append(feature_6, get_bleu(s2, s1, 2))\n",
    "        feature_6 = np.append(feature_6, get_bleu(s1, s2, 3))\n",
    "        feature_6 = np.append(feature_6, get_bleu(s2, s1, 3))\n",
    "        feature_6 = np.append(feature_6, get_bleu(s1, s2, 4))\n",
    "        feature_6 = np.append(feature_6, get_bleu(s2, s1, 4))\n",
    "        \n",
    "        return feature_6\n",
    "        \n",
    "        \n",
    "    def get_features(self, s1, s2):\n",
    "        features = np.array([])\n",
    "        \n",
    "#         features = np.append(features, self.get_feature_1(s1, s2))\n",
    "#         features = np.append(features, self.get_feature_2(s1, s2))\n",
    "        \n",
    "#         features = np.append(features, self.get_feature_4(s1, s2))\n",
    "#         features = np.append(features, self.get_feature_5(s1, s2))\n",
    "        features = np.append(features, self.get_feature_6(s1, s2))\n",
    "    \n",
    "    \n",
    "        return features\n",
    "    \n",
    "march_feature_generator = MarchFeatureGenerator()\n",
    "# get_feature_1 + get_feature_2 \n",
    "# RidgeClassifierCV\n",
    "# {'precision': 75.63, 'recall': 88.49, 'f1': 81.56, 'accuracy': 73.39}\n",
    "# RidgeClassifierCV\n",
    "# {'precision': 75.32, 'recall': 88.58, 'f1': 81.41, 'accuracy': 73.1}\n",
    "# 1 + 2 + 4 + 5\n",
    "# SGDClassifier {'precision': 72.73, 'recall': 94.42, 'f1': 82.17, 'accuracy': 72.75} [False, False, True, False, False, True, False, False, False, True, False, True, True, True, False, True, True, True, False, True]\n",
    "# SVC {'precision': 73.06, 'recall': 93.64, 'f1': 82.08, 'accuracy': 72.81} [True, False, False, False, True, False, True, False, False, True, True, False, True, True, False, True, False, False, False, False]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3afc19ae975f4a91b19a542af6a0f9ea"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# verbose_data(march_feature_generator)\n",
    "scores = base_classification_test(march_feature_generator, force_feature_update=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scores = base_classification_test(march_feature_generator, force_feature_update=True)\n",
    "# feature_selection(march_feature_generator, verbose=False, bitmask_amount=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "These sent seems to be very similar, but a few words a different: \n",
    "* one can easily substitute rose with jumped\n",
    "* numbers are simmilar :   2.11 ~ 1.63\n",
    "* numbers are simmilar :   21.03 ~ 21.51 \n",
    "\n",
    "To work ion this we can do:\n",
    "* enhance node comparison if it is numbers\n",
    "* try to match subtrees without main word (rose = jumped)\n",
    "\n",
    "```\n",
    "First tree\n",
    "ROOT <ROOT> rose\n",
    "The <det> stock\n",
    "stock <nsubj> rose\n",
    "rose <npadvmod> 2.11\n",
    "rose <punct> ,\n",
    "rose <cc> or\n",
    "rose <conj> percent\n",
    "rose <punct> ,\n",
    "rose <advcl> close\n",
    "rose <punct> .\n",
    "$ <nmod> 2.11\n",
    "about <advmod> 11\n",
    "11 <nummod> percent\n",
    "to <aux> close\n",
    "close <npadvmod> Friday\n",
    "close <prep> at\n",
    "at <pobj> 21.51\n",
    "$ <nmod> 21.51\n",
    "21.51 <prep> on\n",
    "on <pobj> Exchange\n",
    "the <det> Exchange\n",
    "New <compound> York\n",
    "York <compound> Exchange\n",
    "Stock <compound> Exchange\n",
    "********************\n",
    "Second tree\n",
    "ROOT <ROOT> jumped\n",
    "PG&E <compound> Corp.\n",
    "Corp. <compound> shares\n",
    "shares <nsubj> jumped\n",
    "jumped <npadvmod> 1.63\n",
    "jumped <prep> to\n",
    "jumped <prep> on\n",
    "jumped <prep> on\n",
    "jumped <punct> .\n",
    "$ <nmod> 1.63\n",
    "1.63 <cc> or\n",
    "1.63 <conj> percent\n",
    "8 <nummod> percent\n",
    "to <pobj> 21.03\n",
    "$ <nmod> 21.03\n",
    "on <pobj> Exchange\n",
    "the <det> Exchange\n",
    "New <compound> York\n",
    "York <compound> Exchange\n",
    "Stock <compound> Exchange\n",
    "on <pobj> Friday\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

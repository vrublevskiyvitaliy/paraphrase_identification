{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# All installs here\n",
    "\n",
    "# Download medium model\n",
    "\n",
    "# Uncomment to install first time\n",
    "#! pip install spacy\n",
    "#! python -m spacy download en_core_web_md\n",
    "# !pip install --upgrade pip\n",
    "# !pip install numpy==1.18\n",
    "# !pip install scipy==1.1.0\n",
    "# !pip install scikit-learn==0.21.3\n",
    "# !pip install networkx==2.4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# All imports and installs should be here\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk import wordpunct_tokenize\n",
    "import operator\n",
    "import re, string\n",
    "import math\n",
    "import spacy\n",
    "import copy\n",
    "\n",
    "from nltk import Tree\n",
    "# Space module import\n",
    "import en_core_web_md\n",
    "# NetworkX is a Python package for the creation, manipulation, and study of the structure, dynamics, and functions of complex networks.\n",
    "import networkx as nx\n",
    "from networkx import __version__ as nxv\n",
    "import networkx.algorithms as networkx_algorithms\n",
    "\n",
    "# linear_sum_assignment Hungarian algorithm\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import NuSVC\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegressionCV, PassiveAggressiveClassifier, RidgeClassifierCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "\n",
    "# Nice progress bars\n",
    "from tqdm.notebook import tqdm\n",
    "# Used in plotting graphs \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from fractions import Fraction\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# All constants\n",
    "\n",
    "COLAB_ENV = \"colab\"\n",
    "LOCAL_ENV = \"local\"\n",
    "\n",
    "SENTENCE_START_TOKEN = \"sentence_start\"\n",
    "SENTENCE_END_TOKEN = \"sentence_end\"\n",
    "UNKNOWN_TOKEN = \"unknown_token\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_spacy_module():\n",
    "  return en_core_web_md.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To be able run this notebook from Google Colab and localy\n",
    "\n",
    "def get_running_env():\n",
    "  current_path = os.getcwd()\n",
    "  if current_path == \"/content\":\n",
    "    return COLAB_ENV\n",
    "  return LOCAL_ENV\n",
    "\n",
    "RUNNING_ENV = get_running_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# Supress output of the cell\n",
    "\n",
    "def download_corpus():\n",
    "    \"\"\"\n",
    "      Downloading corpus files for colab research.\n",
    "    \"\"\" \n",
    "    if RUNNING_ENV == LOCAL_ENV:\n",
    "      return\n",
    "    files = [\n",
    "      'vrublevskiyvitaliy/paraphrase_identification/contents/dataset/msr-paraphrase-corpus/msr_paraphrase_train.txt',\n",
    "      'vrublevskiyvitaliy/paraphrase_identification/contents/dataset/msr-paraphrase-corpus/msr_paraphrase_test.txt',\n",
    "    ]\n",
    "    for f in files:\n",
    "       !curl --remote-name \\\n",
    "          -H 'Accept: application/vnd.github.v3.raw' \\\n",
    "          --location https://api.github.com/repos/{f}\n",
    "\n",
    "# download_corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data_location():\n",
    "  return \"\" if RUNNING_ENV == COLAB_ENV else \"./../dataset/msr-paraphrase-corpus/\"\n",
    "\n",
    "def add_start_end_sentence_tokens(s):\n",
    "  return \"%s %s %s\" % (SENTENCE_START_TOKEN, s, SENTENCE_END_TOKEN)\n",
    "\n",
    "def load_data(_preprocess_sentence=None, _train=False, _test=False):\n",
    "    \"Load the MSRP dataset.\"\n",
    "    loc = get_data_location()\n",
    "    trainloc = loc + 'msr_paraphrase_train.txt'\n",
    "    testloc = loc + 'msr_paraphrase_test.txt'\n",
    "\n",
    "    if _preprocess_sentence is None:\n",
    "      _preprocess_sentence = lambda x: x\n",
    "\n",
    "    sent1_train, sent2_train, sent1_test, sent2_test = [], [], [], []\n",
    "    label_train, label_dev, label_test = [], [], []\n",
    "\n",
    "    if _train:\n",
    "        with open(trainloc, 'r', encoding='utf8') as f:\n",
    "            f.readline()  # skipping the header of the file\n",
    "            for line in f:\n",
    "                text = line.strip().split('\\t')\n",
    "                sent1_train.append(_preprocess_sentence(text[3]))\n",
    "                sent2_train.append(_preprocess_sentence(text[4]))\n",
    "                label_train.append(int(text[0]))\n",
    "\n",
    "    if _test:\n",
    "        with open(testloc, 'r', encoding='utf8') as f:\n",
    "            f.readline()  # skipping the header of the file\n",
    "            for line in f:\n",
    "                text = line.strip().split('\\t')\n",
    "                sent1_test.append(_preprocess_sentence(text[3]))\n",
    "                sent2_test.append(_preprocess_sentence(text[4]))\n",
    "                label_test.append(int(text[0]))\n",
    "\n",
    "    if _train and _test:\n",
    "        return [sent1_train, sent2_train], [sent1_test, sent2_test], [label_train, label_test]\n",
    "    elif _train:\n",
    "        return [sent1_train, sent2_train], label_train\n",
    "    elif _test:\n",
    "        return [sent1_test, sent2_test], label_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = load_data(_preprocess_sentence=None, _train=True, _test=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sample_data(index=0):\n",
    "  all_data = load_data(_preprocess_sentence=None, _train=True, _test=False)\n",
    "  return all_data[0][0][index], all_data[0][1][index], all_data[1][index]\n",
    "\n",
    "def get_sample(index=0):\n",
    "  all_data = load_data(_preprocess_sentence=None, _train=True, _test=False)\n",
    "  return {'s1': all_data[0][0][index], 's2': all_data[0][1][index], 'label': all_data[1][index]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Amrozi accused his brother, whom he called \"the witness\", of deliberately distorting his evidence.',\n",
       " 'Referring to him as only \"the witness\", Amrozi accused his brother of deliberately distorting his evidence.',\n",
       " 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = get_sample_data()\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp = get_spacy_module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nodes': [{'node': 'ROOT', 'token': None, 'is_fake': True}, {'node': 'Amrozi', 'token': Amrozi, 'is_fake': False}, {'node': 'accused', 'token': accused, 'is_fake': False}, {'node': 'his', 'token': his, 'is_fake': False}, {'node': 'brother', 'token': brother, 'is_fake': False}, {'node': ',', 'token': ,, 'is_fake': False}, {'node': 'whom', 'token': whom, 'is_fake': False}, {'node': 'he', 'token': he, 'is_fake': False}, {'node': 'called', 'token': called, 'is_fake': False}, {'node': '\"', 'token': \", 'is_fake': False}, {'node': 'the', 'token': the, 'is_fake': False}, {'node': 'witness', 'token': witness, 'is_fake': False}, {'node': '\"', 'token': \", 'is_fake': False}, {'node': ',', 'token': ,, 'is_fake': False}, {'node': 'of', 'token': of, 'is_fake': False}, {'node': 'deliberately', 'token': deliberately, 'is_fake': False}, {'node': 'distorting', 'token': distorting, 'is_fake': False}, {'node': 'his', 'token': his, 'is_fake': False}, {'node': 'evidence', 'token': evidence, 'is_fake': False}, {'node': '.', 'token': ., 'is_fake': False}], 'edges': [{'start': 'accused', 'end': 'Amrozi', 'start_node_id': 2, 'end_node_id': 1, 'type': 'nsubj'}, {'start': 'ROOT', 'end': 'accused', 'start_node_id': 0, 'end_node_id': 2, 'type': 'ROOT'}, {'start': 'brother', 'end': 'his', 'start_node_id': 4, 'end_node_id': 3, 'type': 'poss'}, {'start': 'accused', 'end': 'brother', 'start_node_id': 2, 'end_node_id': 4, 'type': 'dobj'}, {'start': 'brother', 'end': ',', 'start_node_id': 4, 'end_node_id': 5, 'type': 'punct'}, {'start': 'called', 'end': 'whom', 'start_node_id': 8, 'end_node_id': 6, 'type': 'dobj'}, {'start': 'called', 'end': 'he', 'start_node_id': 8, 'end_node_id': 7, 'type': 'nsubj'}, {'start': 'brother', 'end': 'called', 'start_node_id': 4, 'end_node_id': 8, 'type': 'relcl'}, {'start': 'witness', 'end': '\"', 'start_node_id': 11, 'end_node_id': 9, 'type': 'punct'}, {'start': 'witness', 'end': 'the', 'start_node_id': 11, 'end_node_id': 10, 'type': 'det'}, {'start': 'called', 'end': 'witness', 'start_node_id': 8, 'end_node_id': 11, 'type': 'oprd'}, {'start': 'witness', 'end': '\"', 'start_node_id': 11, 'end_node_id': 12, 'type': 'punct'}, {'start': 'brother', 'end': ',', 'start_node_id': 4, 'end_node_id': 13, 'type': 'punct'}, {'start': 'accused', 'end': 'of', 'start_node_id': 2, 'end_node_id': 14, 'type': 'prep'}, {'start': 'distorting', 'end': 'deliberately', 'start_node_id': 16, 'end_node_id': 15, 'type': 'advmod'}, {'start': 'of', 'end': 'distorting', 'start_node_id': 14, 'end_node_id': 16, 'type': 'pcomp'}, {'start': 'evidence', 'end': 'his', 'start_node_id': 18, 'end_node_id': 17, 'type': 'poss'}, {'start': 'distorting', 'end': 'evidence', 'start_node_id': 16, 'end_node_id': 18, 'type': 'dobj'}, {'start': 'accused', 'end': '.', 'start_node_id': 2, 'end_node_id': 19, 'type': 'punct'}]}\n",
      "{'nodes': [{'node': 'ROOT', 'token': None, 'is_fake': True}, {'node': 'Referring', 'token': Referring, 'is_fake': False}, {'node': 'to', 'token': to, 'is_fake': False}, {'node': 'him', 'token': him, 'is_fake': False}, {'node': 'as', 'token': as, 'is_fake': False}, {'node': 'only', 'token': only, 'is_fake': False}, {'node': '\"', 'token': \", 'is_fake': False}, {'node': 'the', 'token': the, 'is_fake': False}, {'node': 'witness', 'token': witness, 'is_fake': False}, {'node': '\"', 'token': \", 'is_fake': False}, {'node': ',', 'token': ,, 'is_fake': False}, {'node': 'Amrozi', 'token': Amrozi, 'is_fake': False}, {'node': 'accused', 'token': accused, 'is_fake': False}, {'node': 'his', 'token': his, 'is_fake': False}, {'node': 'brother', 'token': brother, 'is_fake': False}, {'node': 'of', 'token': of, 'is_fake': False}, {'node': 'deliberately', 'token': deliberately, 'is_fake': False}, {'node': 'distorting', 'token': distorting, 'is_fake': False}, {'node': 'his', 'token': his, 'is_fake': False}, {'node': 'evidence', 'token': evidence, 'is_fake': False}, {'node': '.', 'token': ., 'is_fake': False}], 'edges': [{'start': 'accused', 'end': 'Referring', 'start_node_id': 12, 'end_node_id': 1, 'type': 'advcl'}, {'start': 'Referring', 'end': 'to', 'start_node_id': 1, 'end_node_id': 2, 'type': 'prep'}, {'start': 'to', 'end': 'him', 'start_node_id': 2, 'end_node_id': 3, 'type': 'pobj'}, {'start': 'Referring', 'end': 'as', 'start_node_id': 1, 'end_node_id': 4, 'type': 'prep'}, {'start': 'witness', 'end': 'only', 'start_node_id': 8, 'end_node_id': 5, 'type': 'advmod'}, {'start': 'witness', 'end': '\"', 'start_node_id': 8, 'end_node_id': 6, 'type': 'punct'}, {'start': 'witness', 'end': 'the', 'start_node_id': 8, 'end_node_id': 7, 'type': 'det'}, {'start': 'as', 'end': 'witness', 'start_node_id': 4, 'end_node_id': 8, 'type': 'pobj'}, {'start': 'witness', 'end': '\"', 'start_node_id': 8, 'end_node_id': 9, 'type': 'punct'}, {'start': 'accused', 'end': ',', 'start_node_id': 12, 'end_node_id': 10, 'type': 'punct'}, {'start': 'accused', 'end': 'Amrozi', 'start_node_id': 12, 'end_node_id': 11, 'type': 'nsubj'}, {'start': 'ROOT', 'end': 'accused', 'start_node_id': 0, 'end_node_id': 12, 'type': 'ROOT'}, {'start': 'brother', 'end': 'his', 'start_node_id': 14, 'end_node_id': 13, 'type': 'poss'}, {'start': 'accused', 'end': 'brother', 'start_node_id': 12, 'end_node_id': 14, 'type': 'dobj'}, {'start': 'accused', 'end': 'of', 'start_node_id': 12, 'end_node_id': 15, 'type': 'prep'}, {'start': 'distorting', 'end': 'deliberately', 'start_node_id': 17, 'end_node_id': 16, 'type': 'advmod'}, {'start': 'of', 'end': 'distorting', 'start_node_id': 15, 'end_node_id': 17, 'type': 'pcomp'}, {'start': 'evidence', 'end': 'his', 'start_node_id': 19, 'end_node_id': 18, 'type': 'poss'}, {'start': 'distorting', 'end': 'evidence', 'start_node_id': 17, 'end_node_id': 19, 'type': 'dobj'}, {'start': 'accused', 'end': '.', 'start_node_id': 12, 'end_node_id': 20, 'type': 'punct'}]}\n"
     ]
    }
   ],
   "source": [
    "def get_dependancy_graph(s, display=False):\n",
    "  doc = nlp(s)\n",
    "  if display:\n",
    "    spacy.displacy.render(doc, style=\"dep\", jupyter=True)\n",
    "  edges = []\n",
    "  nodes = [{\n",
    "      \"node\": \"ROOT\",\n",
    "      \"token\": None,\n",
    "      \"is_fake\": True, \n",
    "  }]\n",
    "  for token in doc:\n",
    "    nodes.append({\n",
    "        \"node\": token.text,\n",
    "        \"token\": token,\n",
    "        \"is_fake\": False,\n",
    "    })\n",
    "    if token.dep_ == \"ROOT\":\n",
    "      edges.append({\n",
    "        \"start\": \"ROOT\",\n",
    "        \"end\": token.text,\n",
    "        \"start_node_id\": 0,\n",
    "        \"end_node_id\": token.i + 1,\n",
    "        \"type\": token.dep_\n",
    "      })\n",
    "    else:\n",
    "      edges.append({\n",
    "        \"start\": token.head.text,\n",
    "        \"end\": token.text,\n",
    "        \"start_node_id\":  token.head.i + 1,\n",
    "        \"end_node_id\": token.i + 1,\n",
    "        \"type\": token.dep_\n",
    "      })\n",
    "  return {\"nodes\": nodes, \"edges\": edges}\n",
    "\n",
    "graph1 = get_dependancy_graph(sample[0], False)\n",
    "graph2 = get_dependancy_graph(sample[1], False)\n",
    "print(graph1)\n",
    "print(graph2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I try to explore diferent Graph similarity algorithms:\n",
    "\n",
    "First approach\n",
    "1.   Map nodes using Hungarian algorithm\n",
    "2.   Count Graph Edit Distance GED also using Hungarian algorithm\n",
    "\n",
    "Ideas to try:\n",
    "* add treshold for node matching, only if > 0.5 for example merge nodes\n",
    "\n",
    "Next ideas to try: \n",
    "* From graphs get graph based entities like path, or subgraphs.\n",
    "* Combine vectors in these entities\n",
    "* Count # of entities with some similarity threshold\n",
    "\n",
    "Look at different structural graph features. Try to look at https://networkx.github.io/documentation/latest/reference/algorithms/index.html\n",
    "\n",
    "\n",
    "One example could be Wiener index (need to think on normalization)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code is taken from https://github.com/Jacobe2169/ged4py\n",
    "\n",
    "class EdgeGraph():\n",
    "    def __init__(self, init_node, nodes):\n",
    "        self.init_node=init_node\n",
    "        self.nodes_ = nodes\n",
    "\n",
    "    def nodes(self):\n",
    "        return self.nodes_\n",
    "\n",
    "    def size(self):\n",
    "        return len(self.nodes)\n",
    "    def __len__(self):\n",
    "        return len(self.nodes_)\n",
    "\n",
    "class AbstractGraphEditDistance(object):\n",
    "    def __init__(self, g1, g2):\n",
    "        self.g1 = g1\n",
    "        self.g2 = g2\n",
    "\n",
    "    def normalized_distance(self):\n",
    "        \"\"\"\n",
    "        Returns the graph edit distance between graph g1 & g2\n",
    "        The distance is normalized on the size of the two graphs.\n",
    "        This is done to avoid favorisation towards smaller graphs\n",
    "        \"\"\"\n",
    "        avg_graphlen = len(self.g1) + len(self.g2)\n",
    "        return self.distance() / avg_graphlen\n",
    "\n",
    "    def distance(self):\n",
    "        return sum(self.edit_costs())\n",
    "\n",
    "    def edit_costs(self):\n",
    "        cost_matrix = self.create_cost_matrix()\n",
    "        row_ind,col_ind = linear_sum_assignment(cost_matrix)\n",
    "        return [cost_matrix[row_ind[i]][col_ind[i]] for i in range(len(row_ind))]\n",
    "\n",
    "    def create_cost_matrix(self):\n",
    "        \"\"\"\n",
    "        Creates a |N+M| X |N+M| cost matrix between all nodes in\n",
    "        graphs g1 and g2\n",
    "        Each cost represents the cost of substituting,\n",
    "        deleting or inserting a node\n",
    "        The cost matrix consists of four regions:\n",
    "        substitute \t| insert costs\n",
    "        -------------------------------\n",
    "        delete \t\t| delete -> delete\n",
    "        The delete -> delete region is filled with zeros\n",
    "        \"\"\"\n",
    "        n = len(self.g1)\n",
    "        m = len(self.g2)\n",
    "        cost_matrix = np.zeros((n+m,n+m))\n",
    "        #cost_matrix = [[0 for i in range(n + m)] for j in range(n + m)]\n",
    "        nodes1 = self.g1.nodes() if float(nxv) < 2 else list(self.g1.nodes())\n",
    "        nodes2 = self.g2.nodes() if float(nxv) < 2 else list(self.g2.nodes())\n",
    "\n",
    "        for i in range(n):\n",
    "            for j in range(m):\n",
    "                cost_matrix[i,j] = self.substitute_cost(nodes1[i], nodes2[j])\n",
    "\n",
    "        for i in range(m):\n",
    "            for j in range(m):\n",
    "                cost_matrix[i+n,j] = self.insert_cost(i, j, nodes2)\n",
    "\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                cost_matrix[j,i+m] = self.delete_cost(i, j, nodes1)\n",
    "\n",
    "        self.cost_matrix = cost_matrix\n",
    "        return cost_matrix\n",
    "\n",
    "    def insert_cost(self, i, j):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def delete_cost(self, i, j):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def substitute_cost(self, nodes1, nodes2):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def print_matrix(self):\n",
    "        print(\"cost matrix:\")\n",
    "        for column in self.create_cost_matrix():\n",
    "            for row in column:\n",
    "                if row == sys.maxsize:\n",
    "                    print (\"inf\\t\")\n",
    "                else:\n",
    "                    print (\"%.2f\\t\" % float(row))\n",
    "            print(\"\")\n",
    "\n",
    "class EdgeEditDistance(AbstractGraphEditDistance):\n",
    "    \"\"\"\n",
    "    Calculates the graph edit distance between two edges.\n",
    "    A node in this context is interpreted as a graph,\n",
    "    and edges are interpreted as nodes.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, g1, g2):\n",
    "        AbstractGraphEditDistance.__init__(self, g1, g2)\n",
    "\n",
    "    def insert_cost(self, i, j, nodes2):\n",
    "        if i == j:\n",
    "            return 1\n",
    "        return sys.maxsize\n",
    "\n",
    "    def delete_cost(self, i, j, nodes1):\n",
    "        if i == j:\n",
    "            return 1\n",
    "        return sys.maxsize\n",
    "\n",
    "    def substitute_cost(self, edge1, edge2):\n",
    "        if edge1 == edge2:\n",
    "            return 0.\n",
    "        return 1\n",
    "\n",
    "class GraphEditDistance(AbstractGraphEditDistance):\n",
    "    def __init__(self, g1, g2):\n",
    "        AbstractGraphEditDistance.__init__(self, g1, g2)\n",
    "\n",
    "    def substitute_cost(self, node1, node2):\n",
    "        return self.relabel_cost(node1, node2) + self.edge_diff(node1, node2)\n",
    "\n",
    "    def relabel_cost(self, node1, node2):\n",
    "        if node1 == node2:\n",
    "            return 0.\n",
    "        else:\n",
    "            return 1.\n",
    "\n",
    "    def delete_cost(self, i, j, nodes1):\n",
    "        if i == j:\n",
    "            return 1\n",
    "        return sys.maxsize\n",
    "\n",
    "    def insert_cost(self, i, j, nodes2):\n",
    "        if i == j:\n",
    "            return 1\n",
    "        else:\n",
    "            return sys.maxsize\n",
    "\n",
    "    def pos_insdel_weight(self, node):\n",
    "        return 1\n",
    "\n",
    "    def edge_diff(self, node1, node2):\n",
    "        edges1 = list(self.g1.edge[node1].keys()) if float(nxv) < 2 else list(self.g1.edges(node1))\n",
    "        edges2 = list(self.g2.edge[node2].keys()) if float(nxv) < 2 else list(self.g2.edges(node2))\n",
    "        if len(edges1) == 0 or len(edges2) == 0:\n",
    "            return max(len(edges1), len(edges2))\n",
    "\n",
    "        edit_edit_dist = EdgeEditDistance(EdgeGraph(node1,edges1), EdgeGraph(node2,edges2))\n",
    "        return edit_edit_dist.normalized_distance()\n",
    "\n",
    "def compare_graphs(g1, g2, print_details=False, use_normalized=True):\n",
    "    ged = GraphEditDistance(g1, g2)\n",
    "\n",
    "    if print_details:\n",
    "        ged.print_matrix()\n",
    "\n",
    "    return ged.normalized_distance() if use_normalized else ged.distance()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class HungarianGraphNodesMatcher:\n",
    "\n",
    "  def __init__(self, _g1, _g2, threshold=0.5):\n",
    "    self.g1 = _g1\n",
    "    self.g2 = _g2\n",
    "    self.node_threshold = threshold\n",
    "    self.create_cost_matrix()\n",
    "    self.match_nodes()\n",
    "    \n",
    "\n",
    "  def create_cost_matrix(self):\n",
    "    self.matrix = np.zeros((len(self.g1[\"nodes\"]), len(self.g2[\"nodes\"])))\n",
    "    for i1, n1 in enumerate(self.g1[\"nodes\"]):\n",
    "       for i2, n2 in enumerate(self.g2[\"nodes\"]):\n",
    "         if (not n1[\"is_fake\"] and not n2[\"is_fake\"] and \n",
    "            n1[\"token\"].has_vector and n2[\"token\"].has_vector):\n",
    "           self.matrix[i1][i2] = n1[\"token\"].similarity(n2[\"token\"])\n",
    "         elif n1[\"is_fake\"] == n2[\"is_fake\"]:\n",
    "           self.matrix[i1][i2] = n1[\"node\"] == n2[\"node\"]\n",
    "         else:\n",
    "           self.matrix[i1][i2] = 0\n",
    "\n",
    "    # Now we need to fleep scores, because Hungarian is trying to minimize\n",
    "    self.cost = np.subtract(np.full(self.matrix.shape, 1), self.matrix)\n",
    "\n",
    "  def get_pandas_matrix(self):\n",
    "    df = pd.DataFrame(\n",
    "        data=self.matrix,\n",
    "        index=np.array([n[\"node\"] for n in self.g1[\"nodes\"]]),\n",
    "        columns=np.array([n[\"node\"] for n in self.g2[\"nodes\"]])\n",
    "      )\n",
    "    \n",
    "    return df\n",
    "\n",
    "  def match_nodes(self):\n",
    "    row_ind, col_ind = linear_sum_assignment(self.cost)\n",
    "\n",
    "    self.graph1_to_graph2 = {\n",
    "        item[0]: item[1] \n",
    "        for item in zip(row_ind, col_ind)\n",
    "        if self.matrix[item[0]][item[1]] > self.node_threshold\n",
    "    }\n",
    "    self.row_ind = row_ind\n",
    "    self.col_ind = col_ind\n",
    "\n",
    "  def create_node_aliases(self):\n",
    "    for id1, n1 in enumerate(self.g1[\"nodes\"]):\n",
    "      n1[\"alias\"] = \"G1_\" + str(id1) + n1[\"node\"]\n",
    "    for id2, n2 in enumerate(self.g2[\"nodes\"]):\n",
    "      n2[\"alias\"] = \"G2_\" + str(id2) + n2[\"node\"] \n",
    "    for id1, id2 in self.graph1_to_graph2.items():\n",
    "      n1 = self.g1[\"nodes\"][id1]\n",
    "      n2 = self.g2[\"nodes\"][id2]\n",
    "      n1[\"alias\"] = \"G1_\" + str(id1) + \"_\" + n1[\"node\"] + \"_G2_\" + str(id2) + \"_\" + n2[\"node\"]\n",
    "      n2[\"alias\"] = n1[\"alias\"]\n",
    "\n",
    "  def build_graph(self, g):\n",
    "    nx_g = nx.Graph()\n",
    "    for edge in g[\"edges\"]:\n",
    "      start_node = g[\"nodes\"][edge[\"start_node_id\"]]\n",
    "      end_node = g[\"nodes\"][edge[\"end_node_id\"]]\n",
    "      nx_g.add_edge(start_node[\"alias\"], end_node[\"alias\"])\n",
    "    return nx_g\n",
    "\n",
    "  def get_converted_graphs(self):\n",
    "    self.create_node_aliases()\n",
    "    g1 = self.build_graph(self.g1)\n",
    "    g2 = self.build_graph(self.g2)\n",
    "    return g1, g2\n",
    "\n",
    "  def print_matched_nodes(self):\n",
    "    print (\"Graph 1  =>   Graph 2\")\n",
    "    for id1, id2 in self.graph1_to_graph2.items():\n",
    "      print(f\"{self.g1['nodes'][id1]['node']}    =>   {self.g2['nodes'][id2]['node']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GraphBuilder:\n",
    "\n",
    "  def __init__(self):\n",
    "    pass\n",
    "  \n",
    "  @classmethod\n",
    "  def build_nx_graph_from_dt(cls, g):\n",
    "    nx_g = nx.Graph()\n",
    "    for index, node in enumerate(g[\"nodes\"]):\n",
    "      nx_g.add_node(index, node=node['node'], token=node['token'], is_fake=node['is_fake'])\n",
    "    for edge in g[\"edges\"]:\n",
    "      nx_g.add_edge(edge[\"start_node_id\"], edge[\"end_node_id\"], dependancy_type=edge[\"type\"])\n",
    "    return nx_g\n",
    "\n",
    "\n",
    "  @classmethod\n",
    "  def build_nx_graph_from_sentance(cls, s):\n",
    "    graph = get_dependancy_graph(s, False)\n",
    "    return cls.build_nx_graph_from_dt(graph)\n",
    "\n",
    "  @classmethod\n",
    "  def get_root_node(cls, g):\n",
    "    main_root_node = [n for n, _ in g.adj[0].items()][0]\n",
    "    return g.nodes[main_root_node]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "node_matcher = HungarianGraphNodesMatcher(graph1, graph2, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph 1  =>   Graph 2\n",
      "ROOT    =>   ROOT\n",
      "Amrozi    =>   Amrozi\n",
      "accused    =>   accused\n",
      "his    =>   his\n",
      "brother    =>   brother\n",
      ",    =>   ,\n",
      "\"    =>   \"\n",
      "the    =>   the\n",
      "witness    =>   witness\n",
      "\"    =>   \"\n",
      "of    =>   of\n",
      "deliberately    =>   deliberately\n",
      "distorting    =>   distorting\n",
      "his    =>   his\n",
      "evidence    =>   evidence\n",
      ".    =>   .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_matcher.print_matched_nodes()\n",
    "len(node_matcher.graph1_to_graph2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROOT</th>\n",
       "      <th>Referring</th>\n",
       "      <th>to</th>\n",
       "      <th>him</th>\n",
       "      <th>as</th>\n",
       "      <th>only</th>\n",
       "      <th>\"</th>\n",
       "      <th>the</th>\n",
       "      <th>witness</th>\n",
       "      <th>\"</th>\n",
       "      <th>...</th>\n",
       "      <th>Amrozi</th>\n",
       "      <th>accused</th>\n",
       "      <th>his</th>\n",
       "      <th>brother</th>\n",
       "      <th>of</th>\n",
       "      <th>deliberately</th>\n",
       "      <th>distorting</th>\n",
       "      <th>his</th>\n",
       "      <th>evidence</th>\n",
       "      <th>.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ROOT</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amrozi</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accused</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.462788</td>\n",
       "      <td>0.247302</td>\n",
       "      <td>0.428843</td>\n",
       "      <td>0.329721</td>\n",
       "      <td>0.288702</td>\n",
       "      <td>0.177370</td>\n",
       "      <td>0.245612</td>\n",
       "      <td>0.495963</td>\n",
       "      <td>0.177370</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.409809</td>\n",
       "      <td>0.430317</td>\n",
       "      <td>0.245755</td>\n",
       "      <td>0.492152</td>\n",
       "      <td>0.162321</td>\n",
       "      <td>0.409809</td>\n",
       "      <td>0.455700</td>\n",
       "      <td>0.089694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>his</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.448873</td>\n",
       "      <td>0.450099</td>\n",
       "      <td>0.818316</td>\n",
       "      <td>0.534291</td>\n",
       "      <td>0.459990</td>\n",
       "      <td>0.307721</td>\n",
       "      <td>0.589037</td>\n",
       "      <td>0.460539</td>\n",
       "      <td>0.307721</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.409809</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.595102</td>\n",
       "      <td>0.470308</td>\n",
       "      <td>0.375484</td>\n",
       "      <td>0.248710</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.372411</td>\n",
       "      <td>0.293258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brother</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.326865</td>\n",
       "      <td>0.278940</td>\n",
       "      <td>0.593552</td>\n",
       "      <td>0.359954</td>\n",
       "      <td>0.315489</td>\n",
       "      <td>0.165423</td>\n",
       "      <td>0.276650</td>\n",
       "      <td>0.382124</td>\n",
       "      <td>0.165423</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.430317</td>\n",
       "      <td>0.595102</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.218296</td>\n",
       "      <td>0.202813</td>\n",
       "      <td>0.091600</td>\n",
       "      <td>0.595102</td>\n",
       "      <td>0.181388</td>\n",
       "      <td>0.244569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.191477</td>\n",
       "      <td>0.260884</td>\n",
       "      <td>0.260457</td>\n",
       "      <td>0.453440</td>\n",
       "      <td>0.272194</td>\n",
       "      <td>0.225224</td>\n",
       "      <td>0.207785</td>\n",
       "      <td>0.204928</td>\n",
       "      <td>0.225224</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.154774</td>\n",
       "      <td>0.247196</td>\n",
       "      <td>0.260554</td>\n",
       "      <td>0.246289</td>\n",
       "      <td>0.178351</td>\n",
       "      <td>0.115272</td>\n",
       "      <td>0.247196</td>\n",
       "      <td>0.218267</td>\n",
       "      <td>0.421524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whom</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.530618</td>\n",
       "      <td>0.404365</td>\n",
       "      <td>0.627295</td>\n",
       "      <td>0.527354</td>\n",
       "      <td>0.508026</td>\n",
       "      <td>0.194234</td>\n",
       "      <td>0.375806</td>\n",
       "      <td>0.491248</td>\n",
       "      <td>0.194234</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.503349</td>\n",
       "      <td>0.543793</td>\n",
       "      <td>0.561806</td>\n",
       "      <td>0.362452</td>\n",
       "      <td>0.402099</td>\n",
       "      <td>0.123924</td>\n",
       "      <td>0.543793</td>\n",
       "      <td>0.391814</td>\n",
       "      <td>0.222853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>he</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.501589</td>\n",
       "      <td>0.436620</td>\n",
       "      <td>0.827520</td>\n",
       "      <td>0.592211</td>\n",
       "      <td>0.577246</td>\n",
       "      <td>0.372794</td>\n",
       "      <td>0.491815</td>\n",
       "      <td>0.476299</td>\n",
       "      <td>0.372794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.454249</td>\n",
       "      <td>0.791888</td>\n",
       "      <td>0.579133</td>\n",
       "      <td>0.374885</td>\n",
       "      <td>0.455827</td>\n",
       "      <td>0.210478</td>\n",
       "      <td>0.791888</td>\n",
       "      <td>0.417391</td>\n",
       "      <td>0.419956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>called</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.503237</td>\n",
       "      <td>0.357370</td>\n",
       "      <td>0.417062</td>\n",
       "      <td>0.558222</td>\n",
       "      <td>0.401485</td>\n",
       "      <td>0.448924</td>\n",
       "      <td>0.532806</td>\n",
       "      <td>0.269240</td>\n",
       "      <td>0.448924</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.313714</td>\n",
       "      <td>0.409235</td>\n",
       "      <td>0.322105</td>\n",
       "      <td>0.401833</td>\n",
       "      <td>0.246508</td>\n",
       "      <td>0.108304</td>\n",
       "      <td>0.409235</td>\n",
       "      <td>0.295163</td>\n",
       "      <td>0.251584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\"</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.314289</td>\n",
       "      <td>0.299291</td>\n",
       "      <td>0.304552</td>\n",
       "      <td>0.358556</td>\n",
       "      <td>0.277636</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.299336</td>\n",
       "      <td>0.192335</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.177370</td>\n",
       "      <td>0.307721</td>\n",
       "      <td>0.165423</td>\n",
       "      <td>0.237327</td>\n",
       "      <td>0.202483</td>\n",
       "      <td>0.119719</td>\n",
       "      <td>0.307721</td>\n",
       "      <td>0.209467</td>\n",
       "      <td>0.292410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.461733</td>\n",
       "      <td>0.587738</td>\n",
       "      <td>0.506893</td>\n",
       "      <td>0.604139</td>\n",
       "      <td>0.568014</td>\n",
       "      <td>0.299336</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.399221</td>\n",
       "      <td>0.299336</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.245612</td>\n",
       "      <td>0.589037</td>\n",
       "      <td>0.276650</td>\n",
       "      <td>0.713939</td>\n",
       "      <td>0.275821</td>\n",
       "      <td>0.190533</td>\n",
       "      <td>0.589037</td>\n",
       "      <td>0.409072</td>\n",
       "      <td>0.311351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>witness</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.431173</td>\n",
       "      <td>0.340437</td>\n",
       "      <td>0.493643</td>\n",
       "      <td>0.392104</td>\n",
       "      <td>0.376920</td>\n",
       "      <td>0.192335</td>\n",
       "      <td>0.399221</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.192335</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.495963</td>\n",
       "      <td>0.460539</td>\n",
       "      <td>0.382124</td>\n",
       "      <td>0.333289</td>\n",
       "      <td>0.351068</td>\n",
       "      <td>0.266294</td>\n",
       "      <td>0.460539</td>\n",
       "      <td>0.629995</td>\n",
       "      <td>0.219035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\"</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.314289</td>\n",
       "      <td>0.299291</td>\n",
       "      <td>0.304552</td>\n",
       "      <td>0.358556</td>\n",
       "      <td>0.277636</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.299336</td>\n",
       "      <td>0.192335</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.177370</td>\n",
       "      <td>0.307721</td>\n",
       "      <td>0.165423</td>\n",
       "      <td>0.237327</td>\n",
       "      <td>0.202483</td>\n",
       "      <td>0.119719</td>\n",
       "      <td>0.307721</td>\n",
       "      <td>0.209467</td>\n",
       "      <td>0.292410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.191477</td>\n",
       "      <td>0.260884</td>\n",
       "      <td>0.260457</td>\n",
       "      <td>0.453440</td>\n",
       "      <td>0.272194</td>\n",
       "      <td>0.225224</td>\n",
       "      <td>0.207785</td>\n",
       "      <td>0.204928</td>\n",
       "      <td>0.225224</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.154774</td>\n",
       "      <td>0.247196</td>\n",
       "      <td>0.260554</td>\n",
       "      <td>0.246289</td>\n",
       "      <td>0.178351</td>\n",
       "      <td>0.115272</td>\n",
       "      <td>0.247196</td>\n",
       "      <td>0.218267</td>\n",
       "      <td>0.421524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.352237</td>\n",
       "      <td>0.473689</td>\n",
       "      <td>0.359554</td>\n",
       "      <td>0.537883</td>\n",
       "      <td>0.474578</td>\n",
       "      <td>0.237327</td>\n",
       "      <td>0.713939</td>\n",
       "      <td>0.333289</td>\n",
       "      <td>0.237327</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.245755</td>\n",
       "      <td>0.470308</td>\n",
       "      <td>0.218296</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.162817</td>\n",
       "      <td>0.164856</td>\n",
       "      <td>0.470308</td>\n",
       "      <td>0.390543</td>\n",
       "      <td>0.314684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deliberately</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.468218</td>\n",
       "      <td>0.314271</td>\n",
       "      <td>0.396287</td>\n",
       "      <td>0.345136</td>\n",
       "      <td>0.381660</td>\n",
       "      <td>0.202483</td>\n",
       "      <td>0.275821</td>\n",
       "      <td>0.351068</td>\n",
       "      <td>0.202483</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.492152</td>\n",
       "      <td>0.375484</td>\n",
       "      <td>0.202813</td>\n",
       "      <td>0.162817</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.489589</td>\n",
       "      <td>0.375484</td>\n",
       "      <td>0.408713</td>\n",
       "      <td>0.132542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distorting</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.292888</td>\n",
       "      <td>0.150938</td>\n",
       "      <td>0.199195</td>\n",
       "      <td>0.240917</td>\n",
       "      <td>0.216367</td>\n",
       "      <td>0.119719</td>\n",
       "      <td>0.190533</td>\n",
       "      <td>0.266294</td>\n",
       "      <td>0.119719</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.162321</td>\n",
       "      <td>0.248710</td>\n",
       "      <td>0.091600</td>\n",
       "      <td>0.164856</td>\n",
       "      <td>0.489589</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.248710</td>\n",
       "      <td>0.315557</td>\n",
       "      <td>0.104219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>his</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.448873</td>\n",
       "      <td>0.450099</td>\n",
       "      <td>0.818316</td>\n",
       "      <td>0.534291</td>\n",
       "      <td>0.459990</td>\n",
       "      <td>0.307721</td>\n",
       "      <td>0.589037</td>\n",
       "      <td>0.460539</td>\n",
       "      <td>0.307721</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.409809</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.595102</td>\n",
       "      <td>0.470308</td>\n",
       "      <td>0.375484</td>\n",
       "      <td>0.248710</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.372411</td>\n",
       "      <td>0.293258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>evidence</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.479350</td>\n",
       "      <td>0.323899</td>\n",
       "      <td>0.368769</td>\n",
       "      <td>0.398676</td>\n",
       "      <td>0.445381</td>\n",
       "      <td>0.209467</td>\n",
       "      <td>0.409072</td>\n",
       "      <td>0.629995</td>\n",
       "      <td>0.209467</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.455700</td>\n",
       "      <td>0.372411</td>\n",
       "      <td>0.181388</td>\n",
       "      <td>0.390543</td>\n",
       "      <td>0.408713</td>\n",
       "      <td>0.315557</td>\n",
       "      <td>0.372411</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.225468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.254930</td>\n",
       "      <td>0.358275</td>\n",
       "      <td>0.380523</td>\n",
       "      <td>0.453307</td>\n",
       "      <td>0.366517</td>\n",
       "      <td>0.292410</td>\n",
       "      <td>0.311351</td>\n",
       "      <td>0.219035</td>\n",
       "      <td>0.292410</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.089694</td>\n",
       "      <td>0.293258</td>\n",
       "      <td>0.244569</td>\n",
       "      <td>0.314684</td>\n",
       "      <td>0.132542</td>\n",
       "      <td>0.104219</td>\n",
       "      <td>0.293258</td>\n",
       "      <td>0.225468</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ROOT  Referring        to       him        as      only  \\\n",
       "ROOT           1.0   0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "Amrozi         0.0   0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "accused        0.0   0.462788  0.247302  0.428843  0.329721  0.288702   \n",
       "his            0.0   0.448873  0.450099  0.818316  0.534291  0.459990   \n",
       "brother        0.0   0.326865  0.278940  0.593552  0.359954  0.315489   \n",
       ",              0.0   0.191477  0.260884  0.260457  0.453440  0.272194   \n",
       "whom           0.0   0.530618  0.404365  0.627295  0.527354  0.508026   \n",
       "he             0.0   0.501589  0.436620  0.827520  0.592211  0.577246   \n",
       "called         0.0   0.503237  0.357370  0.417062  0.558222  0.401485   \n",
       "\"              0.0   0.314289  0.299291  0.304552  0.358556  0.277636   \n",
       "the            0.0   0.461733  0.587738  0.506893  0.604139  0.568014   \n",
       "witness        0.0   0.431173  0.340437  0.493643  0.392104  0.376920   \n",
       "\"              0.0   0.314289  0.299291  0.304552  0.358556  0.277636   \n",
       ",              0.0   0.191477  0.260884  0.260457  0.453440  0.272194   \n",
       "of             0.0   0.352237  0.473689  0.359554  0.537883  0.474578   \n",
       "deliberately   0.0   0.468218  0.314271  0.396287  0.345136  0.381660   \n",
       "distorting     0.0   0.292888  0.150938  0.199195  0.240917  0.216367   \n",
       "his            0.0   0.448873  0.450099  0.818316  0.534291  0.459990   \n",
       "evidence       0.0   0.479350  0.323899  0.368769  0.398676  0.445381   \n",
       ".              0.0   0.254930  0.358275  0.380523  0.453307  0.366517   \n",
       "\n",
       "                     \"       the   witness         \"    ...     Amrozi  \\\n",
       "ROOT          0.000000  0.000000  0.000000  0.000000    ...        0.0   \n",
       "Amrozi        0.000000  0.000000  0.000000  0.000000    ...        1.0   \n",
       "accused       0.177370  0.245612  0.495963  0.177370    ...        0.0   \n",
       "his           0.307721  0.589037  0.460539  0.307721    ...        0.0   \n",
       "brother       0.165423  0.276650  0.382124  0.165423    ...        0.0   \n",
       ",             0.225224  0.207785  0.204928  0.225224    ...        0.0   \n",
       "whom          0.194234  0.375806  0.491248  0.194234    ...        0.0   \n",
       "he            0.372794  0.491815  0.476299  0.372794    ...        0.0   \n",
       "called        0.448924  0.532806  0.269240  0.448924    ...        0.0   \n",
       "\"             1.000000  0.299336  0.192335  1.000000    ...        0.0   \n",
       "the           0.299336  1.000000  0.399221  0.299336    ...        0.0   \n",
       "witness       0.192335  0.399221  1.000000  0.192335    ...        0.0   \n",
       "\"             1.000000  0.299336  0.192335  1.000000    ...        0.0   \n",
       ",             0.225224  0.207785  0.204928  0.225224    ...        0.0   \n",
       "of            0.237327  0.713939  0.333289  0.237327    ...        0.0   \n",
       "deliberately  0.202483  0.275821  0.351068  0.202483    ...        0.0   \n",
       "distorting    0.119719  0.190533  0.266294  0.119719    ...        0.0   \n",
       "his           0.307721  0.589037  0.460539  0.307721    ...        0.0   \n",
       "evidence      0.209467  0.409072  0.629995  0.209467    ...        0.0   \n",
       ".             0.292410  0.311351  0.219035  0.292410    ...        0.0   \n",
       "\n",
       "               accused       his   brother        of  deliberately  \\\n",
       "ROOT          0.000000  0.000000  0.000000  0.000000      0.000000   \n",
       "Amrozi        0.000000  0.000000  0.000000  0.000000      0.000000   \n",
       "accused       1.000000  0.409809  0.430317  0.245755      0.492152   \n",
       "his           0.409809  1.000000  0.595102  0.470308      0.375484   \n",
       "brother       0.430317  0.595102  1.000000  0.218296      0.202813   \n",
       ",             0.154774  0.247196  0.260554  0.246289      0.178351   \n",
       "whom          0.503349  0.543793  0.561806  0.362452      0.402099   \n",
       "he            0.454249  0.791888  0.579133  0.374885      0.455827   \n",
       "called        0.313714  0.409235  0.322105  0.401833      0.246508   \n",
       "\"             0.177370  0.307721  0.165423  0.237327      0.202483   \n",
       "the           0.245612  0.589037  0.276650  0.713939      0.275821   \n",
       "witness       0.495963  0.460539  0.382124  0.333289      0.351068   \n",
       "\"             0.177370  0.307721  0.165423  0.237327      0.202483   \n",
       ",             0.154774  0.247196  0.260554  0.246289      0.178351   \n",
       "of            0.245755  0.470308  0.218296  1.000000      0.162817   \n",
       "deliberately  0.492152  0.375484  0.202813  0.162817      1.000000   \n",
       "distorting    0.162321  0.248710  0.091600  0.164856      0.489589   \n",
       "his           0.409809  1.000000  0.595102  0.470308      0.375484   \n",
       "evidence      0.455700  0.372411  0.181388  0.390543      0.408713   \n",
       ".             0.089694  0.293258  0.244569  0.314684      0.132542   \n",
       "\n",
       "              distorting       his  evidence         .  \n",
       "ROOT            0.000000  0.000000  0.000000  0.000000  \n",
       "Amrozi          0.000000  0.000000  0.000000  0.000000  \n",
       "accused         0.162321  0.409809  0.455700  0.089694  \n",
       "his             0.248710  1.000000  0.372411  0.293258  \n",
       "brother         0.091600  0.595102  0.181388  0.244569  \n",
       ",               0.115272  0.247196  0.218267  0.421524  \n",
       "whom            0.123924  0.543793  0.391814  0.222853  \n",
       "he              0.210478  0.791888  0.417391  0.419956  \n",
       "called          0.108304  0.409235  0.295163  0.251584  \n",
       "\"               0.119719  0.307721  0.209467  0.292410  \n",
       "the             0.190533  0.589037  0.409072  0.311351  \n",
       "witness         0.266294  0.460539  0.629995  0.219035  \n",
       "\"               0.119719  0.307721  0.209467  0.292410  \n",
       ",               0.115272  0.247196  0.218267  0.421524  \n",
       "of              0.164856  0.470308  0.390543  0.314684  \n",
       "deliberately    0.489589  0.375484  0.408713  0.132542  \n",
       "distorting      1.000000  0.248710  0.315557  0.104219  \n",
       "his             0.248710  1.000000  0.372411  0.293258  \n",
       "evidence        0.315557  0.372411  1.000000  0.225468  \n",
       ".               0.104219  0.293258  0.225468  1.000000  \n",
       "\n",
       "[20 rows x 21 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = node_matcher.get_pandas_matrix()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph 1  =>   Graph 2\n",
      "ROOT    =>   ROOT\n",
      "Amrozi    =>   Amrozi\n",
      "accused    =>   accused\n",
      "his    =>   his\n",
      "brother    =>   brother\n",
      ",    =>   ,\n",
      "\"    =>   \"\n",
      "the    =>   the\n",
      "witness    =>   witness\n",
      "\"    =>   \"\n",
      "of    =>   of\n",
      "deliberately    =>   deliberately\n",
      "distorting    =>   distorting\n",
      "his    =>   his\n",
      "evidence    =>   evidence\n",
      ".    =>   .\n",
      "Similarity score 0.2086720867208672\n"
     ]
    }
   ],
   "source": [
    "node_matcher.print_matched_nodes()\n",
    "g1, g2 = node_matcher.get_converted_graphs()\n",
    "score = compare_graphs(g1, g2)\n",
    "print(f\"Similarity score {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [10, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkMAAAI1CAYAAADVQv5HAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiKyakyGiIiIyKr9P6dLgZcWjrrvAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7230c814a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nx.draw_networkx(g1, with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_scores(limit=10):\n",
    "  result = []\n",
    "  for i in range(limit):\n",
    "    s1 = data[0][0][i]\n",
    "    s2 = data[0][1][i]\n",
    "    label = data[1][i]\n",
    "    graph1 = get_dependancy_graph(s1, False)\n",
    "    graph2 = get_dependancy_graph(s2, False)\n",
    "    node_matcher = HungarianGraphNodesMatcher(graph1, graph2, 0.8)  \n",
    "    g1, g2 = node_matcher.get_converted_graphs()\n",
    "    score = compare_graphs(g1, g2)\n",
    "    result.append((s1, s2, label, score))\n",
    "  return result\n",
    "\n",
    "result = calculate_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 1  |   Score 0.1842818428184282\n",
      "Label 0  |   Score 0.43574108818011253\n",
      "Label 1  |   Score 0.274537037037037\n",
      "Label 0  |   Score 0.3694677871148459\n",
      "Label 1  |   Score 0.386436170212766\n",
      "Label 1  |   Score 0.2107481060606061\n",
      "Label 0  |   Score 0.537037037037037\n",
      "Label 1  |   Score 0.21115689865689868\n",
      "Label 0  |   Score 0.44702982202982205\n",
      "Label 1  |   Score 0.21071428571428572\n"
     ]
    }
   ],
   "source": [
    "for d in result:\n",
    "  print (f\"Label {d[2]}  |   Score {d[3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prepared_data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DataGenerator:\n",
    "  @classmethod\n",
    "  def get_train_data(cls):\n",
    "    [sent1_train, sent2_train], label_train = load_data(_preprocess_sentence=None, _train=True, _test=False)\n",
    "    return [\n",
    "      {\"s1\": item[0], \"s2\": item[1], \"label\": item[2]}\n",
    "      for item in zip(sent1_train, sent2_train, label_train)       \n",
    "    ]\n",
    "\n",
    "  @classmethod\n",
    "  def get_test_data(cls):\n",
    "    [sent1_test, sent2_test], label_test = load_data(_preprocess_sentence=None, _train=False, _test=True)\n",
    "    \n",
    "    return [\n",
    "      {\"s1\": item[0], \"s2\": item[1], \"label\": item[2]}\n",
    "      for item in zip(sent1_test, sent2_test, label_test)       \n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_data(feature_generator, force=False, limit=100000):\n",
    "  feature_name = feature_generator.NAME\n",
    "  global prepared_data\n",
    "  if feature_name not in prepared_data or force:\n",
    "    train_data = DataGenerator.get_train_data()\n",
    "    test_data = DataGenerator.get_test_data()\n",
    "    train_X = [\n",
    "      feature_generator.get_features(item['s1'], item['s2'])\n",
    "      for item in tqdm(train_data)\n",
    "    ]\n",
    "    train_Y = [item['label'] for item in train_data]\n",
    "\n",
    "    test_X = [\n",
    "      feature_generator.get_features(item['s1'], item['s2'])\n",
    "      for item in tqdm(test_data)\n",
    "    ]\n",
    "    test_Y = [item['label'] for item in test_data]\n",
    "    \n",
    "    features = {}\n",
    "    features['train_X'] = train_X\n",
    "    features['train_Y'] = train_Y\n",
    "    features['test_X'] = test_X\n",
    "    features['test_Y'] = test_Y\n",
    "    prepared_data[feature_name] = features\n",
    "\n",
    "def verbose_data(feature_generator, limit=10, offset=0):\n",
    "    train_data = DataGenerator.get_train_data()\n",
    "    for item in train_data[offset:limit]:\n",
    "      features = feature_generator.get_features(item['s1'], item['s2'])\n",
    "      print(item['s1'])\n",
    "      print(item['s2'])\n",
    "      print(f\"Label {item['label']}\")\n",
    "      print(features)\n",
    "      print(\"*\"* 8)\n",
    "\n",
    "def get_metrics(feature_generator, classificator, force=False, limit=None, features_bitmap=None):\n",
    "  prepare_data(feature_generator, force, limit)\n",
    "  global prepared_data\n",
    "  feature_name = feature_generator.NAME\n",
    "\n",
    "  train_X = np.array(prepared_data[feature_name]['train_X'])\n",
    "  test_X = np.array(prepared_data[feature_name]['test_X'])\n",
    "  if features_bitmap is not None:\n",
    "    train_X = train_X[:, features_bitmap]\n",
    "    test_X = test_X[:, features_bitmap]\n",
    "\n",
    "  classificator.fit(\n",
    "    train_X,\n",
    "    prepared_data[feature_name]['train_Y']\n",
    "  )\n",
    "\n",
    "  test_Y_predicted = classificator.predict(test_X)\n",
    "\n",
    "  precision = precision_score(\n",
    "    prepared_data[feature_name]['test_Y'],\n",
    "    test_Y_predicted\n",
    "  )\n",
    "  recall = recall_score(\n",
    "    prepared_data[feature_name]['test_Y'],\n",
    "    test_Y_predicted\n",
    "  )\n",
    "  f1 = f1_score(\n",
    "    prepared_data[feature_name]['test_Y'],\n",
    "    test_Y_predicted\n",
    "  )\n",
    "  accuracy = accuracy_score(\n",
    "    prepared_data[feature_name]['test_Y'],\n",
    "    test_Y_predicted\n",
    "  )\n",
    "\n",
    "  return {\n",
    "    \"precision\" : round(precision * 100, 2),\n",
    "    \"recall\" : round(recall * 100, 2),\n",
    "    \"f1\" : round(f1 * 100, 2),\n",
    "    \"accuracy\" : round(accuracy * 100, 2),\n",
    "  }\n",
    "\n",
    "class BaselineFeatureGenerator:\n",
    "  NAME = 'Baseline'\n",
    "\n",
    "  def get_features(self, s1, s2):\n",
    "    return np.array([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# classificator = LogisticRegression()\n",
    "# baseline_feature_generator = BaselineFeatureGenerator()\n",
    "# print(\"Baseline\")\n",
    "# get_metrics(baseline_feature_generator, classificator, True, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class HungarianGraphFeatureGenerator:\n",
    "  NAME = 'HungarianGraph'\n",
    "\n",
    "  def get_features(self, s1, s2):\n",
    "    graph1 = get_dependancy_graph(s1, False)\n",
    "    graph2 = get_dependancy_graph(s2, False)\n",
    "    node_matcher = HungarianGraphNodesMatcher(graph1, graph2, 0.9)\n",
    "    g1, g2 = node_matcher.get_converted_graphs()\n",
    "    score_normalized = compare_graphs(g1, g2, False, True)\n",
    "    score_raw = compare_graphs(g1, g2, False, False)\n",
    "    return np.array([score_normalized, score_raw])\n",
    "\n",
    "hungarian_feature_generator = HungarianGraphFeatureGenerator()\n",
    "\n",
    "# It gives {'precision': 73.99, 'recall': 89.54, 'f1': 81.03, 'accuracy': 72.12}\n",
    "# on LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class HungarianNodeFeatureGenerator:\n",
    "  NAME = 'HungarianNode'\n",
    "\n",
    "  def get_features(self, s1, s2):\n",
    "    graph1 = get_dependancy_graph(s1, False)\n",
    "    graph2 = get_dependancy_graph(s2, False)\n",
    "    node_matcher = HungarianGraphNodesMatcher(graph1, graph2, 0.9)\n",
    "    g1, g2 = node_matcher.get_converted_graphs()\n",
    "    n1, n2 = len(g1), len(g2)\n",
    "    num_matched_nodes = len(node_matcher.graph1_to_graph2)\n",
    "    percent_matched = num_matched_nodes * 2. / (n1 + n2)\n",
    "    features = np.array([n1, n2, percent_matched])\n",
    "    return features\n",
    "\n",
    "hungarian_node_feature_generator = HungarianNodeFeatureGenerator()\n",
    "# It gives {'precision': 74.5, 'recall': 90.67, 'f1': 81.79, 'accuracy': 73.16}\n",
    "# on SGDClassifier(),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amrozi accused his brother, whom he called \"the witness\", of deliberately distorting his evidence.\n",
      "Referring to him as only \"the witness\", Amrozi accused his brother of deliberately distorting his evidence.\n",
      "Label 1\n",
      "[20.        21.         0.7804878]\n",
      "********\n",
      "Yucaipa owned Dominick's before selling the chain to Safeway in 1998 for $2.5 billion.\n",
      "Yucaipa bought Dominick's in 1995 for $693 million and sold it to Safeway for $1.8 billion in 1998.\n",
      "Label 0\n",
      "[18.         23.          0.58536585]\n",
      "********\n",
      "They had published an advertisement on the Internet on June 10, offering the cargo for sale, he added.\n",
      "On June 10, the ship's owners had published an advertisement on the Internet, offering the explosives for sale.\n",
      "Label 1\n",
      "[22.  23.   0.8]\n",
      "********\n",
      "Around 0335 GMT, Tab shares were up 19 cents, or 4.4%, at A$4.56, having earlier set a record high of A$4.57.\n",
      "Tab shares jumped 20 cents, or 4.6%, to set a record closing high at A$4.57.\n",
      "Label 0\n",
      "[30.         21.          0.66666667]\n",
      "********\n",
      "The stock rose $2.11, or about 11 percent, to close Friday at $21.51 on the New York Stock Exchange.\n",
      "PG&E Corp. shares jumped $1.63 or 8 percent to $21.03 on the New York Stock Exchange on Friday.\n",
      "Label 1\n",
      "[25.         22.          0.59574468]\n",
      "********\n",
      "Revenue in the first quarter of the year dropped 15 percent from the same period a year earlier.\n",
      "With the scandal hanging over Stewart's company, revenue the first quarter of the year dropped 15 percent from the same period a year earlier.\n",
      "Label 1\n",
      "[20.         28.          0.79166667]\n",
      "********\n",
      "The Nasdaq had a weekly gain of 17.27, or 1.2 percent, closing at 1,520.15 on Friday.\n",
      "The tech-laced Nasdaq Composite .IXIC rallied 30.46 points, or 2.04 percent, to 1,520.15.\n",
      "Label 0\n",
      "[20.         19.          0.46153846]\n",
      "********\n",
      "The DVD-CCA then appealed to the state Supreme Court.\n",
      "The DVD CCA appealed that decision to the U.S. Supreme Court.\n",
      "Label 1\n",
      "[13.         13.          0.76923077]\n",
      "********\n",
      "That compared with $35.18 million, or 24 cents per share, in the year-ago period.\n",
      "Earnings were affected by a non-recurring $8 million tax benefit in the year-ago period.\n",
      "Label 0\n",
      "[21.         21.          0.47619048]\n",
      "********\n",
      "He said the foodservice pie business doesn't fit the company's long-term growth strategy.\n",
      "\"The foodservice pie business does not fit our long-term growth strategy.\n",
      "Label 1\n",
      "[19.         16.          0.74285714]\n",
      "********\n"
     ]
    }
   ],
   "source": [
    "verbose_data(hungarian_node_feature_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def base_classification_test(feature_generator, verbose=True, features_bitmap=None, force_feature_update=False):\n",
    "  if force_feature_update:\n",
    "    prepare_data(feature_generator, True, 10000)\n",
    "\n",
    "  classificators = [\n",
    "    {\n",
    "      \"name\": \"SVC\",\n",
    "      \"classificator\": SVC(),\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"SVC(kernel = 'rbf', random_state = 0)\",\n",
    "      \"classificator\": SVC(kernel = 'rbf', random_state = 0),\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"SVC(probability=True)\",\n",
    "      \"classificator\": SVC(probability=True),\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"NuSVC\",\n",
    "      \"classificator\": NuSVC(),\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"LinearSVC\",\n",
    "      \"classificator\": LinearSVC(),\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"DecisionTreeClassifier\",\n",
    "      \"classificator\": DecisionTreeClassifier(),\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"DecisionTreeClassifier(criterion='entropy',random_state=0)\",\n",
    "      \"classificator\": DecisionTreeClassifier(criterion=\"entropy\",random_state=0),\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"ExtraTreeClassifier\",\n",
    "      \"classificator\": ExtraTreeClassifier(),\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"KNeighborsClassifier\",\n",
    "      \"classificator\": KNeighborsClassifier(),\n",
    "    },\n",
    "    {\n",
    "      \"name\": \" KNeighborsClassifier(n_neighbors=5,metric='minkowski',p=2)\",\n",
    "      \"classificator\":  KNeighborsClassifier(n_neighbors=5,metric='minkowski',p=2),\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"GaussianNB\",\n",
    "      \"classificator\": GaussianNB(),\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"BernoulliNB\",\n",
    "      \"classificator\": BernoulliNB(),\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"Perceptron\",\n",
    "      \"classificator\": Perceptron(),\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"SGDClassifier\",\n",
    "      \"classificator\": SGDClassifier(),\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"RandomForestClassifier\",\n",
    "      \"classificator\": RandomForestClassifier(),\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"RandomForestClassifier(n_estimators=1000,criterion='entropy',random_state=0)\",\n",
    "      \"classificator\": RandomForestClassifier(n_estimators=1000,criterion='entropy',random_state=0),\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"LogisticRegressionCV\",\n",
    "      \"classificator\": LogisticRegressionCV(),\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"PassiveAggressiveClassifier\",\n",
    "      \"classificator\": PassiveAggressiveClassifier(),\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"RidgeClassifierCV\",\n",
    "      \"classificator\": RidgeClassifierCV(),\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"LogisticRegression(max_iter = 500000)\",\n",
    "      \"classificator\": LogisticRegression(max_iter = 500000),\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"GradientBoostingClassifier\",\n",
    "      \"classificator\": GradientBoostingClassifier(),\n",
    "    },\n",
    "  ]\n",
    "  res = []\n",
    "  for item in tqdm(classificators):\n",
    "    score = get_metrics(feature_generator, item[\"classificator\"], features_bitmap=features_bitmap)\n",
    "    res.append({\"classificator\": item[\"name\"], \"score\": score})\n",
    "\n",
    "  if verbose:\n",
    "    for r in res:\n",
    "      print(r[\"classificator\"])\n",
    "      print(r[\"score\"])\n",
    "  return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Uncomment to test\n",
    "# prepare_data(hungarian_feature_generator, True, 100000)\n",
    "# base_classification_test(hungarian_feature_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Uncomment to test\n",
    "# prepare_data(hungarian_node_feature_generator, True, 100000)\n",
    "# base_classification_test(hungarian_node_feature_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GraphTraversal:\n",
    "  def __init__(self, graph=None, sentance=None):\n",
    "    assert graph is not None or sentance is not None\n",
    "    if graph is not None:\n",
    "      self.g = graph\n",
    "    else:\n",
    "      self.g = GraphBuilder.build_nx_graph_from_sentance(sentance)\n",
    "  \n",
    "  def get_paths_from_root_to_leafs(self, root=0):\n",
    "     #                 node. parent. path.      \n",
    "    res, stack = [], [(root, None, [])]\n",
    "    while stack:\n",
    "        node, parent, path = stack.pop()\n",
    "        path.append(node)\n",
    "        neighbours = [n for n, _ in self.g.adj[node].items()]\n",
    "        if len(neighbours) == 1 and neighbours[0] == parent:\n",
    "            res.append(path)\n",
    "        for n in neighbours:\n",
    "          if n == parent:\n",
    "            continue\n",
    "          stack.append((n, node, path[:]))\n",
    "    return res\n",
    "    \n",
    "  def get_all_paths_with_len(self, root=0, length=0):\n",
    "    \"\"\"\n",
    "    Return list of pathes with specificified len + 1.\n",
    "    The start is every node.\n",
    "    \n",
    "    For the tree:\n",
    "           1\n",
    "         2   3\n",
    "       5\n",
    "         6\n",
    "         \n",
    "    Len = 2:\n",
    "    [1, 2, 5]\n",
    "    [2, 5, 6]\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    #                  node. parent. path.                  \n",
    "    res, stack = [], [(root, None, [])]\n",
    "    started_new_path = {root}\n",
    "    while stack:\n",
    "        node, parent, path = stack.pop()\n",
    "        path.append(node)\n",
    "        neighbours = [n for n, _ in self.g.adj[node].items()]\n",
    "        if len(path) == length + 1:\n",
    "          res.append(path)\n",
    "        for n in neighbours:\n",
    "          if n == parent:\n",
    "            continue\n",
    "          if len(path) < length + 1:\n",
    "            stack.append((n, node, path[:]))\n",
    "          if n not in started_new_path:\n",
    "            stack.append((n, node, []))\n",
    "            started_new_path.add(n)\n",
    "        \n",
    "    return res\n",
    "\n",
    "  def get_all_subtrees_with_depth(self, root=0, parent=None, length=0):\n",
    "    \"\"\"\n",
    "      Return array of subtrees.\n",
    "      Each subtree is defined by indexes of their nodes.\n",
    "    \"\"\"\n",
    "    #                  node. parent. distance.  \n",
    "    res, stack = [], [(root, parent, 0)]\n",
    "    reached_depth = False\n",
    "    while stack:\n",
    "        node, _parent, distance = stack.pop()\n",
    "        res.append(node)\n",
    "        if distance >= length:\n",
    "          reached_depth = True\n",
    "          continue\n",
    "        neighbours = [n for n, _ in self.g.adj[node].items()]\n",
    "        for n in neighbours:\n",
    "          if n == _parent:\n",
    "            continue\n",
    "          stack.append((n, node, distance + 1))\n",
    "      \n",
    "    all_subtrees = []\n",
    "    if reached_depth:\n",
    "      all_subtrees.append(res)\n",
    "    for n, _ in self.g.adj[root].items():\n",
    "      if n == parent:\n",
    "        continue\n",
    "      all_subtrees += self.get_all_subtrees_with_depth(n, root, length)\n",
    "\n",
    "    return all_subtrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_graphs(graphs, word_labels=False):\n",
    "  for g in graphs:\n",
    "     fig, ax = plt.subplots(1, 1)\n",
    "     if word_labels:\n",
    "       nx.draw(g, arrowstyle=\"->\", with_labels=True, pos=nx.kamada_kawai_layout(g), ax=ax, labels={n: g.nodes[n]['node'] for n in g.nodes})\n",
    "     else:\n",
    "       nx.draw(g, with_labels=True, pos=nx.kamada_kawai_layout(g), ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GraphFeatures:\n",
    "  def __init__(self, graph=None, sentance=None):\n",
    "    assert graph is not None or sentance is not None\n",
    "    if graph is not None:\n",
    "      self.g = graph\n",
    "    else:\n",
    "      self.g = GraphBuilder.build_nx_graph_from_sentance(sentance)\n",
    "  \n",
    "  def get_path_features(self, length=0):\n",
    "    traversal = GraphTraversal(graph=self.g)\n",
    "    pathes = traversal.get_all_paths_with_len(length=length)\n",
    "    \n",
    "    pathes_with_nodes = [\n",
    "      [self.g.nodes[node] for node in path ]\n",
    "      for path in pathes \n",
    "    ]\n",
    "\n",
    "    filtered_pathes_with_nodes = [\n",
    "      path \n",
    "      for path in pathes_with_nodes \n",
    "      if all(\n",
    "          node[\"token\"] is not None and node[\"token\"].has_vector \n",
    "          for node in path\n",
    "      )\n",
    "    ]\n",
    "\n",
    "    aggregated_vectors = [\n",
    "       sum([node[\"token\"].vector for node in path])\n",
    "       for path in filtered_pathes_with_nodes\n",
    "    ]\n",
    "\n",
    "    return aggregated_vectors\n",
    "\n",
    "  def get_subtree_features(self, length=0, remove_tree_without_vector=True, remove_stop_words=False, idf_model=None):\n",
    "    \"\"\"\n",
    "    Return list of vectors, where each vector represent one subtree.\n",
    "    Subtree is created by aggregating vectors in this subtree.\n",
    "\n",
    "    Keyword arguments:\n",
    "    length -- the real part (default 0.0)\n",
    "    remove_tree_without_vector -- remove whole tree if at least one vector inside it \n",
    "      is empty (non common word)\n",
    "    remove_stop_words - remove word from tree if it is stop word\n",
    "    idf_model - If present, multiply vector by word idf\n",
    "    \"\"\"\n",
    "    traversal = GraphTraversal(graph=self.g)\n",
    "    subtrees = traversal.get_all_subtrees_with_depth(length=length)\n",
    "    \n",
    "    subtrees_with_nodes = [\n",
    "      [self.g.nodes[node] for node in subtree ]\n",
    "      for subtree in subtrees\n",
    "    ]\n",
    "\n",
    "    if remove_tree_without_vector:\n",
    "      subtrees_with_nodes = [\n",
    "        subtree \n",
    "        for subtree in subtrees_with_nodes \n",
    "        if all(\n",
    "            node[\"token\"] is not None and node[\"token\"].has_vector \n",
    "            for node in subtree\n",
    "        )\n",
    "      ]\n",
    "\n",
    "    idf = lambda word: 1\n",
    "    \n",
    "    if idf_model is not None:\n",
    "        idf = lambda word: idf_model.get_idf(word)\n",
    "    \n",
    "    aggregated_vectors = [\n",
    "       sum([\n",
    "          node[\"token\"].vector * idf(node[\"token\"])\n",
    "          for node in subtree \n",
    "          # If remove_tree_without_vector == false\n",
    "          if node[\"token\"] is not None and node[\"token\"].has_vector\n",
    "          and (not remove_stop_words or not node[\"token\"].is_stop)\n",
    "        ])\n",
    "       for subtree in subtrees_with_nodes\n",
    "    ]\n",
    "\n",
    "    # Filter empty vectors\n",
    "    aggregated_vectors = [\n",
    "      v\n",
    "      for v in aggregated_vectors\n",
    "      if not np.isscalar(v)\n",
    "    ]\n",
    "\n",
    "    return aggregated_vectors\n",
    "\n",
    "  def get_simple_edge_features(self):\n",
    "    \"\"\"\n",
    "    Return list of edges\n",
    "    \"\"\"\n",
    "    edges = []\n",
    "    for (start_idx, end_idx, dependancy_type) in self.g.edges.data('dependancy_type'):\n",
    "        item = {}\n",
    "        item['start_idx'] = start_idx\n",
    "        item['end_idx'] = end_idx\n",
    "        item['dependancy_type'] = dependancy_type\n",
    "        item['start_node'] = self.g.nodes[start_idx]\n",
    "        item['end_node'] = self.g.nodes[end_idx]\n",
    "        edges.append(item)\n",
    "        \n",
    "    return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Vector:\n",
    "  @classmethod\n",
    "  def get_norm(cls, v):\n",
    "    total = (v ** 2).sum()\n",
    "    return np.sqrt(total) if total != 0 else 0\n",
    "\n",
    "  @classmethod\n",
    "  def similarity(cls, v1, v2):\n",
    "    v1_norm = cls.get_norm(v1)\n",
    "    v2_norm = cls.get_norm(v2)\n",
    "    if v1_norm == 0 or v1_norm == 0:\n",
    "      return 0.0\n",
    "    return (np.dot(v1, v2) / (v1_norm * v2_norm))\n",
    "\n",
    "class MatchFeatureVectors:\n",
    "  @classmethod\n",
    "  def match_feature_vectors(cls, features1, features2, similarity=0.8):\n",
    "    \"\"\"\n",
    "      This function tries to do the following:\n",
    "      1) For each vector in features1 try to find whether vector with good similarity exist in features2.\n",
    "      Return ammount of matched vectors.\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "\n",
    "    features1_norm = []\n",
    "    for v1 in features1:\n",
    "      for v2 in features2:\n",
    "        score = Vector.similarity(v1, v2)\n",
    "        if score > similarity:\n",
    "          count += 1\n",
    "          break\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nxv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "sample = get_sample(0)\n",
    "g1 = GraphBuilder.build_nx_graph_from_sentance(sample['s1'])\n",
    "g2 = GraphBuilder.build_nx_graph_from_sentance(sample['s2'])\n",
    "g_f1 = GraphFeatures(g1)\n",
    "g_f2 = GraphFeatures(g2)\n",
    "f1 = g_f1.get_subtree_features(length=1)\n",
    "f2 = g_f2.get_subtree_features(length=1)\n",
    "score = MatchFeatureVectors.match_feature_vectors(f1, f2, similarity=0.8)\n",
    "print (score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "sample = get_sample(0)\n",
    "g1 = GraphBuilder.build_nx_graph_from_sentance(sample['s1'])\n",
    "g2 = GraphBuilder.build_nx_graph_from_sentance(sample['s2'])\n",
    "g_f1 = GraphFeatures(g1)\n",
    "g_f2 = GraphFeatures(g2)\n",
    "f1 = g_f1.get_path_features(length=3)\n",
    "f2 = g_f2.get_path_features(length=3)\n",
    "score = MatchFeatureVectors.match_feature_vectors(f1, f2, similarity=0.8)\n",
    "print (score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PathFeatureGenerator:\n",
    "  NAME = 'PathSimilarity'\n",
    "\n",
    "  SIMILARITY = 0.8\n",
    "\n",
    "  def get_feature_for_length(self, g_f1, g_f2, length):\n",
    "    f1 = g_f1.get_path_features(length=length)\n",
    "    f2 = g_f2.get_path_features(length=length)\n",
    "    \n",
    "    score = MatchFeatureVectors.match_feature_vectors(f1, f2, similarity=self.SIMILARITY)\n",
    "\n",
    "    norm = len(f1) + len(f2)\n",
    "    return (score * 2.) / norm if norm != 0 else 0\n",
    "\n",
    "  def get_features(self, s1, s2):\n",
    "    g1 = GraphBuilder.build_nx_graph_from_sentance(s1)\n",
    "    g2 = GraphBuilder.build_nx_graph_from_sentance(s2)\n",
    "    \n",
    "    g_f1 = GraphFeatures(g1)\n",
    "    g_f2 = GraphFeatures(g2)\n",
    "\n",
    "    features = np.array([\n",
    "      self.get_feature_for_length(g_f1, g_f2, 0),\n",
    "      self.get_feature_for_length(g_f1, g_f2, 1),\n",
    "      self.get_feature_for_length(g_f1, g_f2, 2),\n",
    "      self.get_feature_for_length(g_f1, g_f2, 3),\n",
    "      self.get_feature_for_length(g_f1, g_f2, 4),\n",
    "    ])\n",
    "\n",
    "    return features\n",
    "\n",
    "path_feature_generator = PathFeatureGenerator()\n",
    "# SGDClassifier {'precision': 74.34, 'recall': 90.41, 'f1': 81.59, 'accuracy': 72.87} [True, False, True, False, True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amrozi accused his brother, whom he called \"the witness\", of deliberately distorting his evidence.\n",
      "Referring to him as only \"the witness\", Amrozi accused his brother of deliberately distorting his evidence.\n",
      "Label 1\n",
      "[0.86486486 0.74285714 1.03703704 1.         0.88888889]\n",
      "********\n",
      "Yucaipa owned Dominick's before selling the chain to Safeway in 1998 for $2.5 billion.\n",
      "Yucaipa bought Dominick's in 1995 for $693 million and sold it to Safeway for $1.8 billion in 1998.\n",
      "Label 0\n",
      "[0.56410256 0.54054054 0.53846154 0.70588235 0.75      ]\n",
      "********\n",
      "They had published an advertisement on the Internet on June 10, offering the cargo for sale, he added.\n",
      "On June 10, the ship's owners had published an advertisement on the Internet, offering the explosives for sale.\n",
      "Label 1\n",
      "[0.79069767 0.68292683 0.62068966 0.88888889 1.        ]\n",
      "********\n",
      "Around 0335 GMT, Tab shares were up 19 cents, or 4.4%, at A$4.56, having earlier set a record high of A$4.57.\n",
      "Tab shares jumped 20 cents, or 4.6%, to set a record closing high at A$4.57.\n",
      "Label 0\n",
      "[0.84444444 0.55813953 0.90322581 0.875      0.        ]\n",
      "********\n",
      "The stock rose $2.11, or about 11 percent, to close Friday at $21.51 on the New York Stock Exchange.\n",
      "PG&E Corp. shares jumped $1.63 or 8 percent to $21.03 on the New York Stock Exchange on Friday.\n",
      "Label 1\n",
      "[0.72727273 0.33333333 0.28571429 0.13333333 0.25      ]\n",
      "********\n",
      "Revenue in the first quarter of the year dropped 15 percent from the same period a year earlier.\n",
      "With the scandal hanging over Stewart's company, revenue the first quarter of the year dropped 15 percent from the same period a year earlier.\n",
      "Label 1\n",
      "[0.7826087  0.81818182 0.8        0.88       0.875     ]\n",
      "********\n",
      "The Nasdaq had a weekly gain of 17.27, or 1.2 percent, closing at 1,520.15 on Friday.\n",
      "The tech-laced Nasdaq Composite .IXIC rallied 30.46 points, or 2.04 percent, to 1,520.15.\n",
      "Label 0\n",
      "[0.41176471 0.         0.         0.         0.        ]\n",
      "********\n",
      "The DVD-CCA then appealed to the state Supreme Court.\n",
      "The DVD CCA appealed that decision to the U.S. Supreme Court.\n",
      "Label 1\n",
      "[0.75       0.90909091 0.8        0.85714286 0.        ]\n",
      "********\n",
      "That compared with $35.18 million, or 24 cents per share, in the year-ago period.\n",
      "Earnings were affected by a non-recurring $8 million tax benefit in the year-ago period.\n",
      "Label 0\n",
      "[0.45       0.57894737 0.64516129 0.4137931  0.58823529]\n",
      "********\n",
      "He said the foodservice pie business doesn't fit the company's long-term growth strategy.\n",
      "\"The foodservice pie business does not fit our long-term growth strategy.\n",
      "Label 1\n",
      "[0.84848485 0.83870968 0.90909091 1.23076923 0.        ]\n",
      "********\n"
     ]
    }
   ],
   "source": [
    "verbose_data(path_feature_generator, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that PathFeatureGenerator with more length are giving more stable (core) feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Uncomment to test\n",
    "# prepare_data(path_feature_generator, True)\n",
    "# base_classification_test(path_feature_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_all_bitmasks(length):\n",
    "  res = []\n",
    "  for i in range(1, 2 ** length):\n",
    "     bitmask = np.zeros(length)\n",
    "     n = int(i)\n",
    "     pos = 0\n",
    "     while n > 0:\n",
    "       bitmask[pos] = n % 2\n",
    "       pos += 1\n",
    "       n = n // 2\n",
    "     bitmask = [b == 1 for b in bitmask]\n",
    "     res.append(bitmask)\n",
    "  return res\n",
    "\n",
    "\n",
    "def feature_selection(feature_generator, top_results=5, verbose=False, bitmask_amount=None):\n",
    "  global prepared_data\n",
    "  feature_name = feature_generator.NAME\n",
    "  assert feature_name in prepared_data\n",
    "  length = len(prepared_data[feature_generator.NAME][\"test_X\"][0])\n",
    "  bitmasks = get_all_bitmasks(length)\n",
    "  results = []\n",
    "  if bitmask_amount is not None:\n",
    "    random.shuffle(bitmasks)\n",
    "    bitmasks = random.sample(bitmasks, bitmask_amount)\n",
    "  for bitmask in tqdm(bitmasks):\n",
    "    if verbose:\n",
    "      print(f\"mask {bitmask}\")\n",
    "    scores = base_classification_test(feature_generator, features_bitmap=bitmask, verbose=False)\n",
    "    for score in scores:\n",
    "      if verbose:\n",
    "        print(f\"classificator {score['classificator']}\")\n",
    "        print(f\"score {score['score']}\")\n",
    "        \n",
    "      results.append({\n",
    "        \"mask\": bitmask, \n",
    "        \"score\": score[\"score\"], \n",
    "        \"classificator\": score[\"classificator\"]\n",
    "      })\n",
    "  \n",
    "  results = sorted(results, key=lambda k: k[\"score\"][\"accuracy\"], reverse=True)\n",
    "  print(\"Top Accuracy\")\n",
    "  for r in results[:top_results]:\n",
    "    print(f\"{r['classificator']} {r['score']} {r['mask']}\")\n",
    "  \n",
    "  results = sorted(results, key=lambda k: k[\"score\"][\"f1\"], reverse=True)\n",
    "  print(\"Top F1\")\n",
    "  for r in results[:top_results]:\n",
    "    print(f\"{r['classificator']} {r['score']} {r['mask']}\")\n",
    "\n",
    "# Uncomment to run feature selection\n",
    "# feature_selection(path_feature_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.1312923\n",
      "5.1312923\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Give it back! He pleaded.\")\n",
    "token = doc[0]\n",
    "vector = token.vector\n",
    "total = (vector ** 2).sum()\n",
    "norm = np.sqrt(total) if total != 0 else 0\n",
    "print(norm)\n",
    "print(token.vector_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample = get_sample(0)\n",
    "g1 = GraphBuilder.build_nx_graph_from_sentance(sample['s1'])\n",
    "g2 = GraphBuilder.build_nx_graph_from_sentance(sample['s2'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkMAAAI1CAYAAADVQv5HAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f72300fa7b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_graphs([g1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'is_fake': True, 'node': 'ROOT', 'token': None}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g1.nodes[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SimpleGraphVector:\n",
    "  @classmethod\n",
    "  def get_graph_vector(cls, g):\n",
    "    \"\"\"\n",
    "    g: networkx graph\n",
    "    Return vector\n",
    "    \"\"\"\n",
    "    vectors = []\n",
    "    for node_index in g.nodes:\n",
    "      node = g.nodes[node_index]\n",
    "      if node['token'] is not None and node['token'].has_vector:\n",
    "        attention = g.degree[node_index]\n",
    "        vectors.append(attention * np.array(node['token'].vector))\n",
    "    return sum(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SimpleGraphVectorFeatureGenerator:\n",
    "  \"\"\"\n",
    "  Compute only one feature - one vector of the whole tree\n",
    "  \"\"\"\n",
    "  NAME = 'SimpleGraphVectorFeatureGenerator'\n",
    "\n",
    "  def get_features(self, s1, s2):\n",
    "    g1 = GraphBuilder.build_nx_graph_from_sentance(s1)\n",
    "    g2 = GraphBuilder.build_nx_graph_from_sentance(s2)\n",
    "    \n",
    "    v1 = SimpleGraphVector.get_graph_vector(g1)\n",
    "    v2 = SimpleGraphVector.get_graph_vector(g2)\n",
    "\n",
    "    features = np.array([\n",
    "      Vector.similarity(v1, v2)\n",
    "    ])\n",
    "\n",
    "    return features\n",
    "\n",
    "simple_graph_vector_feature_generator = SimpleGraphVectorFeatureGenerator()\n",
    "# GaussianNB {'precision': 71.35, 'recall': 92.5, 'f1': 80.56, 'accuracy': 70.32}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Uncomment to test\n",
    "# prepare_data(simple_graph_vector_feature_generator, True, 10000)\n",
    "# base_classification_test(simple_graph_vector_feature_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amrozi accused his brother, whom he called \"the witness\", of deliberately distorting his evidence.\n",
      "Referring to him as only \"the witness\", Amrozi accused his brother of deliberately distorting his evidence.\n",
      "Label 1\n",
      "[0.9749242]\n",
      "********\n",
      "Yucaipa owned Dominick's before selling the chain to Safeway in 1998 for $2.5 billion.\n",
      "Yucaipa bought Dominick's in 1995 for $693 million and sold it to Safeway for $1.8 billion in 1998.\n",
      "Label 0\n",
      "[0.92126673]\n",
      "********\n",
      "They had published an advertisement on the Internet on June 10, offering the cargo for sale, he added.\n",
      "On June 10, the ship's owners had published an advertisement on the Internet, offering the explosives for sale.\n",
      "Label 1\n",
      "[0.9578174]\n",
      "********\n",
      "Around 0335 GMT, Tab shares were up 19 cents, or 4.4%, at A$4.56, having earlier set a record high of A$4.57.\n",
      "Tab shares jumped 20 cents, or 4.6%, to set a record closing high at A$4.57.\n",
      "Label 0\n",
      "[0.92144954]\n",
      "********\n",
      "The stock rose $2.11, or about 11 percent, to close Friday at $21.51 on the New York Stock Exchange.\n",
      "PG&E Corp. shares jumped $1.63 or 8 percent to $21.03 on the New York Stock Exchange on Friday.\n",
      "Label 1\n",
      "[0.8688785]\n",
      "********\n",
      "Revenue in the first quarter of the year dropped 15 percent from the same period a year earlier.\n",
      "With the scandal hanging over Stewart's company, revenue the first quarter of the year dropped 15 percent from the same period a year earlier.\n",
      "Label 1\n",
      "[0.9773977]\n",
      "********\n",
      "The Nasdaq had a weekly gain of 17.27, or 1.2 percent, closing at 1,520.15 on Friday.\n",
      "The tech-laced Nasdaq Composite .IXIC rallied 30.46 points, or 2.04 percent, to 1,520.15.\n",
      "Label 0\n",
      "[0.7365288]\n",
      "********\n",
      "The DVD-CCA then appealed to the state Supreme Court.\n",
      "The DVD CCA appealed that decision to the U.S. Supreme Court.\n",
      "Label 1\n",
      "[0.9789003]\n",
      "********\n",
      "That compared with $35.18 million, or 24 cents per share, in the year-ago period.\n",
      "Earnings were affected by a non-recurring $8 million tax benefit in the year-ago period.\n",
      "Label 0\n",
      "[0.8678842]\n",
      "********\n",
      "He said the foodservice pie business doesn't fit the company's long-term growth strategy.\n",
      "\"The foodservice pie business does not fit our long-term growth strategy.\n",
      "Label 1\n",
      "[0.948756]\n",
      "********\n"
     ]
    }
   ],
   "source": [
    "verbose_data(simple_graph_vector_feature_generator, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SubtreeFeatureGenerator:\n",
    "  NAME = 'SubtreeFeature'\n",
    "\n",
    "  SIMILARITY = 0.8\n",
    "\n",
    "  def get_feature_for_length(self, g_f1, g_f2, length):\n",
    "    f1 = g_f1.get_subtree_features(length=length)\n",
    "    f2 = g_f2.get_subtree_features(length=length)\n",
    "    \n",
    "    score = MatchFeatureVectors.match_feature_vectors(f1, f2, similarity=self.SIMILARITY)\n",
    "\n",
    "    norm = len(f1) + len(f2)\n",
    "    return (score * 2.) / norm if norm != 0 else 0\n",
    "\n",
    "  def get_features(self, s1, s2):\n",
    "    g1 = GraphBuilder.build_nx_graph_from_sentance(s1)\n",
    "    g2 = GraphBuilder.build_nx_graph_from_sentance(s2)\n",
    "    \n",
    "    g_f1 = GraphFeatures(g1)\n",
    "    g_f2 = GraphFeatures(g2)\n",
    "\n",
    "    features = np.array([\n",
    "      self.get_feature_for_length(g_f1, g_f2, 0),\n",
    "      self.get_feature_for_length(g_f1, g_f2, 1),\n",
    "      self.get_feature_for_length(g_f1, g_f2, 2),\n",
    "      self.get_feature_for_length(g_f1, g_f2, 3),\n",
    "      self.get_feature_for_length(g_f1, g_f2, 4),\n",
    "    ])\n",
    "\n",
    "    return features\n",
    "\n",
    "subtree_feature_generator = SubtreeFeatureGenerator()\n",
    "# LinearSVC {'precision': 74.85, 'recall': 89.8, 'f1': 81.65, 'accuracy': 73.16}\n",
    "# SGDClassifier {'precision': 74.84, 'recall': 90.5, 'f1': 81.93, 'accuracy': 73.45}\n",
    "# LogisticRegression(max_iter = 500000) {'precision': 75.02, 'recall': 90.32, 'f1': 81.96, 'accuracy': 73.57} [True, True, True, True, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Uncomment to test\n",
    "# prepare_data(subtree_feature_generator, True, 10000)\n",
    "# scores = base_classification_test(subtree_feature_generator)\n",
    "# Uncomment to run feature selection\n",
    "# feature_selection(subtree_feature_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amrozi accused his brother, whom he called \"the witness\", of deliberately distorting his evidence.\n",
      "Referring to him as only \"the witness\", Amrozi accused his brother of deliberately distorting his evidence.\n",
      "Label 1\n",
      "[0.86486486 0.85714286 1.         1.         0.        ]\n",
      "********\n",
      "Yucaipa owned Dominick's before selling the chain to Safeway in 1998 for $2.5 billion.\n",
      "Yucaipa bought Dominick's in 1995 for $693 million and sold it to Safeway for $1.8 billion in 1998.\n",
      "Label 0\n",
      "[0.56410256 0.73684211 1.         1.2        1.33333333]\n",
      "********\n",
      "They had published an advertisement on the Internet on June 10, offering the cargo for sale, he added.\n",
      "On June 10, the ship's owners had published an advertisement on the Internet, offering the explosives for sale.\n",
      "Label 1\n",
      "[0.79069767 0.76190476 1.         1.14285714 1.33333333]\n",
      "********\n",
      "Around 0335 GMT, Tab shares were up 19 cents, or 4.4%, at A$4.56, having earlier set a record high of A$4.57.\n",
      "Tab shares jumped 20 cents, or 4.6%, to set a record closing high at A$4.57.\n",
      "Label 0\n",
      "[0.84444444 0.82352941 1.25       1.         0.        ]\n",
      "********\n",
      "The stock rose $2.11, or about 11 percent, to close Friday at $21.51 on the New York Stock Exchange.\n",
      "PG&E Corp. shares jumped $1.63 or 8 percent to $21.03 on the New York Stock Exchange on Friday.\n",
      "Label 1\n",
      "[0.72727273 0.47619048 0.5        0.66666667 0.        ]\n",
      "********\n",
      "Revenue in the first quarter of the year dropped 15 percent from the same period a year earlier.\n",
      "With the scandal hanging over Stewart's company, revenue the first quarter of the year dropped 15 percent from the same period a year earlier.\n",
      "Label 1\n",
      "[0.7826087  0.74074074 0.84210526 0.85714286 0.88888889]\n",
      "********\n",
      "The Nasdaq had a weekly gain of 17.27, or 1.2 percent, closing at 1,520.15 on Friday.\n",
      "The tech-laced Nasdaq Composite .IXIC rallied 30.46 points, or 2.04 percent, to 1,520.15.\n",
      "Label 0\n",
      "[0.41176471 0.         0.         0.         0.        ]\n",
      "********\n",
      "The DVD-CCA then appealed to the state Supreme Court.\n",
      "The DVD CCA appealed that decision to the U.S. Supreme Court.\n",
      "Label 1\n",
      "[0.75       0.88888889 0.8        0.66666667 0.        ]\n",
      "********\n",
      "That compared with $35.18 million, or 24 cents per share, in the year-ago period.\n",
      "Earnings were affected by a non-recurring $8 million tax benefit in the year-ago period.\n",
      "Label 0\n",
      "[0.45       0.47058824 0.66666667 1.         1.        ]\n",
      "********\n",
      "He said the foodservice pie business doesn't fit the company's long-term growth strategy.\n",
      "\"The foodservice pie business does not fit our long-term growth strategy.\n",
      "Label 1\n",
      "[0.84848485 0.83333333 1.14285714 1.33333333 0.        ]\n",
      "********\n"
     ]
    }
   ],
   "source": [
    "verbose_data(subtree_feature_generator, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RootNodeFeatureGenerator:\n",
    "  NAME = 'RootNodeFeature'\n",
    "\n",
    "  def get_features(self, s1, s2):\n",
    "    g1 = GraphBuilder.build_nx_graph_from_sentance(s1)\n",
    "    g2 = GraphBuilder.build_nx_graph_from_sentance(s2)\n",
    "\n",
    "    root_node1 = GraphBuilder.get_root_node(g1)\n",
    "    root_node2 = GraphBuilder.get_root_node(g2)\n",
    "\n",
    "    if root_node1['token'].has_vector and root_node2['token'].has_vector:\n",
    "      score = root_node1['token'].similarity(root_node2['token'])\n",
    "    else:\n",
    "      score = 0\n",
    "\n",
    "    features = np.array([\n",
    "      score,\n",
    "    ])\n",
    "\n",
    "    return features\n",
    "\n",
    "root_node_feature_generator = RootNodeFeatureGenerator()\n",
    "# SVC {'precision': 66.49, 'recall': 100.0, 'f1': 79.87, 'accuracy': 66.49}\n",
    "# By itself is not usefull, but maybe in combination could be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare_data(root_node_feature_generator, True, 10000)\n",
    "# scores = base_classification_test(root_node_feature_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# class GraphAlgoFeatureGenerator:\n",
    "#   NAME = 'GraphAlgoFeature'\n",
    "\n",
    "#   def get_features(self, s1, s2):\n",
    "#     g1 = GraphBuilder.build_nx_graph_from_sentance(s1)\n",
    "#     g2 = GraphBuilder.build_nx_graph_from_sentance(s2)\n",
    "\n",
    "#     s1 = networkx_algorithms.smetric.s_metric(g1, normalized=False)\n",
    "#     s2 = networkx_algorithms.smetric.s_metric(g2, normalized=False)\n",
    "    \n",
    "#     w1 = networkx_algorithms.wiener.wiener_index(g1)\n",
    "#     w2 = networkx_algorithms.wiener.wiener_index(g2)\n",
    "\n",
    "#     # r1 = networkx_algorithms.richclub.rich_club_coefficient(g1)\n",
    "#     # r2 = networkx_algorithms.richclub.rich_club_coefficient(g2)\n",
    "\n",
    "#     features = np.array([\n",
    "#       s1 / (s1 + s2),\n",
    "#       s2 / (s1 + s2),\n",
    "#       abs(s1 - s2) / (s1 + s2),\n",
    "#       w1 / (w1 + w2),\n",
    "#       w2 / (w1 + w2),\n",
    "#       abs(w1 - w2) / (w1 + w2),\n",
    "#       # abs(r1[0] - r2[0]),\n",
    "#       # abs(r1[1] - r2[1]),\n",
    "#       # abs(r1[2] - r2[2]),      \n",
    "#     ])\n",
    "\n",
    "#     return features\n",
    "\n",
    "# graph_algo_feature_generator = GraphAlgoFeatureGenerator()\n",
    "# Even after feature selection\n",
    "# PassiveAggressiveClassifier {'precision': 68.34, 'recall': 95.2, 'f1': 79.56, 'accuracy': 67.48} [False, False, False, True, True, True]\n",
    "# So it's not useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare_data(graph_algo_feature_generator, True, 10000)\n",
    "# scores = base_classification_test(graph_algo_feature_generator)\n",
    "# feature_selection(graph_algo_feature_generator, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# import json\n",
    "# from json import JSONEncoder\n",
    "\n",
    "# class NumpyArrayEncoder(JSONEncoder):\n",
    "#     def default(self, obj):\n",
    "#         if isinstance(obj, np.ndarray):\n",
    "#             return obj.tolist()\n",
    "#         return JSONEncoder.default(self, obj)\n",
    "\n",
    "# with open('/content/drive/My Drive/phd/prepared_data.json', 'w') as f:\n",
    "#   json.dump(prepared_data, f, cls=NumpyArrayEncoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to remove stop words (don't use their vectors):\n",
    " - Results:\n",
    "    SubtreeFeature - not very usefull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SubtreeFeatureGeneratorWithoutStopWords:\n",
    "  NAME = 'SubtreeFeatureWithoutStopWords'\n",
    "\n",
    "  SIMILARITY = 0.8\n",
    "\n",
    "  def get_feature_for_length(self, g_f1, g_f2, length):\n",
    "    f1 = g_f1.get_subtree_features(length=length, remove_stop_words=True)\n",
    "    f2 = g_f2.get_subtree_features(length=length, remove_stop_words=True)\n",
    "    \n",
    "    score = MatchFeatureVectors.match_feature_vectors(f1, f2, similarity=self.SIMILARITY)\n",
    "\n",
    "    norm = len(f1) + len(f2)\n",
    "    return (score * 2.) / norm if norm != 0 else 0\n",
    "\n",
    "  def get_features(self, s1, s2):\n",
    "    g1 = GraphBuilder.build_nx_graph_from_sentance(s1)\n",
    "    g2 = GraphBuilder.build_nx_graph_from_sentance(s2)\n",
    "    \n",
    "    g_f1 = GraphFeatures(g1)\n",
    "    g_f2 = GraphFeatures(g2)\n",
    "\n",
    "    features = np.array([\n",
    "      self.get_feature_for_length(g_f1, g_f2, 0),\n",
    "      self.get_feature_for_length(g_f1, g_f2, 1),\n",
    "      self.get_feature_for_length(g_f1, g_f2, 2),\n",
    "      self.get_feature_for_length(g_f1, g_f2, 3),\n",
    "      self.get_feature_for_length(g_f1, g_f2, 4),\n",
    "    ])\n",
    "\n",
    "    return features\n",
    "\n",
    "subtree_without_stop_words_feature_generator = SubtreeFeatureGeneratorWithoutStopWords()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare_data(subtree_without_stop_words_feature_generator, True, 10000)\n",
    "# scores = base_classification_test(subtree_without_stop_words_feature_generator)\n",
    "# feature_selection(subtree_without_stop_words_feature_generator, verbose=False)\n",
    "\n",
    "# Results\n",
    "# SVC {'precision': 72.9, 'recall': 91.46, 'f1': 81.13, 'accuracy': 71.71}\n",
    "# feature selection didn't improve results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AllFeatureGenerator:\n",
    "  NAME = 'AllFeatures'\n",
    "\n",
    "  def get_features(self, s1, s2):\n",
    "    generators = [\n",
    "        HungarianGraphFeatureGenerator(),\n",
    "        HungarianNodeFeatureGenerator(),\n",
    "        PathFeatureGenerator(),\n",
    "        SubtreeFeatureGenerator(),\n",
    "    ]\n",
    "    features = np.array([])\n",
    "    for generator in generators:\n",
    "      features = np.append(features, generator.get_features(s1, s2))\n",
    "    return features\n",
    "\n",
    "all_feature_generator = AllFeatureGenerator()\n",
    "# LogisticRegression(max_iter = 500000) {'precision': 76.04, 'recall': 88.84, 'f1': 81.95, 'accuracy': 73.97}\n",
    "# RandomForestClassifier(n_estimators=1000,criterion='entropy',random_state=0) {'precision': 76.32, 'recall': 88.23, 'f1': 81.84, 'accuracy': 73.97}\n",
    "\n",
    "# RidgeClassifierCV {'precision': 76.28, 'recall': 89.71, 'f1': 82.45, 'accuracy': 74.61} [True, False, True, False, False, True, False, False, True, False, True, True, False, True, False]\n",
    "# LogisticRegressionCV {'precision': 76.8, 'recall': 88.58, 'f1': 82.27, 'accuracy': 74.61} [True, False, True, True, True, False, False, True, True, True, False, False, True, True, False]\n",
    "# RidgeClassifierCV {'precision': 76.09, 'recall': 90.15, 'f1': 82.52, 'accuracy': 74.61} [True, True, False, False, False, True, True, False, False, False, True, True, False, False, True]\n",
    "# LogisticRegression(max_iter = 500000) {'precision': 76.4, 'recall': 89.45, 'f1': 82.41, 'accuracy': 74.61} [True, False, True, True, True, True, False, True, True, True, False, False, False, True, False]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare_data(all_feature_generator, True, 10000)\n",
    "# scores = base_classification_test(all_feature_generator)\n",
    "# all_feature_generator = AllFeatureGenerator()\n",
    "# feature_selection(all_feature_generator, verbose=True, bitmask_amount=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AllFeatureGeneratorV1:\n",
    "  NAME = 'AllFeatureV1'\n",
    "\n",
    "  def get_features(self, s1, s2):\n",
    "    generators = [\n",
    "        HungarianGraphFeatureGenerator(),\n",
    "        HungarianNodeFeatureGenerator(),\n",
    "        PathFeatureGenerator(),\n",
    "        SubtreeFeatureGenerator(),\n",
    "        SubtreeFeatureGeneratorWithoutStopWords(),\n",
    "    ]\n",
    "    features = np.array([])\n",
    "    for generator in generators:\n",
    "      features = np.append(features, generator.get_features(s1, s2))\n",
    "    return features\n",
    "\n",
    "all_feature_generator_v1 = AllFeatureGeneratorV1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare_data(all_feature_generator, True, 10000)\n",
    "# scores = base_classification_test(all_feature_generator)\n",
    "# all_feature_generator = AllFeatureGenerator()\n",
    "# feature_selection(all_feature_generator, verbose=False, bitmask_amount=100)\n",
    "\n",
    "# Top Accuracy\n",
    "# LinearSVC {'precision': 76.62, 'recall': 89.45, 'f1': 82.54, 'accuracy': 74.84} [True, False, False, False, False, False, False, False, True, True, True, True, True, True, False]\n",
    "# RidgeClassifierCV {'precision': 76.57, 'recall': 89.45, 'f1': 82.51, 'accuracy': 74.78} [True, False, False, False, False, False, False, False, True, True, True, True, True, True, False]\n",
    "# LogisticRegression(max_iter = 500000) {'precision': 76.79, 'recall': 88.84, 'f1': 82.38, 'accuracy': 74.72} [False, True, False, True, True, True, False, False, False, True, False, True, False, False, True]\n",
    "# LogisticRegression(max_iter = 500000) {'precision': 76.59, 'recall': 89.28, 'f1': 82.45, 'accuracy': 74.72} [False, False, True, True, True, False, False, True, False, False, True, False, True, True, False]\n",
    "# RidgeClassifierCV {'precision': 76.83, 'recall': 88.75, 'f1': 82.36, 'accuracy': 74.72} [False, False, False, False, True, True, False, True, False, False, False, True, True, True, False]\n",
    "# Top F1\n",
    "# LogisticRegression(max_iter = 500000) {'precision': 76.01, 'recall': 90.32, 'f1': 82.55, 'accuracy': 74.61} [True, False, True, False, False, True, True, True, False, True, False, False, False, True, True]\n",
    "# LinearSVC {'precision': 76.62, 'recall': 89.45, 'f1': 82.54, 'accuracy': 74.84} [True, False, False, False, False, False, False, False, True, True, True, True, True, True, False]\n",
    "# RidgeClassifierCV {'precision': 76.57, 'recall': 89.45, 'f1': 82.51, 'accuracy': 74.78} [True, False, False, False, False, False, False, False, True, True, True, True, True, True, False]\n",
    "# SGDClassifier {'precision': 75.22, 'recall': 91.28, 'f1': 82.47, 'accuracy': 74.2} [False, True, True, False, True, False, False, False, False, False, True, True, False, True, False]\n",
    "# Perceptron {'precision': 75.97, 'recall': 90.15, 'f1': 82.46, 'accuracy': 74.49} [True, False, True, False, True, False, False, False, False, False, True, True, True, False, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AnalyzePredictions:\n",
    "  CORRECT_PREDICTIONS = 'CORRECT_PREDICTIONS'\n",
    "  WRONG_PREDICTIONS = 'WRONG_PREDICTIONS'\n",
    "  \n",
    "  @classmethod\n",
    "  def get_predictions(cls, feature_generator, classificator, mode, verbose=True, limit=10):\n",
    "    feature_name = feature_generator.NAME\n",
    "    assert feature_name in prepared_data, \"No features found\"\n",
    "\n",
    "    test_data = DataGenerator.get_test_data()\n",
    "    \n",
    "    train_X = prepared_data[feature_name]['train_X']\n",
    "    test_X = prepared_data[feature_name]['test_X']\n",
    "    train_Y = prepared_data[feature_name]['train_Y']\n",
    "    test_Y = prepared_data[feature_name]['test_Y']\n",
    "\n",
    "\n",
    "    classificator.fit(train_X, train_Y)\n",
    "\n",
    "    test_Y_predicted = classificator.predict(test_X)\n",
    "\n",
    "    res = []\n",
    "    for data, features, prediction, label in zip(test_data, test_X, test_Y_predicted, test_Y):\n",
    "      if (mode == AnalyzePredictions.CORRECT_PREDICTIONS and prediction == label or \n",
    "         mode == AnalyzePredictions.WRONG_PREDICTIONS and prediction != label):\n",
    "          res.append({\n",
    "              \"raw\": data,\n",
    "              \"features\": features,\n",
    "              \"prediction\": prediction,\n",
    "              \"label\": label\n",
    "          })\n",
    "          if verbose:\n",
    "            print(data)\n",
    "            print(features)\n",
    "            print(f\"Prediction {prediction}, but label {label}\")\n",
    "          limit -= 1\n",
    "          if limit == 0:\n",
    "            break\n",
    "    return res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_sample(p):\n",
    "  print (p[\"raw\"][\"s1\"])\n",
    "  print (p[\"raw\"][\"s2\"])\n",
    "  print (f\"Label {p['raw']['label']}\")\n",
    "  print (f\"Prediction {p['prediction']}\")\n",
    "  print (p[\"features\"])\n",
    "\n",
    "# model = LinearSVC()\n",
    "# prepare_data(subtree_feature_generator, True, 10000)\n",
    "# not_predicted = AnalyzePredictions.get_predictions(subtree_feature_generator, model, AnalyzePredictions.WRONG_PREDICTIONS,  verbose=False)\n",
    "# ok_predicted = AnalyzePredictions.get_predictions(subtree_feature_generator, model, AnalyzePredictions.CORRECT_PREDICTIONS,  verbose=False, limit=10)\n",
    "# sample_wrong = not_predicted[0]\n",
    "# sample_ok = ok_predicted[0]\n",
    "\n",
    "# print_sample(sample_wrong)\n",
    "# print_sample(sample_ok)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting to work with edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SimpleEdgeMatcher:\n",
    "  NAME = 'SimpleEdgeMatcher'\n",
    "\n",
    "  SIMILARITY = 0.8\n",
    "\n",
    "  def simple_match_edges(self, g_f1, g_f2):\n",
    "    f1 = g_f1.get_simple_edge_features()\n",
    "    f2 = g_f2.get_simple_edge_features()\n",
    "    \n",
    "    score = 0\n",
    "    for edge1 in f1:\n",
    "        if (edge1['start_node']['token'] is None or \n",
    "            not edge1['start_node']['token'].has_vector\n",
    "            or edge1['end_node']['token'] is None\n",
    "            or not edge1['end_node']['token'].has_vector):\n",
    "                continue\n",
    "        for edge2 in f2:\n",
    "            if (edge2['start_node']['token'] is None \n",
    "            or not edge2['start_node']['token'].has_vector\n",
    "            or edge2['end_node']['token'] is None\n",
    "            or not edge2['end_node']['token'].has_vector):\n",
    "                continue\n",
    "            if (Vector.similarity(\n",
    "                    edge1['start_node']['token'].vector, \n",
    "                    edge2['start_node']['token'].vector\n",
    "                ) > self.SIMILARITY\n",
    "                and Vector.similarity(\n",
    "                    edge1['end_node']['token'].vector, \n",
    "                    edge2['end_node']['token'].vector\n",
    "                ) > self.SIMILARITY\n",
    "               ):\n",
    "                score += 1\n",
    "        \n",
    "    similarity_score = (1. * score) / (len(f1) * len(f2))\n",
    "    \n",
    "    return similarity_score\n",
    "\n",
    "  def get_features(self, s1, s2):\n",
    "    g1 = GraphBuilder.build_nx_graph_from_sentance(s1)\n",
    "    g2 = GraphBuilder.build_nx_graph_from_sentance(s2)\n",
    "    \n",
    "    g_f1 = GraphFeatures(g1)\n",
    "    g_f2 = GraphFeatures(g2)\n",
    "\n",
    "    features = np.array([\n",
    "      self.simple_match_edges(g_f1, g_f2)\n",
    "    ])\n",
    "    \n",
    "    return features\n",
    "\n",
    "simple_edge_matcher_feature_generator = SimpleEdgeMatcher()\n",
    "# Don't efective \n",
    "# GaussianNB {'precision': 67.78, 'recall': 97.56, 'f1': 79.99, 'accuracy': 67.54}\n",
    "# RidgeClassifierCV {'precision': 66.82, 'recall': 99.74, 'f1': 80.03, 'accuracy': 66.9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare_data(simple_edge_matcher_feature_generator, True, 10000)\n",
    "# scores = base_classification_test(simple_edge_matcher_feature_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SimpleEdgeMatcherWithDependancy:\n",
    "  NAME = 'SimpleEdgeMatcherWithDependancy'\n",
    "\n",
    "  SIMILARITY = 0.8\n",
    "\n",
    "  def simple_match_edges_with_dependancy_type(self, g_f1, g_f2):\n",
    "    f1 = g_f1.get_simple_edge_features()\n",
    "    f2 = g_f2.get_simple_edge_features()\n",
    "    \n",
    "    score = 0\n",
    "    total = 0\n",
    "    for edge1 in f1:\n",
    "        if (edge1['start_node']['token'] is None or \n",
    "            not edge1['start_node']['token'].has_vector\n",
    "            or edge1['end_node']['token'] is None\n",
    "            or not edge1['end_node']['token'].has_vector):\n",
    "                continue\n",
    "        for edge2 in f2:\n",
    "            if (edge2['start_node']['token'] is None \n",
    "            or not edge2['start_node']['token'].has_vector\n",
    "            or edge2['end_node']['token'] is None\n",
    "            or not edge2['end_node']['token'].has_vector):\n",
    "                continue\n",
    "            if (Vector.similarity(\n",
    "                    edge1['start_node']['token'].vector, \n",
    "                    edge2['start_node']['token'].vector\n",
    "                ) > self.SIMILARITY\n",
    "                and Vector.similarity(\n",
    "                    edge1['end_node']['token'].vector, \n",
    "                    edge2['end_node']['token'].vector\n",
    "                ) > self.SIMILARITY\n",
    "               ):\n",
    "                if (edge1['dependancy_type'] == edge2['dependancy_type']):\n",
    "                    score += 1\n",
    "                total += 1\n",
    "        \n",
    "    similarity_score = 0 if total == 0 else (1. * score) / total\n",
    "    \n",
    "    return similarity_score\n",
    "\n",
    "  def get_features(self, s1, s2):\n",
    "    g1 = GraphBuilder.build_nx_graph_from_sentance(s1)\n",
    "    g2 = GraphBuilder.build_nx_graph_from_sentance(s2)\n",
    "    \n",
    "    g_f1 = GraphFeatures(g1)\n",
    "    g_f2 = GraphFeatures(g2)\n",
    "\n",
    "    features = np.array([\n",
    "      self.simple_match_edges_with_dependancy_type(g_f1, g_f2)\n",
    "    ])\n",
    "    \n",
    "    simple_edge_matcher_feature_generator = SimpleEdgeMatcher()\n",
    "    features = np.append(features, simple_edge_matcher_feature_generator.get_features(s1, s2))\n",
    "\n",
    "\n",
    "    return features\n",
    "\n",
    "simple_edge_matcher_with_dependancy_feature_generator = SimpleEdgeMatcherWithDependancy()\n",
    "# GradientBoostingClassifier {'precision': 68.77, 'recall': 94.25, 'f1': 79.51, 'accuracy': 67.71}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare_data(simple_edge_matcher_with_dependancy_feature_generator, True, 10000)\n",
    "# scores = base_classification_test(simple_edge_matcher_with_dependancy_feature_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SimpleApproximateBigramKernel:\n",
    "  \"\"\"\n",
    "        From https://www.aclweb.org/anthology/L16-1452.pdf\n",
    "        Simple Approximate Bigram Kernel (SABK)\n",
    "  \"\"\"\n",
    "\n",
    "  NAME = 'SimpleApproximateBigramKernel'\n",
    "  EDGE_SIMILARITY_SCORE = 2\n",
    "\n",
    "  @classmethod  \n",
    "  def node_similarity(cls, node1, node2):\n",
    "    if (node1['token'] is None or \n",
    "        node2['token'] is None or \n",
    "        not node1['token'].has_vector or \n",
    "        not node2['token'].has_vector\n",
    "       ):\n",
    "        return 1 if node1['node'] == node2['node'] else 0\n",
    "    else:\n",
    "        return Vector.similarity(\n",
    "            node1['token'].vector, \n",
    "            node2['token'].vector\n",
    "        )\n",
    "  @classmethod  \n",
    "  def edge_similarity(cls, edge1, edge2):\n",
    "    return SimpleApproximateBigramKernel.EDGE_SIMILARITY_SCORE if edge1['dependancy_type'] == edge2['dependancy_type'] else 1\n",
    "\n",
    "  @classmethod  \n",
    "  def similarity(cls, edge1, edge2):\n",
    "    start_node_similarity = cls.node_similarity(edge1['start_node'], edge2['start_node'])\n",
    "    end_node_similarity = cls.node_similarity(edge1['end_node'], edge2['end_node'])\n",
    "    \n",
    "    edge_similarity = cls.edge_similarity(edge1, edge2)\n",
    "    \n",
    "    return (start_node_similarity + end_node_similarity) * edge_similarity\n",
    "    \n",
    "  @classmethod  \n",
    "  def compute_simple_approximate_bigram_kernel(cls, g_f1, g_f2):\n",
    "    f1 = g_f1.get_simple_edge_features()\n",
    "    f2 = g_f2.get_simple_edge_features()\n",
    "    \n",
    "    similarity_score = 0\n",
    "\n",
    "    for edge1 in f1:\n",
    "        for edge2 in f2:\n",
    "            similarity_score += cls.similarity(edge1, edge2)\n",
    "        \n",
    "    similarity_score = (similarity_score * 1.) / (len(g1.nodes) + len(g2.nodes))\n",
    "    \n",
    "    return similarity_score\n",
    "\n",
    "  def get_features(self, s1, s2):\n",
    "    g1 = GraphBuilder.build_nx_graph_from_sentance(s1)\n",
    "    g2 = GraphBuilder.build_nx_graph_from_sentance(s2)\n",
    "    \n",
    "    g_f1 = GraphFeatures(g1)\n",
    "    g_f2 = GraphFeatures(g2)\n",
    "\n",
    "    features = np.array([\n",
    "      SimpleApproximateBigramKernel.compute_simple_approximate_bigram_kernel(g_f1, g_f2)\n",
    "    ])\n",
    "\n",
    "    return features\n",
    "\n",
    "simple_approximate_bigram_kernel = SimpleApproximateBigramKernel()\n",
    "# LogisticRegression(max_iter = 500000) {'precision': 67.65, 'recall': 98.08, 'f1': 80.07, 'accuracy': 67.54}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scores = base_classification_test(simple_approximate_bigram_kernel, force_feature_update=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TfIdf:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.prepare_corpus()\n",
    "        self.fit()\n",
    "        \n",
    "    def prepare_corpus(self):\n",
    "        self.corpus = [x['s1'] for x in self.data] + [x['s2'] for x in self.data]\n",
    "        self.corpus = list(set(self.corpus))\n",
    "        self.corpus = sorted(self.corpus)\n",
    "        self.corpus_len = len(self.corpus)\n",
    "                \n",
    "        self.sent_to_index = {}\n",
    "        for index, s in enumerate(self.corpus):\n",
    "            self.sent_to_index[s] = index\n",
    "            \n",
    "    def fit(self):\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        X = vectorizer.fit_transform(self.corpus)\n",
    "        \n",
    "        self.vectorizer = vectorizer\n",
    "        \n",
    "        self.words_list = vectorizer.get_feature_names()\n",
    "        self.idf = vectorizer._tfidf.idf_\n",
    "        \n",
    "        self.word_to_index = {}\n",
    "        for index, w in enumerate(self.words_list):\n",
    "            self.word_to_index[w] = index\n",
    "    \n",
    "    def use_idf(self, t):\n",
    "        return (t.is_alpha and \n",
    "                not (t.is_space or t.is_punct or \n",
    "                     t.is_stop or t.like_num))\n",
    "    \n",
    "    def get_idf(self, token):\n",
    "        if not self.use_idf(token):\n",
    "            return 1\n",
    "        return self.get_word_idf(token.text)\n",
    "    \n",
    "    def get_word_idf(self, word):\n",
    "        if word in self.word_to_index:\n",
    "            idf = self.idf[self.word_to_index[word]]\n",
    "        else:\n",
    "            # https://github.com/scikit-learn/scikit-learn/blob/0fb307bf3/sklearn/feature_extraction/text.py#L1443\n",
    "            idf = np.log(self.corpus_len + 1 / 1) + 1\n",
    "#         print(\"Calling idf for \" + word + \" = \" + str(idf))\n",
    "        return idf\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idf_model = TfIdf(DataGenerator.get_test_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SubtreeFeatureGeneratorIdf:\n",
    "  NAME = 'SubtreeFeatureIdf'\n",
    "\n",
    "  SIMILARITY = 0.8\n",
    "\n",
    "  def get_feature_for_length(self, g_f1, g_f2, length):\n",
    "    f1 = g_f1.get_subtree_features(length=length, idf_model=idf_model)\n",
    "    f2 = g_f2.get_subtree_features(length=length, idf_model=idf_model)\n",
    "    \n",
    "    score = MatchFeatureVectors.match_feature_vectors(f1, f2, similarity=self.SIMILARITY)\n",
    "\n",
    "    norm = len(f1) + len(f2)\n",
    "    return (score * 2.) / norm if norm != 0 else 0\n",
    "\n",
    "  def get_features(self, s1, s2):\n",
    "    g1 = GraphBuilder.build_nx_graph_from_sentance(s1)\n",
    "    g2 = GraphBuilder.build_nx_graph_from_sentance(s2)\n",
    "    \n",
    "    g_f1 = GraphFeatures(g1)\n",
    "    g_f2 = GraphFeatures(g2)\n",
    "\n",
    "    features = np.array([\n",
    "      self.get_feature_for_length(g_f1, g_f2, 0),\n",
    "      self.get_feature_for_length(g_f1, g_f2, 1),\n",
    "      self.get_feature_for_length(g_f1, g_f2, 2),\n",
    "      self.get_feature_for_length(g_f1, g_f2, 3),\n",
    "      self.get_feature_for_length(g_f1, g_f2, 4),\n",
    "    ])\n",
    "\n",
    "    return features\n",
    "\n",
    "subtree_feature_generator_idf = SubtreeFeatureGeneratorIdf()\n",
    "# SGDClassifier {'precision': 71.5, 'recall': 95.38, 'f1': 81.73, 'accuracy': 71.65}\n",
    "# Not better than simple subtree_feature_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scores = base_classification_test(subtree_feature_generator_idf, force_feature_update=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GeneralFeatures:\n",
    "    \n",
    "    @classmethod\n",
    "    def get_s_len(cls, s):\n",
    "        doc = nlp(s)\n",
    "        return np.array([len(doc)])\n",
    "    \n",
    "    @classmethod\n",
    "    def get_n_grams(cls, s, n, doc=None):\n",
    "        if doc is None:\n",
    "            d = nlp(s)\n",
    "        else:\n",
    "            d = doc\n",
    "        \n",
    "        res = []\n",
    "        count=0\n",
    "        for token in d[:len(d)-n+1]:  \n",
    "           res.append(d[count:count+n])  \n",
    "           count=count+1  \n",
    "        return res\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NodeSimilarity:\n",
    "    \n",
    "    \n",
    "    @classmethod\n",
    "    def basic(cls, node1, node2):\n",
    "        if (node1['token'] is None or \n",
    "            node2['token'] is None or \n",
    "            not node1['token'].has_vector or \n",
    "            not node2['token'].has_vector\n",
    "           ):\n",
    "            return 1 if node1['node'] == node2['node'] else 0\n",
    "        else:\n",
    "            return Vector.similarity(\n",
    "                node1['token'].vector, \n",
    "                node2['token'].vector\n",
    "            )\n",
    "        \n",
    "    @classmethod\n",
    "    def token_similarity(cls, token1, token2):\n",
    "        \"\"\"\n",
    "        It's spacy tokens\n",
    "        \"\"\"\n",
    "        if token1.has_vector and token2.has_vector:\n",
    "            return Vector.similarity(\n",
    "                token1.vector, \n",
    "                token2.vector\n",
    "            )\n",
    "        else:\n",
    "            return 1 if token1.text == token2.text else 0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from spacy.tokens import Token as SpacyToken\n",
    "\n",
    "class NGramSimilarity:\n",
    "    \n",
    "    @classmethod\n",
    "    def basic_word(cls, n_gram_1, n_gram_2):\n",
    "        \"\"\"\n",
    "            n_gram_1 is Token\n",
    "            n_gram_2 is Token\n",
    "        \"\"\"\n",
    "        if isinstance(n_gram_1[0], SpacyToken):\n",
    "            comparator = NodeSimilarity.token_similarity\n",
    "            \n",
    "        for i in range(len(n_gram_1)):\n",
    "            if comparator(n_gram_1[i], n_gram_2[i]) < 0.9:\n",
    "                return False\n",
    "        return True\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BrevityPenalty:\n",
    "    \n",
    "    @classmethod\n",
    "    def compute(cls, ref_length, hyp_length):\n",
    "        \"\"\"\n",
    "            ref_lengths - int\n",
    "            hyp_lengths - int\n",
    "            Return BrevityPenalty - double\n",
    "            https://www.nltk.org/_modules/nltk/translate/bleu_score.html\n",
    "        \"\"\"\n",
    "        \n",
    "        if hyp_length > ref_length:\n",
    "            return 1\n",
    "        # If hypothesis is empty, brevity penalty = 0 should result in BLEU = 0.0\n",
    "        elif hyp_length == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return math.exp(1 - ref_length / hyp_length)\n",
    "\n",
    "\n",
    "class BLEUCalculator:\n",
    "    \n",
    "    @classmethod\n",
    "    def precision(cls, reference, hypothesis, get_n_grams_funct, is_n_gram_equal_func, n):\n",
    "        \"\"\"\n",
    "        s1 - First sentance\n",
    "        s2 - Second sentance\n",
    "        get_n_grams_funct - Function that takes:\n",
    "            s - sentance\n",
    "            n - size of n gram\n",
    "            Return list of n_grams\n",
    "        is_n_gram_equal_func - n_gram comparator\n",
    "            n_gram_1\n",
    "            n_gram_2\n",
    "            Return Bool\n",
    "        n - size of bigram\n",
    "\n",
    "        \"\"\"\n",
    "        # Extracts all ngrams in hypothesis\n",
    "        # Set an empty Counter if hypothesis is empty.\n",
    "        \n",
    "        reference_n_grams = get_n_grams_funct(reference, n)\n",
    "\n",
    "        hypothesis_n_grams = get_n_grams_funct(hypothesis, n)\n",
    "\n",
    "        total_found = 0\n",
    "\n",
    "        for n_gram_h in hypothesis_n_grams:\n",
    "            found = False\n",
    "            for n_gram_r in reference_n_grams:\n",
    "#                 print(n_gram_h)\n",
    "#                 print(n_gram_r)\n",
    "                if is_n_gram_equal_func(n_gram_h, n_gram_r):\n",
    "#                     print(n_gram_h)\n",
    "#                     print(n_gram_r)\n",
    "#                     print(\"Match\")\n",
    "#                     print(\"*\" * 20)\n",
    "                    \n",
    "                    found = True\n",
    "            if found:\n",
    "                total_found += 1\n",
    "\n",
    "        numerator = total_found\n",
    "        # Ensures that denominator is minimum 1 to avoid ZeroDivisionError.\n",
    "        denominator = max(1, len(hypothesis_n_grams))\n",
    "\n",
    "        return (numerator * 1.) / denominator\n",
    "    \n",
    "    @classmethod\n",
    "    def compute(cls, reference, hypothesis, get_n_grams_funct, is_n_gram_equal_func, max_n):\n",
    "        \"\"\"\n",
    "        s1 - First sentance\n",
    "        s2 - Second sentance\n",
    "        get_n_grams_funct - Function that takes:\n",
    "            s - sentance\n",
    "            n - size of n gram\n",
    "            Return list of n_grams\n",
    "        is_n_gram_equal_func - n_gram comparator\n",
    "            n_gram_1\n",
    "            n_gram_2\n",
    "            Return Bool\n",
    "        max_n - Max size of bigram\n",
    "        \n",
    "        Return BLEU - double\n",
    "        \n",
    "        https://www.nltk.org/_modules/nltk/translate/bleu_score.html\n",
    "        \"\"\"\n",
    "        \n",
    "        p_n = []\n",
    "        \n",
    "        weight = 1. / max_n\n",
    "            \n",
    "        weights = [weight] * max_n\n",
    "        \n",
    "        # For each order of ngram, calculate the numerator and\n",
    "        # denominator for the corpus-level modified precision.\n",
    "        for i, _ in enumerate(weights, start=1):\n",
    "            _p = cls.precision(reference, hypothesis, get_n_grams_funct, is_n_gram_equal_func, i)\n",
    "            if abs(_p) < 0.001:\n",
    "                return 0\n",
    "            p_n.append(_p)\n",
    "\n",
    "        hyp_lengths = GeneralFeatures.get_s_len(hypothesis)\n",
    "        ref_lengths = GeneralFeatures.get_s_len(reference)\n",
    "\n",
    "        # Calculate brevity penalty.\n",
    "        bp = BrevityPenalty.compute(ref_lengths, hyp_lengths)\n",
    "        \n",
    "        s = [w_i * math.log(p_i) for w_i, p_i in zip(weights, p_n)]\n",
    "        s = bp * math.exp(math.fsum(s))\n",
    "        \n",
    "        return s\n",
    "    \n",
    "    @classmethod\n",
    "    def test_precision(cls):\n",
    "        \"\"\"\n",
    "            Example from https://leimao.github.io/blog/BLEU-Score/\n",
    "        \n",
    "        \"\"\"\n",
    "        s1 = \"the cat is on the mat\"\n",
    "        s2 = \"the cat the cat on the mat\"\n",
    "        \n",
    "        p1 = cls.precision(\n",
    "            s1, \n",
    "            s2,\n",
    "            GeneralFeatures.get_n_grams,\n",
    "            NGramSimilarity.basic_word,\n",
    "            1\n",
    "        )\n",
    "        \n",
    "        assert( abs(p1 - 1.) < 0.001)\n",
    "        \n",
    "        p2 = cls.precision(\n",
    "            s1, \n",
    "            s2,\n",
    "            GeneralFeatures.get_n_grams,\n",
    "            NGramSimilarity.basic_word,\n",
    "            2\n",
    "        )\n",
    "        \n",
    "        assert( abs(p2 - 0.66666) < 0.001)\n",
    "        \n",
    "    @classmethod\n",
    "    def test_bleu(cls):\n",
    "        \"\"\"\n",
    "            Example from https://leimao.github.io/blog/BLEU-Score/\n",
    "        \n",
    "        \"\"\"\n",
    "        s1 = \"the cat is on the mat\"\n",
    "        s2 = \"the cat the cat on the mat\"\n",
    "        \n",
    "        bleu1 = cls.compute(\n",
    "            s1, \n",
    "            s2,\n",
    "            GeneralFeatures.get_n_grams,\n",
    "            NGramSimilarity.basic_word,\n",
    "            4\n",
    "        )\n",
    "        print(bleu1)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "BLEUCalculator.test_bleu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarchFeatureGenerator:\n",
    "    NAME = 'MarchFeature'\n",
    "\n",
    "    def get_feature_1(self, s1, s2):\n",
    "        len_s1 = GeneralFeatures.get_s_len(s1)\n",
    "        len_s2 = GeneralFeatures.get_s_len(s2)\n",
    "        \n",
    "        def f(len_s1, len_s2):\n",
    "            d_1 = (len_s1 - len_s2) * 1. / len_s1\n",
    "            d_2 = 1./ 0.8 ** (len_s1 - len_s2)\n",
    "            r = np.array([d_1, d_2])\n",
    "            return r\n",
    "        \n",
    "        feature_1 = np.array([])\n",
    "        feature_1 = np.append(feature_1, f(len_s1, len_s2))\n",
    "        feature_1 = np.append(feature_1, f(len_s2, len_s1))\n",
    "        return feature_1\n",
    "    \n",
    "    def get_feature_2(self, s1, s2):\n",
    "        doc_1 = nlp(s1)\n",
    "        doc_2 = nlp(s2)\n",
    "        \n",
    "        def compare_n_grams(s1, s2, doc_1, doc_2,  n):\n",
    "            s1_list = GeneralFeatures.get_n_grams(s1, n, doc_1)\n",
    "            s2_list = GeneralFeatures.get_n_grams(s2, n, doc_2)\n",
    "            \n",
    "            def is_n_gram_equal(n_gram_1, n_gram_2):\n",
    "                for i in range(len(n_gram_1)):\n",
    "                    if n_gram_1[i].text != n_gram_2[i].text:\n",
    "                        if n_gram_1[i].similarity(n_gram_2[i]) < 0.9:\n",
    "                            return False\n",
    "                return True\n",
    "            \n",
    "            count = 0\n",
    "            for n_gram_1 in s1_list:\n",
    "                match = False\n",
    "                for n_gram_2 in s2_list:\n",
    "                    if is_n_gram_equal(n_gram_1, n_gram_2):\n",
    "                        match = True\n",
    "                if match:\n",
    "                    count += 1\n",
    "            d = count * 1. / len(s1_list)\n",
    "            return np.array([d])\n",
    "        \n",
    "        feature_2 = np.array([])\n",
    "        \n",
    "        feature_2 = np.append(feature_2, compare_n_grams(s1, s2, doc_1, doc_2, 1))\n",
    "        feature_2 = np.append(feature_2, compare_n_grams(s2, s1, doc_2, doc_1, 1))\n",
    "        feature_2 = np.append(feature_2, compare_n_grams(s1, s2, doc_1, doc_2, 2))\n",
    "        feature_2 = np.append(feature_2, compare_n_grams(s2, s1, doc_2, doc_1, 2))\n",
    "        feature_2 = np.append(feature_2, compare_n_grams(s1, s2, doc_1, doc_2, 3))\n",
    "        feature_2 = np.append(feature_2, compare_n_grams(s2, s1, doc_2, doc_1, 3))\n",
    "        \n",
    "        return feature_2\n",
    "    \n",
    "    def get_feature_4(self, s1, s2):\n",
    "        g1 = GraphBuilder.build_nx_graph_from_sentance(s1)\n",
    "        g2 = GraphBuilder.build_nx_graph_from_sentance(s2)\n",
    "    \n",
    "        g_f1 = GraphFeatures(g1)\n",
    "        g_f2 = GraphFeatures(g2)\n",
    "        \n",
    "        f1 = g_f1.get_simple_edge_features()\n",
    "        f2 = g_f2.get_simple_edge_features()\n",
    "        \n",
    "        def edge_similarity(edge1, edge2):\n",
    "            return (\n",
    "                (edge1['dependancy_type'] == edge2['dependancy_type']) \n",
    "                and NodeSimilarity.basic(edge1['start_node'], edge2['start_node']) > 0.9\n",
    "                and NodeSimilarity.basic(edge1['end_node'], edge2['end_node']) > 0.9\n",
    "            )\n",
    "        \n",
    "        def get_dependancy_similarity(f1, f2):\n",
    "            similarity_score = 0\n",
    "            \n",
    "#             def print_edge(edge):\n",
    "#                 print (edge['start_node']['node'] + \" <\" + edge['dependancy_type'] +  \"> \" + edge['end_node']['node'])\n",
    "            \n",
    "#             print(\"First tree\")\n",
    "#             for edge1 in f1:\n",
    "#                 print_edge(edge1)\n",
    "            \n",
    "#             print(\"*\" * 20)\n",
    "#             print(\"Second tree\")\n",
    "            \n",
    "#             for edge2 in f2:\n",
    "#                 print_edge(edge2)\n",
    "                        \n",
    "            for edge1 in f1:\n",
    "                match = False\n",
    "                for edge2 in f2:\n",
    "                    if edge_similarity(edge1, edge2):\n",
    "                        match = True\n",
    "                if match:\n",
    "                    similarity_score += 1\n",
    "\n",
    "            similarity_score = (similarity_score * 1.) / len(f1)\n",
    "            \n",
    "            return np.array([similarity_score])\n",
    "    \n",
    "        feature_4 = np.array([])\n",
    "        feature_4 = np.append(feature_4, get_dependancy_similarity(f1, f2))\n",
    "        feature_4 = np.append(feature_4, get_dependancy_similarity(f2, f1))\n",
    "        \n",
    "\n",
    "        return feature_4\n",
    "    \n",
    "    def get_feature_5(self, s1, s2):\n",
    "        g1 = GraphBuilder.build_nx_graph_from_sentance(s1)\n",
    "        g2 = GraphBuilder.build_nx_graph_from_sentance(s2)\n",
    "        \n",
    "        def compare_n_grams(g1, g2, length):\n",
    "            # Length in traversal starts with 0\n",
    "            length = length - 1\n",
    "            traversal_1 = GraphTraversal(graph=g1)\n",
    "            traversal_2 = GraphTraversal(graph=g2)\n",
    "            \n",
    "            s1_list = traversal_1.get_all_paths_with_len(length=length)\n",
    "            s2_list = traversal_2.get_all_paths_with_len(length=length)\n",
    "\n",
    "            def is_n_gram_equal(g1, g2, n_gram_1, n_gram_2):\n",
    "                for i in range(len(n_gram_1)):\n",
    "                    if NodeSimilarity.basic(g1.nodes[n_gram_1[i]], g2.nodes[n_gram_2[i]]) < 0.9:\n",
    "                        return False\n",
    "                return True\n",
    "            \n",
    "            count = 0\n",
    "            for n_gram_1 in s1_list:\n",
    "                match = False\n",
    "                for n_gram_2 in s2_list:\n",
    "                    if is_n_gram_equal(g1, g2, n_gram_1, n_gram_2):\n",
    "                        match = True\n",
    "                if match:\n",
    "                    count += 1\n",
    "            d = count * 1. / len(s1_list)\n",
    "            return np.array([d])\n",
    "        \n",
    "        feature_5 = np.array([])\n",
    "        \n",
    "        feature_5 = np.append(feature_5, compare_n_grams(g1, g2, 1))\n",
    "        feature_5 = np.append(feature_5, compare_n_grams(g2, g1, 1))\n",
    "        feature_5 = np.append(feature_5, compare_n_grams(g1, g2, 2))\n",
    "        feature_5 = np.append(feature_5, compare_n_grams(g2, g1, 2))\n",
    "        feature_5 = np.append(feature_5, compare_n_grams(g1, g2, 3))\n",
    "        feature_5 = np.append(feature_5, compare_n_grams(g2, g1, 3))\n",
    "        feature_5 = np.append(feature_5, compare_n_grams(g1, g2, 4))\n",
    "        feature_5 = np.append(feature_5, compare_n_grams(g2, g1, 4))\n",
    "        \n",
    "        return feature_5\n",
    "    \n",
    "    \n",
    "    def get_feature_6(self, s1, s2):\n",
    "        \n",
    "        def get_bleu(s1, s2, n_grams):\n",
    "            return np.array([BLEUCalculator.compute(\n",
    "                s1, \n",
    "                s2,\n",
    "                GeneralFeatures.get_n_grams,\n",
    "                NGramSimilarity.basic_word,\n",
    "                n_grams\n",
    "            )])\n",
    "        \n",
    "\n",
    "        feature_6 = np.array([])\n",
    "        \n",
    "        feature_6 = np.append(feature_6, get_bleu(s1, s2, 1))\n",
    "        feature_6 = np.append(feature_6, get_bleu(s2, s1, 1))\n",
    "        feature_6 = np.append(feature_6, get_bleu(s1, s2, 2))\n",
    "        feature_6 = np.append(feature_6, get_bleu(s2, s1, 2))\n",
    "        feature_6 = np.append(feature_6, get_bleu(s1, s2, 3))\n",
    "        feature_6 = np.append(feature_6, get_bleu(s2, s1, 3))\n",
    "        feature_6 = np.append(feature_6, get_bleu(s1, s2, 4))\n",
    "        feature_6 = np.append(feature_6, get_bleu(s2, s1, 4))\n",
    "        \n",
    "        return feature_6\n",
    "        \n",
    "        \n",
    "    def get_features(self, s1, s2):\n",
    "        features = np.array([])\n",
    "        \n",
    "#         features = np.append(features, self.get_feature_1(s1, s2))\n",
    "#         features = np.append(features, self.get_feature_2(s1, s2))\n",
    "        \n",
    "#         features = np.append(features, self.get_feature_4(s1, s2))\n",
    "#         features = np.append(features, self.get_feature_5(s1, s2))\n",
    "        features = np.append(features, self.get_feature_6(s1, s2))\n",
    "    \n",
    "    \n",
    "        return features\n",
    "    \n",
    "march_feature_generator = MarchFeatureGenerator()\n",
    "# get_feature_1 + get_feature_2 \n",
    "# RidgeClassifierCV\n",
    "# {'precision': 75.63, 'recall': 88.49, 'f1': 81.56, 'accuracy': 73.39}\n",
    "# RidgeClassifierCV\n",
    "# {'precision': 75.32, 'recall': 88.58, 'f1': 81.41, 'accuracy': 73.1}\n",
    "# 1 + 2 + 4 + 5\n",
    "# SGDClassifier {'precision': 72.73, 'recall': 94.42, 'f1': 82.17, 'accuracy': 72.75} [False, False, True, False, False, True, False, False, False, True, False, True, True, True, False, True, True, True, False, True]\n",
    "# SVC {'precision': 73.06, 'recall': 93.64, 'f1': 82.08, 'accuracy': 72.81} [True, False, False, False, True, False, True, False, False, True, True, False, True, True, False, True, False, False, False, False]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3afc19ae975f4a91b19a542af6a0f9ea"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# verbose_data(march_feature_generator)\n",
    "scores = base_classification_test(march_feature_generator, force_feature_update=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scores = base_classification_test(march_feature_generator, force_feature_update=True)\n",
    "# feature_selection(march_feature_generator, verbose=False, bitmask_amount=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "These sent seems to be very similar, but a few words a different: \n",
    "* one can easily substitute rose with jumped\n",
    "* numbers are simmilar :   2.11 ~ 1.63\n",
    "* numbers are simmilar :   21.03 ~ 21.51 \n",
    "\n",
    "To work ion this we can do:\n",
    "* enhance node comparison if it is numbers\n",
    "* try to match subtrees without main word (rose = jumped)\n",
    "\n",
    "```\n",
    "First tree\n",
    "ROOT <ROOT> rose\n",
    "The <det> stock\n",
    "stock <nsubj> rose\n",
    "rose <npadvmod> 2.11\n",
    "rose <punct> ,\n",
    "rose <cc> or\n",
    "rose <conj> percent\n",
    "rose <punct> ,\n",
    "rose <advcl> close\n",
    "rose <punct> .\n",
    "$ <nmod> 2.11\n",
    "about <advmod> 11\n",
    "11 <nummod> percent\n",
    "to <aux> close\n",
    "close <npadvmod> Friday\n",
    "close <prep> at\n",
    "at <pobj> 21.51\n",
    "$ <nmod> 21.51\n",
    "21.51 <prep> on\n",
    "on <pobj> Exchange\n",
    "the <det> Exchange\n",
    "New <compound> York\n",
    "York <compound> Exchange\n",
    "Stock <compound> Exchange\n",
    "********************\n",
    "Second tree\n",
    "ROOT <ROOT> jumped\n",
    "PG&E <compound> Corp.\n",
    "Corp. <compound> shares\n",
    "shares <nsubj> jumped\n",
    "jumped <npadvmod> 1.63\n",
    "jumped <prep> to\n",
    "jumped <prep> on\n",
    "jumped <prep> on\n",
    "jumped <punct> .\n",
    "$ <nmod> 1.63\n",
    "1.63 <cc> or\n",
    "1.63 <conj> percent\n",
    "8 <nummod> percent\n",
    "to <pobj> 21.03\n",
    "$ <nmod> 21.03\n",
    "on <pobj> Exchange\n",
    "the <det> Exchange\n",
    "New <compound> York\n",
    "York <compound> Exchange\n",
    "Stock <compound> Exchange\n",
    "on <pobj> Friday\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
